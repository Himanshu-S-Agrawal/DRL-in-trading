{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('^NSEBANK.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ret</th>\n",
       "      <th>fwd_ret5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-27</td>\n",
       "      <td>43804.550781</td>\n",
       "      <td>44194.648438</td>\n",
       "      <td>43693.148438</td>\n",
       "      <td>44121.500000</td>\n",
       "      <td>44121.500000</td>\n",
       "      <td>137300</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.004748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-28</td>\n",
       "      <td>44419.500000</td>\n",
       "      <td>44508.398438</td>\n",
       "      <td>44163.199219</td>\n",
       "      <td>44327.800781</td>\n",
       "      <td>44327.800781</td>\n",
       "      <td>243800</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>0.011963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>44666.000000</td>\n",
       "      <td>44787.101563</td>\n",
       "      <td>44447.199219</td>\n",
       "      <td>44747.351563</td>\n",
       "      <td>44747.351563</td>\n",
       "      <td>191300</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.018033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>44957.949219</td>\n",
       "      <td>45353.199219</td>\n",
       "      <td>44882.101563</td>\n",
       "      <td>45158.101563</td>\n",
       "      <td>45158.101563</td>\n",
       "      <td>228200</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.030163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-04</td>\n",
       "      <td>45310.550781</td>\n",
       "      <td>45655.500000</td>\n",
       "      <td>45000.250000</td>\n",
       "      <td>45301.449219</td>\n",
       "      <td>45301.449219</td>\n",
       "      <td>463000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.036505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date          Open          High           Low         Close  \\\n",
       "0  2023-06-27  43804.550781  44194.648438  43693.148438  44121.500000   \n",
       "1  2023-06-28  44419.500000  44508.398438  44163.199219  44327.800781   \n",
       "2  2023-06-30  44666.000000  44787.101563  44447.199219  44747.351563   \n",
       "3  2023-07-03  44957.949219  45353.199219  44882.101563  45158.101563   \n",
       "4  2023-07-04  45310.550781  45655.500000  45000.250000  45301.449219   \n",
       "\n",
       "      Adj Close  Volume       ret  fwd_ret5  \n",
       "0  44121.500000  137300  0.002054  0.004748  \n",
       "1  44327.800781  243800  0.014038  0.011963  \n",
       "2  44747.351563  191300  0.005549  0.018033  \n",
       "3  45158.101563  228200  0.006536  0.030163  \n",
       "4  45301.449219  463000  0.007843  0.036505  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ret'] = df['Open'].pct_change()\n",
    "df['fwd_ret5'] = df['Open'].pct_change(periods=5)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fwd_ret5        x2  new_column\n",
      "0   0.004748  1.828461   -0.059618\n",
      "1   0.011963  2.702655    0.193575\n",
      "2   0.018033  1.826424   -0.031244\n",
      "3   0.030163  1.746109   -0.026651\n",
      "4   0.036505  2.953060    0.315039\n",
      "5   0.031165  2.988872    0.313140\n",
      "6   0.014432  1.834771   -0.036819\n",
      "7   0.010121  1.957795   -0.012785\n",
      "8   0.000016  1.526550   -0.151940\n",
      "9  -0.006898  2.234107    0.025221\n",
      "10 -0.006577  3.395694    0.341476\n",
      "11 -0.001137  2.489529    0.107153\n",
      "12 -0.005705  1.444387   -0.186717\n",
      "13 -0.000166  2.475774    0.105531\n",
      "14  0.016819  2.793477    0.228821\n",
      "15  0.016712  1.002989   -0.257816\n",
      "16  0.015102  1.347859   -0.167633\n",
      "17  0.026823  1.302100   -0.154543\n",
      "18  0.026266  1.775108   -0.027258\n",
      "19  0.008740  1.725095   -0.079007\n",
      "20  0.006853  1.609687   -0.114467\n",
      "21  0.013062  1.859155   -0.033176\n",
      "22 -0.010921  1.924355   -0.067686\n",
      "23 -0.012693  2.474792    0.077988\n",
      "24 -0.008985  1.882621   -0.074808\n",
      "25 -0.015250  2.812247    0.164093\n",
      "26 -0.030744  1.776310   -0.151067\n",
      "27 -0.017694  1.235233   -0.269641\n",
      "28 -0.012134  2.837940    0.177858\n",
      "29 -0.018606  2.588100    0.095893\n",
      "30 -0.005774  1.227843   -0.245694\n",
      "31 -0.001453  1.651299   -0.121249\n",
      "32 -0.004169  2.448978    0.089534\n",
      "33 -0.020605  2.671125    0.114095\n",
      "34 -0.025902  2.649325    0.096640\n",
      "35 -0.023930  1.991147   -0.077867\n",
      "36 -0.023950  2.183373   -0.025691\n",
      "37 -0.013806  2.335157    0.037631\n",
      "38  0.001325  2.396592    0.087267\n",
      "39  0.007736  1.257213   -0.208298\n",
      "40  0.018383  2.124382    0.050460\n",
      "41  0.012612  1.985952    0.000288\n",
      "42  0.006844  2.351628    0.087068\n",
      "43  0.012028  2.219832    0.062554\n",
      "44  0.014571  1.487347   -0.130897\n",
      "45 -0.009806  1.948294   -0.058754\n",
      "0.10000000000000013\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n = 46                     # length of vector\n",
    "rho = 0.1                 # desired correlation = cos(angle)\n",
    "theta = np.arccos(rho)         # corresponding angle\n",
    "fixed_data = df['fwd_ret5']\n",
    "new_data = np.random.normal(2, 0.5, n)  # new random data\n",
    "\n",
    "fixed_data.reset_index(drop=True, inplace=True)  # Reset index of fixed_data\n",
    "new_data = pd.DataFrame(new_data, columns=['x2'])  # Convert new_data to a Series\n",
    "\n",
    "X = pd.concat([fixed_data, new_data], axis=1)  # dataframe with fixed and new data\n",
    "Xctr = X - X.mean()  # centered columns (mean 0)\n",
    "\n",
    "Q, _ = np.linalg.qr(Xctr[['fwd_ret5']].values)  # QR-decomposition, just matrix Q\n",
    "P = Q @ Q.T  # projection onto space defined by x1\n",
    "x2o = (np.eye(n) - P) @ Xctr['x2'].values  # x2ctr made orthogonal to x1ctr\n",
    "Xc2 = pd.concat([Xctr['fwd_ret5'], pd.Series(x2o, name='x2o')], axis=1)  # bind to dataframe\n",
    "Y = Xc2.div(np.sqrt(np.sum(Xc2**2, axis=0)), axis=1)  # scale columns to length 1\n",
    "\n",
    "x = Y['x2o'] + (1 / np.tan(theta)) * Y['fwd_ret5']  # final new vector\n",
    "\n",
    "df_with_new_column = pd.concat([X, pd.Series(x, name='new_column')], axis=1)  # dataframe with new column added\n",
    "print(df_with_new_column)\n",
    "print(np.corrcoef(df_with_new_column['fwd_ret5'], df_with_new_column['new_column'])[0, 1])  # check correlation = rho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10000000000000013"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_new_column['new_column'].corr(df_with_new_column['fwd_ret5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df, df_with_new_column], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('banknifty_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('df_final.csv')\n",
    "\n",
    "# Split the data into an 80-20 ratio\n",
    "train_data, x_data = train_test_split(data, train_size=0.7, shuffle=False)\n",
    "validate_data, test_data = train_test_split(x_data, train_size=0.5, shuffle=False)\n",
    "\n",
    "# Save the train and test data to separate CSV files\n",
    "train_data.to_csv('trainbase_data.csv', index=False)\n",
    "test_data.to_csv('testbase_data.csv', index=False)\n",
    "validate_data.to_csv('validation_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('validation_data.csv')\n",
    "\n",
    "# Select the desired columns\n",
    "selected_columns = df[['Open', 'ret', 'new_column']]\n",
    "\n",
    "# Save the selected columns to a new CSV file\n",
    "selected_columns.to_csv('validation_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import gymnasium\n",
    "from gymnasium import spaces\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, env_config):\n",
    "        super(TradingEnv, self).__init__()\n",
    "\n",
    "        data = pd.read_csv(env_config[\"data_filepath\"])\n",
    "        self.historical_data = data['Open']\n",
    "        self.returns = data['ret']\n",
    "        self.sma = data['new_column']\n",
    "        self.window_size = env_config[\"window_size\"]\n",
    "        self.unrealized_pnl_history = deque([0.0]*5, maxlen=5)\n",
    "\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(env_config[\"window_size\"], 3), dtype=np.float32)\n",
    "        \n",
    "        self.max_episode_steps = 20\n",
    "        np.random.seed(123)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        current_price = self.historical_data[self.current_step]\n",
    "        current_ret = 0\n",
    "        unrealized_pnl = 0\n",
    "        if action == 0:  # Buy\n",
    "            if self.position == 0:\n",
    "                self.position = 1\n",
    "                self.buy_price = current_price\n",
    "                #reward = 0\n",
    "            elif self.position == -1:\n",
    "                r = (self.sell_price - current_price)/self.sell_price\n",
    "                current_ret = np.log(1 + r)\n",
    "                self.position = 0\n",
    "            else:\n",
    "                unrealized_pnl = np.log(current_price/self.buy_price)\n",
    "        elif action == 1:  # Sell\n",
    "            if self.position == 0:\n",
    "                self.position = -1\n",
    "                self.sell_price = current_price\n",
    "                #reward = 0\n",
    "            elif self.position == 1:\n",
    "                current_ret = np.log(current_price/self.buy_price)\n",
    "                self.position = 0\n",
    "            else:\n",
    "                r = (self.sell_price - current_price)/self.sell_price\n",
    "                unrealized_pnl = np.log(1 + r)\n",
    "        else:  # Hold\n",
    "            if self.position == 1:\n",
    "                unrealized_pnl = np.log(current_price/self.buy_price)\n",
    "            elif self.position == -1:\n",
    "                r = (self.sell_price - current_price)/self.sell_price\n",
    "                unrealized_pnl = np.log(1 + r)\n",
    "            \n",
    "            #reward = unrealized_pnl\n",
    "        #reward = self.previous_reward\n",
    "        reward = current_ret\n",
    "        #if current_ret != 0 :\n",
    "            #self.cumulative_return *= (1 + current_ret)\n",
    "            #reward = self.cumulative_return - 1\n",
    "            #self.previous_reward = reward\n",
    "        \n",
    "        self.unrealized_pnl_history.append(unrealized_pnl)\n",
    "        unrealized_pnl_array = np.array(self.unrealized_pnl_history).reshape(-1, 1)\n",
    "        new_returns = self.returns.iloc[self.current_step-self.window_size + 1:self.current_step + 1].fillna(0).values\n",
    "        new_sma = self.sma.iloc[self.current_step-self.window_size + 1:self.current_step + 1].fillna(0).values\n",
    "        temp_state = np.array([new_returns, new_sma]).T\n",
    "        self.state = np.concatenate([temp_state, unrealized_pnl_array], axis=1)\n",
    "        self.current_step += 1\n",
    "        \n",
    "        done = False\n",
    "        if self.current_step >= len(self.historical_data) - 1:\n",
    "            done = True\n",
    "            #print(\"End of episode. State:\", self.state)\n",
    "\n",
    "        return np.array(self.state), reward, done, {}\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = self.window_size\n",
    "        self.position = 0\n",
    "        self.buy_price = 0\n",
    "        self.sell_price = 0\n",
    "        #self.cumulative_returns = 0\n",
    "        #self.cumulative_return = 1.0\n",
    "        #self.previous_reward = 0.0\n",
    "        self.unrealized_pnl_history = deque([0.0]*5, maxlen=5)\n",
    "        unrealized_pnl_array = np.array(self.unrealized_pnl_history).reshape(-1, 1)\n",
    "        self.current_step += np.random.randint(0, len(self.returns) - self.window_size - self.max_episode_steps )\n",
    "        initial_returns = self.returns.iloc[self.current_step - self.window_size + 1:self.current_step + 1].fillna(0).values\n",
    "        initial_sma = self.sma.iloc[self.current_step - self.window_size + 1:self.current_step + 1].fillna(0).values\n",
    "        temp_state = np.array([initial_returns, initial_sma]).T\n",
    "        self.state = np.concatenate([temp_state, unrealized_pnl_array], axis=1)\n",
    "        return np.array(self.state)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 03:00:16,446\tINFO worker.py:1636 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.6</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.5.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.9.6', ray_version='2.5.0', ray_commit='586c376e0769082cb5cfa1333e8264a5fa6b73ec', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-09-20_03-00-14_665120_30391/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-09-20_03-00-14_665120_30391/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-09-20_03-00-14_665120_30391', 'metrics_export_port': 62577, 'gcs_address': '127.0.0.1:63475', 'address': '127.0.0.1:63475', 'dashboard_agent_listen_port': 52365, 'node_id': '5004d5efedb1b766dca978fc933e2e6f9c7806f75650f4c08537cfa9'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.wrappers import EnvCompatibility\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "def create_compatible_trading_env(env_config):\n",
    "    env = TradingEnv(env_config)\n",
    "    return EnvCompatibility(env)\n",
    "\n",
    "register_env(\"wrapped_trading_env\", create_compatible_trading_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Construct the absolute paths of the data files\n",
    "train_data_path = os.path.join(cwd, 'train_file.csv')\n",
    "validation_data_path = os.path.join(cwd, 'validation_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune import Stopper\n",
    "\n",
    "class EarlyStoppingStopper(Stopper):\n",
    "    def __init__(self, patience, eval_patience, min_iterations, reward_weight=0.999, length_weight=0.001):\n",
    "        self.patience = patience\n",
    "        self.eval_patience = eval_patience\n",
    "        self.reward_weight = reward_weight\n",
    "        self.length_weight = length_weight\n",
    "        self.min_iterations = min_iterations\n",
    "        self.best_trial = None\n",
    "        self.best_train_score = -float('inf')\n",
    "        self.best_eval_score = -float('inf')\n",
    "        self.strikes = 0\n",
    "        self.eval_strikes = 0\n",
    "\n",
    "    def __call__(self, trial_id, result):\n",
    "\n",
    "        if result['training_iteration'] < self.min_iterations:\n",
    "            return False\n",
    "\n",
    "        # Calculate a score that is a weighted sum of the mean reward and the episode length\n",
    "        train_score =  (result['episode_reward_mean'] )/ (result['episode_len_mean'])\n",
    "        #eval_score = result['evaluation/episode_reward_mean'] \n",
    "\n",
    "        # If this is the best trial so far in terms of training score, update the best score and reset the strike counter\n",
    "        if self.best_trial is None or train_score > self.best_train_score:\n",
    "            self.best_trial = trial_id\n",
    "            self.best_train_score = train_score\n",
    "            self.strikes = 0\n",
    "\n",
    "        # If this trial's training score is less than the best seen so far, increment the strike counter\n",
    "        elif trial_id == self.best_trial:\n",
    "            self.strikes += 1\n",
    "\n",
    "        # If the evaluation score is improving, reset the evaluation strike counter\n",
    "        if 'evaluation/episode_reward_mean' in result and (self.best_trial is None or ((result['evaluation/episode_reward_mean']) / (result['evaluation/episode_len_mean'])) > self.best_eval_reward):\n",
    "            self.best_eval_reward = ((result['evaluation/episode_reward_mean']) / (result['evaluation/episode_len_mean']))\n",
    "            self.eval_strikes = 0\n",
    "\n",
    "        # If this trial's evaluation score is less than the best seen so far, increment the evaluation strike counter\n",
    "        elif 'evaluation/episode_reward_mean' in result and trial_id == self.best_trial:\n",
    "            self.eval_strikes += 1\n",
    "\n",
    "        # Stop if we've had `patience` iterations without improvement in training score\n",
    "        # or if we've had `eval_patience` iterations without improvement in evaluation score\n",
    "        return self.strikes >= self.patience or self.eval_strikes >= self.eval_patience\n",
    "\n",
    "    def stop_all(self):\n",
    "        return self.strikes >= self.patience or self.eval_strikes >= self.eval_patience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-09-19 20:50:46</td></tr>\n",
       "<tr><td>Running for: </td><td>01:23:20.57        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.5/8.0 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      PopulationBasedTraining: 138 checkpoints, 93 perturbs<br>Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_wrapped_trading_env_76be2_00000</td><td>TERMINATED</td><td>127.0.0.1:27645</td><td style=\"text-align: right;\">            43</td><td style=\"text-align: right;\">  6120</td><td style=\"text-align: right;\">         1215.83</td><td style=\"text-align: right;\">177480</td><td style=\"text-align: right;\">0.18248 </td><td style=\"text-align: right;\">            0.286494</td><td style=\"text-align: right;\">           0.0982098</td><td style=\"text-align: right;\">           98.4   </td></tr>\n",
       "<tr><td>PPO_wrapped_trading_env_76be2_00001</td><td>TERMINATED</td><td>127.0.0.1:27638</td><td style=\"text-align: right;\">            43</td><td style=\"text-align: right;\">  6097</td><td style=\"text-align: right;\">         1211.55</td><td style=\"text-align: right;\">176813</td><td style=\"text-align: right;\">0.140684</td><td style=\"text-align: right;\">            0.284793</td><td style=\"text-align: right;\">          -0.0277575</td><td style=\"text-align: right;\">           81.9412</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPO pid=24675)\u001b[0m 2023-09-19 19:27:27,923\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24676)\u001b[0m 2023-09-19 19:27:29,856\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24675)\u001b[0m 2023-09-19 19:27:31,602\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24687)\u001b[0m 2023-09-19 19:27:46,245\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24679)\u001b[0m 2023-09-19 19:27:46,245\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24688)\u001b[0m 2023-09-19 19:27:48,138\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24687)\u001b[0m 2023-09-19 19:27:50,082\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "2023-09-19 19:28:01,184\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=24722)\u001b[0m 2023-09-19 19:28:03,765\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24692)\u001b[0m 2023-09-19 19:28:03,765\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24723)\u001b[0m 2023-09-19 19:28:05,562\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24722)\u001b[0m 2023-09-19 19:28:07,313\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24722)\u001b[0m 2023-09-19 19:28:07,341\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_e048f82a416d4de3921e7d6feeb767a3\n",
      "\u001b[2m\u001b[36m(PPO pid=24722)\u001b[0m 2023-09-19 19:28:07,341\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 58, '_timesteps_total': None, '_time_total': 10.095865488052368, '_episodes_total': 20}\n",
      "2023-09-19 19:28:18,848\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=24731)\u001b[0m 2023-09-19 19:28:21,306\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24726)\u001b[0m 2023-09-19 19:28:21,306\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24733)\u001b[0m 2023-09-19 19:28:23,154\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24731)\u001b[0m 2023-09-19 19:28:24,838\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24731)\u001b[0m 2023-09-19 19:28:24,871\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_1c25534b83a94b2cac75fa99e91665ec\n",
      "\u001b[2m\u001b[36m(PPO pid=24731)\u001b[0m 2023-09-19 19:28:24,871\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 36, '_timesteps_total': None, '_time_total': 10.196551322937012, '_episodes_total': 8}\n",
      "\u001b[2m\u001b[36m(PPO pid=24744)\u001b[0m 2023-09-19 19:28:38,189\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24736)\u001b[0m 2023-09-19 19:28:38,189\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24745)\u001b[0m 2023-09-19 19:28:39,962\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24776)\u001b[0m 2023-09-19 19:28:56,220\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24750)\u001b[0m 2023-09-19 19:28:56,220\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24777)\u001b[0m 2023-09-19 19:28:58,010\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24776)\u001b[0m 2023-09-19 19:28:59,747\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24776)\u001b[0m 2023-09-19 19:28:59,773\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_e3ba521180a648969d060d309ff1edd3\n",
      "\u001b[2m\u001b[36m(PPO pid=24776)\u001b[0m 2023-09-19 19:28:59,773\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 70, '_timesteps_total': None, '_time_total': 20.355578422546387, '_episodes_total': 16}\n",
      "2023-09-19 19:29:10,364\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.044993) into trial 76be2_00001 (score = 0.000000)\n",
      "\n",
      "2023-09-19 19:29:10,365\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.0003 --- (* 0.8) --> 0.00023999999999999998\n",
      "gamma : 0.99 --- (* 1.2) --> 1.188\n",
      "clip_param : 0.2 --- (* 0.8) --> 0.16000000000000003\n",
      "kl_coeff : 0.5 --- (* 0.8) --> 0.4\n",
      "\n",
      "2023-09-19 19:29:10,367\tWARNING trial_runner.py:1592 -- You are trying to access pause_trial interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "\u001b[2m\u001b[36m(PPO pid=24781)\u001b[0m 2023-09-19 19:29:13,460\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24780)\u001b[0m 2023-09-19 19:29:13,460\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24784)\u001b[0m 2023-09-19 19:29:15,325\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24797)\u001b[0m 2023-09-19 19:29:31,333\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24787)\u001b[0m 2023-09-19 19:29:31,333\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24798)\u001b[0m 2023-09-19 19:29:33,139\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24797)\u001b[0m 2023-09-19 19:29:34,814\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24797)\u001b[0m 2023-09-19 19:29:34,839\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_5d04321f0afa4352a038ee053c994c93\n",
      "\u001b[2m\u001b[36m(PPO pid=24797)\u001b[0m 2023-09-19 19:29:34,839\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 159, '_timesteps_total': None, '_time_total': 30.35173511505127, '_episodes_total': 52}\n",
      "2023-09-19 19:29:46,043\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.092249) into trial 76be2_00001 (score = 0.055733)\n",
      "\n",
      "2023-09-19 19:29:46,044\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.0003 --- (* 1.2) --> 0.00035999999999999997\n",
      "gamma : 0.99 --- (resample) --> 0.9606851988230908\n",
      "clip_param : 0.2 --- (* 0.8) --> 0.16000000000000003\n",
      "kl_coeff : 0.5 --- (* 0.8) --> 0.4\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=24808)\u001b[0m 2023-09-19 19:29:49,342\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24801)\u001b[0m 2023-09-19 19:29:49,342\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24810)\u001b[0m 2023-09-19 19:29:51,099\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24808)\u001b[0m 2023-09-19 19:29:52,901\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24808)\u001b[0m 2023-09-19 19:29:52,926\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_a50ee362211a4876bb7b02945a54e59f\n",
      "\u001b[2m\u001b[36m(PPO pid=24808)\u001b[0m 2023-09-19 19:29:52,926\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 209, '_timesteps_total': None, '_time_total': 40.37824845314026, '_episodes_total': 69}\n",
      "\u001b[2m\u001b[36m(PPO pid=24819)\u001b[0m 2023-09-19 19:30:07,441\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24814)\u001b[0m 2023-09-19 19:30:07,441\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24820)\u001b[0m 2023-09-19 19:30:09,227\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24819)\u001b[0m 2023-09-19 19:30:10,961\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24819)\u001b[0m 2023-09-19 19:30:10,988\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_3bd6e256ca1147dc958ff6b2797d94a2\n",
      "\u001b[2m\u001b[36m(PPO pid=24819)\u001b[0m 2023-09-19 19:30:10,988\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 209, '_timesteps_total': None, '_time_total': 40.37824845314026, '_episodes_total': 69}\n",
      "\u001b[2m\u001b[36m(PPO pid=24837)\u001b[0m 2023-09-19 19:30:25,426\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24823)\u001b[0m 2023-09-19 19:30:25,426\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24838)\u001b[0m 2023-09-19 19:30:27,288\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24837)\u001b[0m 2023-09-19 19:30:29,024\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24837)\u001b[0m 2023-09-19 19:30:29,058\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d815e55a24464e50bdce0bce5bb3e600\n",
      "\u001b[2m\u001b[36m(PPO pid=24837)\u001b[0m 2023-09-19 19:30:29,058\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 262, '_timesteps_total': None, '_time_total': 50.64799523353577, '_episodes_total': 86}\n",
      "2023-09-19 19:30:40,384\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.092761) into trial 76be2_00000 (score = 0.063424)\n",
      "\n",
      "2023-09-19 19:30:40,385\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00035999999999999997 --- (* 0.8) --> 0.000288\n",
      "gamma : 0.9606851988230908 --- (* 1.2) --> 1.152822238587709\n",
      "clip_param : 0.16000000000000003 --- (resample) --> 0.23171446598118772\n",
      "kl_coeff : 0.4 --- (* 0.8) --> 0.32000000000000006\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=24848)\u001b[0m 2023-09-19 19:30:43,476\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24841)\u001b[0m 2023-09-19 19:30:43,476\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24849)\u001b[0m 2023-09-19 19:30:45,375\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24848)\u001b[0m 2023-09-19 19:30:47,089\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24848)\u001b[0m 2023-09-19 19:30:47,117\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ef143064015a4a44b9e1ba6ec5af7b6e\n",
      "\u001b[2m\u001b[36m(PPO pid=24848)\u001b[0m 2023-09-19 19:30:47,117\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 258, '_timesteps_total': None, '_time_total': 50.463414669036865, '_episodes_total': 84}\n",
      "\u001b[2m\u001b[36m(PPO pid=24858)\u001b[0m 2023-09-19 19:31:01,485\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24852)\u001b[0m 2023-09-19 19:31:01,485\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24859)\u001b[0m 2023-09-19 19:31:03,340\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24858)\u001b[0m 2023-09-19 19:31:05,066\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24858)\u001b[0m 2023-09-19 19:31:05,097\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_7162a01b673148faa19ecc67bfcb8a87\n",
      "\u001b[2m\u001b[36m(PPO pid=24858)\u001b[0m 2023-09-19 19:31:05,097\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 258, '_timesteps_total': None, '_time_total': 50.463414669036865, '_episodes_total': 84}\n",
      "2023-09-19 19:31:16,403\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.126340) into trial 76be2_00000 (score = 0.116209)\n",
      "\n",
      "2023-09-19 19:31:16,405\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00035999999999999997 --- (* 1.2) --> 0.00043199999999999993\n",
      "gamma : 0.9606851988230908 --- (resample) --> 0.9659179318178129\n",
      "clip_param : 0.16000000000000003 --- (* 0.8) --> 0.12800000000000003\n",
      "kl_coeff : 0.4 --- (* 0.8) --> 0.32000000000000006\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=24864)\u001b[0m 2023-09-19 19:31:19,588\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24862)\u001b[0m 2023-09-19 19:31:19,588\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24868)\u001b[0m 2023-09-19 19:31:21,449\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24864)\u001b[0m 2023-09-19 19:31:23,353\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24864)\u001b[0m 2023-09-19 19:31:23,406\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_afd1238cdc354c54835091ca6d965df1\n",
      "\u001b[2m\u001b[36m(PPO pid=24864)\u001b[0m 2023-09-19 19:31:23,407\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 310, '_timesteps_total': None, '_time_total': 60.63133478164673, '_episodes_total': 101}\n",
      "\u001b[2m\u001b[36m(PPO pid=24877)\u001b[0m 2023-09-19 19:31:37,505\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24871)\u001b[0m 2023-09-19 19:31:37,505\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24878)\u001b[0m 2023-09-19 19:31:39,410\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24877)\u001b[0m 2023-09-19 19:31:41,173\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24877)\u001b[0m 2023-09-19 19:31:41,200\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d7ced241b23548c88794b168458472f9\n",
      "\u001b[2m\u001b[36m(PPO pid=24877)\u001b[0m 2023-09-19 19:31:41,200\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 310, '_timesteps_total': None, '_time_total': 60.63133478164673, '_episodes_total': 101}\n",
      "2023-09-19 19:31:52,359\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.137075) into trial 76be2_00000 (score = 0.116864)\n",
      "\n",
      "2023-09-19 19:31:52,361\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00035999999999999997 --- (resample) --> 0.00030175561763372987\n",
      "gamma : 0.9606851988230908 --- (* 0.8) --> 0.7685481590584726\n",
      "clip_param : 0.16000000000000003 --- (resample) --> 0.2693230591525607\n",
      "kl_coeff : 0.4 --- (resample) --> 1.0239956596158448\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=24886)\u001b[0m 2023-09-19 19:31:54,540\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24881)\u001b[0m 2023-09-19 19:31:54,540\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24889)\u001b[0m 2023-09-19 19:31:56,688\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24886)\u001b[0m 2023-09-19 19:31:58,456\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24886)\u001b[0m 2023-09-19 19:31:58,518\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_1c30791aa189475890afe3f69270f66a\n",
      "\u001b[2m\u001b[36m(PPO pid=24886)\u001b[0m 2023-09-19 19:31:58,518\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 361, '_timesteps_total': None, '_time_total': 70.76585054397583, '_episodes_total': 118}\n",
      "2023-09-19 19:32:09,653\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=24903)\u001b[0m 2023-09-19 19:32:12,596\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24892)\u001b[0m 2023-09-19 19:32:12,596\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24905)\u001b[0m 2023-09-19 19:32:14,419\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24903)\u001b[0m 2023-09-19 19:32:16,172\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24903)\u001b[0m 2023-09-19 19:32:16,200\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_2219e4cdc0e842a888ee93f32993f7f3\n",
      "\u001b[2m\u001b[36m(PPO pid=24903)\u001b[0m 2023-09-19 19:32:16,200\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 361, '_timesteps_total': None, '_time_total': 70.76585054397583, '_episodes_total': 118}\n",
      "\u001b[2m\u001b[36m(PPO pid=24912)\u001b[0m 2023-09-19 19:32:30,515\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24908)\u001b[0m 2023-09-19 19:32:30,515\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24913)\u001b[0m 2023-09-19 19:32:32,400\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "2023-09-19 19:32:45,559\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.124122) into trial 76be2_00001 (score = 0.111609)\n",
      "\n",
      "2023-09-19 19:32:45,560\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00030175561763372987 --- (* 0.8) --> 0.00024140449410698392\n",
      "gamma : 0.7685481590584726 --- (* 1.2) --> 0.9222577908701671\n",
      "clip_param : 0.2693230591525607 --- (resample) --> 0.11031749112248589\n",
      "kl_coeff : 1.0239956596158448 --- (* 0.8) --> 0.8191965276926759\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=24920)\u001b[0m 2023-09-19 19:32:48,565\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24916)\u001b[0m 2023-09-19 19:32:48,565\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24923)\u001b[0m 2023-09-19 19:32:50,348\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24920)\u001b[0m 2023-09-19 19:32:52,238\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24920)\u001b[0m 2023-09-19 19:32:52,279\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_a83ea83cf9574509a506a4618317d979\n",
      "\u001b[2m\u001b[36m(PPO pid=24920)\u001b[0m 2023-09-19 19:32:52,279\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 413, '_timesteps_total': None, '_time_total': 80.88830900192261, '_episodes_total': 135}\n",
      "\u001b[2m\u001b[36m(PPO pid=24929)\u001b[0m 2023-09-19 19:33:06,429\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24926)\u001b[0m 2023-09-19 19:33:06,429\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24930)\u001b[0m 2023-09-19 19:33:08,311\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24929)\u001b[0m 2023-09-19 19:33:10,033\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24929)\u001b[0m 2023-09-19 19:33:10,060\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_781dfb4e62934c088b9d012c96f18576\n",
      "\u001b[2m\u001b[36m(PPO pid=24929)\u001b[0m 2023-09-19 19:33:10,060\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 413, '_timesteps_total': None, '_time_total': 80.88830900192261, '_episodes_total': 135}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24936)\u001b[0m 2023-09-19 19:33:26,488\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24935)\u001b[0m 2023-09-19 19:33:28,275\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24935)\u001b[0m 2023-09-19 19:33:28,312\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_e215302b9d924734a764858086c8aaf9\n",
      "\u001b[2m\u001b[36m(PPO pid=24935)\u001b[0m 2023-09-19 19:33:28,312\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 465, '_timesteps_total': None, '_time_total': 91.00186014175415, '_episodes_total': 152}\n",
      "2023-09-19 19:33:39,529\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.146128) into trial 76be2_00000 (score = 0.123219)\n",
      "\n",
      "2023-09-19 19:33:39,529\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00024140449410698392 --- (* 0.8) --> 0.00019312359528558714\n",
      "gamma : 0.9222577908701671 --- (resample) --> 0.9833904602884944\n",
      "clip_param : 0.11031749112248589 --- (* 1.2) --> 0.13238098934698306\n",
      "kl_coeff : 0.8191965276926759 --- (* 0.8) --> 0.6553572221541408\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=24941)\u001b[0m 2023-09-19 19:33:42,577\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24939)\u001b[0m 2023-09-19 19:33:42,577\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24944)\u001b[0m 2023-09-19 19:33:44,472\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24941)\u001b[0m 2023-09-19 19:33:46,265\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24941)\u001b[0m 2023-09-19 19:33:46,299\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_1997f877fcd440e581bb53e00311b318\n",
      "\u001b[2m\u001b[36m(PPO pid=24941)\u001b[0m 2023-09-19 19:33:46,299\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 466, '_timesteps_total': None, '_time_total': 91.01331043243408, '_episodes_total': 152}\n",
      "\u001b[2m\u001b[36m(PPO pid=24964)\u001b[0m 2023-09-19 19:34:00,689\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24947)\u001b[0m 2023-09-19 19:34:00,689\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24966)\u001b[0m 2023-09-19 19:34:02,599\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24964)\u001b[0m 2023-09-19 19:34:04,385\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24964)\u001b[0m 2023-09-19 19:34:04,432\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_6588db1db5b548abbe7c0bf74209bf73\n",
      "\u001b[2m\u001b[36m(PPO pid=24964)\u001b[0m 2023-09-19 19:34:04,432\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 466, '_timesteps_total': None, '_time_total': 91.01331043243408, '_episodes_total': 152}\n",
      "2023-09-19 19:34:15,539\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.149138) into trial 76be2_00000 (score = 0.128065)\n",
      "\n",
      "2023-09-19 19:34:15,539\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00024140449410698392 --- (* 0.8) --> 0.00019312359528558714\n",
      "gamma : 0.9222577908701671 --- (resample) --> 0.9687720392896703\n",
      "clip_param : 0.11031749112248589 --- (* 0.8) --> 0.08825399289798871\n",
      "kl_coeff : 0.8191965276926759 --- (* 0.8) --> 0.6553572221541408\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=24982)\u001b[0m 2023-09-19 19:34:18,790\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24969)\u001b[0m 2023-09-19 19:34:18,790\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24987)\u001b[0m 2023-09-19 19:34:20,713\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=24982)\u001b[0m 2023-09-19 19:34:22,580\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=24982)\u001b[0m 2023-09-19 19:34:22,637\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_853e6fd17cd946b4a16b6858b0c32bc8\n",
      "\u001b[2m\u001b[36m(PPO pid=24982)\u001b[0m 2023-09-19 19:34:22,638\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 517, '_timesteps_total': None, '_time_total': 101.09779500961304, '_episodes_total': 169}\n",
      "\u001b[2m\u001b[36m(PPO pid=24998)\u001b[0m 2023-09-19 19:34:36,622\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24990)\u001b[0m 2023-09-19 19:34:36,622\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24999)\u001b[0m 2023-09-19 19:34:38,643\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25005)\u001b[0m 2023-09-19 19:34:54,728\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25002)\u001b[0m 2023-09-19 19:34:54,728\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25007)\u001b[0m 2023-09-19 19:34:56,706\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25005)\u001b[0m 2023-09-19 19:34:58,526\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25005)\u001b[0m 2023-09-19 19:34:58,578\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_18eac5f71ccb4a95b412201f16ee28ce\n",
      "\u001b[2m\u001b[36m(PPO pid=25005)\u001b[0m 2023-09-19 19:34:58,578\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 567, '_timesteps_total': None, '_time_total': 111.11579942703247, '_episodes_total': 186}\n",
      "2023-09-19 19:35:09,864\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.149457) into trial 76be2_00001 (score = 0.121839)\n",
      "\n",
      "2023-09-19 19:35:09,865\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00019312359528558714 --- (resample) --> 0.00022386551267047537\n",
      "gamma : 0.9687720392896703 --- (* 1.2) --> 1.1625264471476042\n",
      "clip_param : 0.08825399289798871 --- (* 1.2) --> 0.10590479147758645\n",
      "kl_coeff : 0.6553572221541408 --- (resample) --> 1.2443816579218787\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25026)\u001b[0m 2023-09-19 19:35:12,668\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25022)\u001b[0m 2023-09-19 19:35:12,668\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25029)\u001b[0m 2023-09-19 19:35:14,598\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25026)\u001b[0m 2023-09-19 19:35:16,313\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25026)\u001b[0m 2023-09-19 19:35:16,351\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_112aead20bbe48759ee304bd05d98353\n",
      "\u001b[2m\u001b[36m(PPO pid=25026)\u001b[0m 2023-09-19 19:35:16,351\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 569, '_timesteps_total': None, '_time_total': 111.27877902984619, '_episodes_total': 186}\n",
      "\u001b[2m\u001b[36m(PPO pid=25041)\u001b[0m 2023-09-19 19:35:30,725\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25032)\u001b[0m 2023-09-19 19:35:30,725\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25042)\u001b[0m 2023-09-19 19:35:32,670\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25041)\u001b[0m 2023-09-19 19:35:34,407\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25041)\u001b[0m 2023-09-19 19:35:34,434\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c630545485224d2d9293621763a76327\n",
      "\u001b[2m\u001b[36m(PPO pid=25041)\u001b[0m 2023-09-19 19:35:34,434\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 569, '_timesteps_total': None, '_time_total': 111.27877902984619, '_episodes_total': 186}\n",
      "2023-09-19 19:35:45,776\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.130635) into trial 76be2_00001 (score = 0.126659)\n",
      "\n",
      "2023-09-19 19:35:45,776\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00019312359528558714 --- (* 0.8) --> 0.00015449887622846973\n",
      "gamma : 0.9687720392896703 --- (* 1.2) --> 1.1625264471476042\n",
      "clip_param : 0.08825399289798871 --- (resample) --> 0.23807761091964488\n",
      "kl_coeff : 0.6553572221541408 --- (* 0.8) --> 0.5242857777233126\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25047)\u001b[0m 2023-09-19 19:35:48,685\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25045)\u001b[0m 2023-09-19 19:35:48,685\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25050)\u001b[0m 2023-09-19 19:35:50,610\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25047)\u001b[0m 2023-09-19 19:35:52,396\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25047)\u001b[0m 2023-09-19 19:35:52,429\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_8ea7d63328e64a51a11b30ce66787012\n",
      "\u001b[2m\u001b[36m(PPO pid=25047)\u001b[0m 2023-09-19 19:35:52,429\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 620, '_timesteps_total': None, '_time_total': 121.41863965988159, '_episodes_total': 203}\n",
      "\u001b[2m\u001b[36m(PPO pid=25055)\u001b[0m 2023-09-19 19:36:06,680\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25053)\u001b[0m 2023-09-19 19:36:06,680\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25056)\u001b[0m 2023-09-19 19:36:08,564\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25055)\u001b[0m 2023-09-19 19:36:10,361\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25055)\u001b[0m 2023-09-19 19:36:10,401\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c987aaec53e846e8a89f5cfd9a8dcc9f\n",
      "\u001b[2m\u001b[36m(PPO pid=25055)\u001b[0m 2023-09-19 19:36:10,401\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 620, '_timesteps_total': None, '_time_total': 121.41863965988159, '_episodes_total': 203}\n",
      "\u001b[2m\u001b[36m(PPO pid=25061)\u001b[0m 2023-09-19 19:36:24,710\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25059)\u001b[0m 2023-09-19 19:36:24,710\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25062)\u001b[0m 2023-09-19 19:36:26,751\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25061)\u001b[0m 2023-09-19 19:36:28,486\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25061)\u001b[0m 2023-09-19 19:36:28,521\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_25fcb5b9ce834d6cb43b88cc77be4b8b\n",
      "\u001b[2m\u001b[36m(PPO pid=25061)\u001b[0m 2023-09-19 19:36:28,521\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 672, '_timesteps_total': None, '_time_total': 131.48552322387695, '_episodes_total': 220}\n",
      "2023-09-19 19:36:39,816\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.144388) into trial 76be2_00000 (score = 0.124589)\n",
      "\n",
      "2023-09-19 19:36:39,816\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00015449887622846973 --- (* 1.2) --> 0.00018539865147416368\n",
      "gamma : 1.1625264471476042 --- (resample) --> 0.9573637541966249\n",
      "clip_param : 0.23807761091964488 --- (* 1.2) --> 0.28569313310357386\n",
      "kl_coeff : 0.5242857777233126 --- (* 0.8) --> 0.4194286221786501\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25069)\u001b[0m 2023-09-19 19:36:42,698\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25065)\u001b[0m 2023-09-19 19:36:42,698\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25070)\u001b[0m 2023-09-19 19:36:44,747\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25075)\u001b[0m 2023-09-19 19:37:00,781\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25073)\u001b[0m 2023-09-19 19:37:00,781\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25076)\u001b[0m 2023-09-19 19:37:02,911\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25075)\u001b[0m 2023-09-19 19:37:04,826\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25075)\u001b[0m 2023-09-19 19:37:04,858\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_e4bd9cd319fb403fb120d98d7972b915\n",
      "\u001b[2m\u001b[36m(PPO pid=25075)\u001b[0m 2023-09-19 19:37:04,858\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 672, '_timesteps_total': None, '_time_total': 131.55283856391907, '_episodes_total': 220}\n",
      "2023-09-19 19:37:16,104\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.142166) into trial 76be2_00000 (score = 0.129914)\n",
      "\n",
      "2023-09-19 19:37:16,105\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00015449887622846973 --- (* 0.8) --> 0.00012359910098277578\n",
      "gamma : 1.1625264471476042 --- (resample) --> 0.9519961952899102\n",
      "clip_param : 0.23807761091964488 --- (* 1.2) --> 0.28569313310357386\n",
      "kl_coeff : 0.5242857777233126 --- (* 1.2) --> 0.6291429332679751\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25082)\u001b[0m 2023-09-19 19:37:18,734\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25080)\u001b[0m 2023-09-19 19:37:18,734\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25083)\u001b[0m 2023-09-19 19:37:20,693\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25082)\u001b[0m 2023-09-19 19:37:22,579\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25082)\u001b[0m 2023-09-19 19:37:22,610\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_539c5240a87845f8937da99cc97310b0\n",
      "\u001b[2m\u001b[36m(PPO pid=25082)\u001b[0m 2023-09-19 19:37:22,610\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 722, '_timesteps_total': None, '_time_total': 141.65308928489685, '_episodes_total': 237}\n",
      "\u001b[2m\u001b[36m(PPO pid=25097)\u001b[0m 2023-09-19 19:37:36,882\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25086)\u001b[0m 2023-09-19 19:37:36,882\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25098)\u001b[0m 2023-09-19 19:37:38,844\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25097)\u001b[0m 2023-09-19 19:37:40,582\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25097)\u001b[0m 2023-09-19 19:37:40,622\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_7c5d2a2a6423495397ed5484a210a3cd\n",
      "\u001b[2m\u001b[36m(PPO pid=25097)\u001b[0m 2023-09-19 19:37:40,622\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 722, '_timesteps_total': None, '_time_total': 141.65308928489685, '_episodes_total': 237}\n",
      "2023-09-19 19:37:51,773\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.134207) into trial 76be2_00000 (score = 0.122528)\n",
      "\n",
      "2023-09-19 19:37:51,773\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00015449887622846973 --- (* 1.2) --> 0.00018539865147416368\n",
      "gamma : 1.1625264471476042 --- (* 1.2) --> 1.395031736577125\n",
      "clip_param : 0.23807761091964488 --- (* 0.8) --> 0.1904620887357159\n",
      "kl_coeff : 0.5242857777233126 --- (resample) --> 0.3142548239245667\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25105)\u001b[0m 2023-09-19 19:37:54,788\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25101)\u001b[0m 2023-09-19 19:37:54,788\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25108)\u001b[0m 2023-09-19 19:37:56,892\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25105)\u001b[0m 2023-09-19 19:37:58,756\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25105)\u001b[0m 2023-09-19 19:37:58,812\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_b10fbe63d62d42dfa6accce1dda297d4\n",
      "\u001b[2m\u001b[36m(PPO pid=25105)\u001b[0m 2023-09-19 19:37:58,813\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 772, '_timesteps_total': None, '_time_total': 151.65406107902527, '_episodes_total': 254}\n",
      "\u001b[2m\u001b[36m(PPO pid=25115)\u001b[0m 2023-09-19 19:38:12,940\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25111)\u001b[0m 2023-09-19 19:38:12,940\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25116)\u001b[0m 2023-09-19 19:38:15,127\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25115)\u001b[0m 2023-09-19 19:38:17,020\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25115)\u001b[0m 2023-09-19 19:38:17,072\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d3cd2311f45f4bcbb6fee3a5d8132eec\n",
      "\u001b[2m\u001b[36m(PPO pid=25115)\u001b[0m 2023-09-19 19:38:17,072\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 772, '_timesteps_total': None, '_time_total': 151.65406107902527, '_episodes_total': 254}\n",
      "2023-09-19 19:38:28,358\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.129797) into trial 76be2_00000 (score = 0.107987)\n",
      "\n",
      "2023-09-19 19:38:28,359\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00015449887622846973 --- (resample) --> 0.0005863107868421772\n",
      "gamma : 1.1625264471476042 --- (* 1.2) --> 1.395031736577125\n",
      "clip_param : 0.23807761091964488 --- (* 0.8) --> 0.1904620887357159\n",
      "kl_coeff : 0.5242857777233126 --- (* 1.2) --> 0.6291429332679751\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25132)\u001b[0m 2023-09-19 19:38:31,879\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25120)\u001b[0m 2023-09-19 19:38:31,879\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25135)\u001b[0m 2023-09-19 19:38:33,811\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25132)\u001b[0m 2023-09-19 19:38:35,813\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25132)\u001b[0m 2023-09-19 19:38:35,883\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_fd78074c58cc44d9a4d610b069073606\n",
      "\u001b[2m\u001b[36m(PPO pid=25132)\u001b[0m 2023-09-19 19:38:35,883\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 820, '_timesteps_total': None, '_time_total': 161.66143894195557, '_episodes_total': 269}\n",
      "\u001b[2m\u001b[36m(PPO pid=25141)\u001b[0m 2023-09-19 19:38:50,010\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25138)\u001b[0m 2023-09-19 19:38:50,010\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25142)\u001b[0m 2023-09-19 19:38:52,109\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25141)\u001b[0m 2023-09-19 19:38:53,993\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25141)\u001b[0m 2023-09-19 19:38:54,040\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_49cccbb6f057475e9d032ec10295be68\n",
      "\u001b[2m\u001b[36m(PPO pid=25141)\u001b[0m 2023-09-19 19:38:54,040\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 820, '_timesteps_total': None, '_time_total': 161.66143894195557, '_episodes_total': 269}\n",
      "2023-09-19 19:39:05,229\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.126878) into trial 76be2_00000 (score = 0.098259)\n",
      "\n",
      "2023-09-19 19:39:05,229\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00015449887622846973 --- (resample) --> 0.00010389511375471438\n",
      "gamma : 1.1625264471476042 --- (resample) --> 0.955978809382184\n",
      "clip_param : 0.23807761091964488 --- (* 0.8) --> 0.1904620887357159\n",
      "kl_coeff : 0.5242857777233126 --- (resample) --> 1.3045342825984199\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25154)\u001b[0m 2023-09-19 19:39:08,872\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25145)\u001b[0m 2023-09-19 19:39:08,872\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25155)\u001b[0m 2023-09-19 19:39:10,796\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25154)\u001b[0m 2023-09-19 19:39:12,537\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25154)\u001b[0m 2023-09-19 19:39:12,563\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ff955395a2a34714aeda1439e10bdbc3\n",
      "\u001b[2m\u001b[36m(PPO pid=25154)\u001b[0m 2023-09-19 19:39:12,563\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 868, '_timesteps_total': None, '_time_total': 171.688138961792, '_episodes_total': 284}\n",
      "\u001b[2m\u001b[36m(PPO pid=25161)\u001b[0m 2023-09-19 19:39:26,597\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25158)\u001b[0m 2023-09-19 19:39:26,597\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=25161)\u001b[0m 2023-09-19 19:39:30,231\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25161)\u001b[0m 2023-09-19 19:39:30,260\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_785badf52a99496094a2ada366ee159b\n",
      "\u001b[2m\u001b[36m(PPO pid=25161)\u001b[0m 2023-09-19 19:39:30,260\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 868, '_timesteps_total': None, '_time_total': 171.688138961792, '_episodes_total': 284}\n",
      "2023-09-19 19:39:41,486\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.138848) into trial 76be2_00000 (score = 0.123110)\n",
      "\n",
      "2023-09-19 19:39:41,486\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00015449887622846973 --- (* 0.8) --> 0.00012359910098277578\n",
      "gamma : 1.1625264471476042 --- (resample) --> 0.9603425372395339\n",
      "clip_param : 0.23807761091964488 --- (* 1.2) --> 0.28569313310357386\n",
      "kl_coeff : 0.5242857777233126 --- (* 1.2) --> 0.6291429332679751\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25169)\u001b[0m 2023-09-19 19:39:44,821\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25165)\u001b[0m 2023-09-19 19:39:44,821\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25170)\u001b[0m 2023-09-19 19:39:46,747\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25169)\u001b[0m 2023-09-19 19:39:48,442\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25169)\u001b[0m 2023-09-19 19:39:48,467\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_e66f15f4eb2449be84579fdcdd3b8d6a\n",
      "\u001b[2m\u001b[36m(PPO pid=25169)\u001b[0m 2023-09-19 19:39:48,467\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 920, '_timesteps_total': None, '_time_total': 181.84860682487488, '_episodes_total': 301}\n",
      "2023-09-19 19:39:59,735\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=25178)\u001b[0m 2023-09-19 19:40:02,909\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25173)\u001b[0m 2023-09-19 19:40:02,909\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25179)\u001b[0m 2023-09-19 19:40:04,810\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25178)\u001b[0m 2023-09-19 19:40:06,498\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25178)\u001b[0m 2023-09-19 19:40:06,524\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_f2ee862dcc5a43129afd7040cad9105a\n",
      "\u001b[2m\u001b[36m(PPO pid=25178)\u001b[0m 2023-09-19 19:40:06,525\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 920, '_timesteps_total': None, '_time_total': 181.84860682487488, '_episodes_total': 301}\n",
      "2023-09-19 19:40:17,681\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=25191)\u001b[0m 2023-09-19 19:40:20,952\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25182)\u001b[0m 2023-09-19 19:40:20,952\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25192)\u001b[0m 2023-09-19 19:40:22,788\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25191)\u001b[0m 2023-09-19 19:40:24,615\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25191)\u001b[0m 2023-09-19 19:40:24,642\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c7429256b7a04d71b80d487de6f2dc03\n",
      "\u001b[2m\u001b[36m(PPO pid=25191)\u001b[0m 2023-09-19 19:40:24,642\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 972, '_timesteps_total': None, '_time_total': 191.9047315120697, '_episodes_total': 318}\n",
      "\u001b[2m\u001b[36m(PPO pid=25200)\u001b[0m 2023-09-19 19:40:38,962\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25195)\u001b[0m 2023-09-19 19:40:38,962\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25201)\u001b[0m 2023-09-19 19:40:40,781\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25200)\u001b[0m 2023-09-19 19:40:42,607\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25200)\u001b[0m 2023-09-19 19:40:42,637\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_06c5e4455b524b3698bfb170a85512ca\n",
      "\u001b[2m\u001b[36m(PPO pid=25200)\u001b[0m 2023-09-19 19:40:42,637\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 972, '_timesteps_total': None, '_time_total': 191.87338089942932, '_episodes_total': 318}\n",
      "2023-09-19 19:40:53,821\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.120516) into trial 76be2_00000 (score = 0.112547)\n",
      "\n",
      "2023-09-19 19:40:53,821\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00015449887622846973 --- (resample) --> 0.00025692275518296177\n",
      "gamma : 1.1625264471476042 --- (resample) --> 0.9773332571096557\n",
      "clip_param : 0.23807761091964488 --- (* 1.2) --> 0.28569313310357386\n",
      "kl_coeff : 0.5242857777233126 --- (* 1.2) --> 0.6291429332679751\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25206)\u001b[0m 2023-09-19 19:40:55,872\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25204)\u001b[0m 2023-09-19 19:40:55,872\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25209)\u001b[0m 2023-09-19 19:40:57,723\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "2023-09-19 19:41:10,682\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=25214)\u001b[0m 2023-09-19 19:41:13,889\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25212)\u001b[0m 2023-09-19 19:41:13,889\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25215)\u001b[0m 2023-09-19 19:41:15,772\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25214)\u001b[0m 2023-09-19 19:41:17,506\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25214)\u001b[0m 2023-09-19 19:41:17,533\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_eefb955d75ce4ac3aafdba66441647fd\n",
      "\u001b[2m\u001b[36m(PPO pid=25214)\u001b[0m 2023-09-19 19:41:17,533\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1024, '_timesteps_total': None, '_time_total': 201.90845942497253, '_episodes_total': 335}\n",
      "2023-09-19 19:41:28,938\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=25220)\u001b[0m 2023-09-19 19:41:31,775\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25218)\u001b[0m 2023-09-19 19:41:31,775\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25221)\u001b[0m 2023-09-19 19:41:33,665\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25220)\u001b[0m 2023-09-19 19:41:35,380\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25220)\u001b[0m 2023-09-19 19:41:35,411\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c9b58f305c7b4ae8b86ff8d3f77c3b5a\n",
      "\u001b[2m\u001b[36m(PPO pid=25220)\u001b[0m 2023-09-19 19:41:35,411\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1075, '_timesteps_total': None, '_time_total': 212.00547862052917, '_episodes_total': 352}\n",
      "\u001b[2m\u001b[36m(PPO pid=25227)\u001b[0m 2023-09-19 19:41:49,850\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25224)\u001b[0m 2023-09-19 19:41:49,850\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25228)\u001b[0m 2023-09-19 19:41:51,676\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25227)\u001b[0m 2023-09-19 19:41:53,449\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25227)\u001b[0m 2023-09-19 19:41:53,477\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_354a7097c2aa4f2c992be665142dc88d\n",
      "\u001b[2m\u001b[36m(PPO pid=25227)\u001b[0m 2023-09-19 19:41:53,477\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1076, '_timesteps_total': None, '_time_total': 211.94213366508484, '_episodes_total': 352}\n",
      "\u001b[2m\u001b[36m(PPO pid=25237)\u001b[0m 2023-09-19 19:42:08,080\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25233)\u001b[0m 2023-09-19 19:42:08,080\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25238)\u001b[0m 2023-09-19 19:42:09,972\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25237)\u001b[0m 2023-09-19 19:42:11,673\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25237)\u001b[0m 2023-09-19 19:42:11,699\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_dd5a81de86b04be4ac9418f3705d101f\n",
      "\u001b[2m\u001b[36m(PPO pid=25237)\u001b[0m 2023-09-19 19:42:11,699\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1127, '_timesteps_total': None, '_time_total': 222.0782437324524, '_episodes_total': 369}\n",
      "2023-09-19 19:42:22,924\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.118997) into trial 76be2_00001 (score = 0.087695)\n",
      "\n",
      "2023-09-19 19:42:22,925\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00025692275518296177 --- (* 0.8) --> 0.00020553820414636942\n",
      "gamma : 0.9773332571096557 --- (* 1.2) --> 1.1727999085315868\n",
      "clip_param : 0.28569313310357386 --- (resample) --> 0.25303514397134175\n",
      "kl_coeff : 0.6291429332679751 --- (* 1.2) --> 0.7549715199215701\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25244)\u001b[0m 2023-09-19 19:42:26,013\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25241)\u001b[0m 2023-09-19 19:42:26,013\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25245)\u001b[0m 2023-09-19 19:42:27,859\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25244)\u001b[0m 2023-09-19 19:42:29,641\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25244)\u001b[0m 2023-09-19 19:42:29,666\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_691b885d368b4ba386f95dfb8bf7bc84\n",
      "\u001b[2m\u001b[36m(PPO pid=25244)\u001b[0m 2023-09-19 19:42:29,666\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1127, '_timesteps_total': None, '_time_total': 222.05151629447937, '_episodes_total': 369}\n",
      "\u001b[2m\u001b[36m(PPO pid=25255)\u001b[0m 2023-09-19 19:42:43,759\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25249)\u001b[0m 2023-09-19 19:42:43,759\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25256)\u001b[0m 2023-09-19 19:42:45,630\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25255)\u001b[0m 2023-09-19 19:42:47,321\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25255)\u001b[0m 2023-09-19 19:42:47,347\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_b59430951eda493497b8604a6a1fcd0a\n",
      "\u001b[2m\u001b[36m(PPO pid=25255)\u001b[0m 2023-09-19 19:42:47,347\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1127, '_timesteps_total': None, '_time_total': 222.05151629447937, '_episodes_total': 369}\n",
      "2023-09-19 19:42:58,449\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.101916) into trial 76be2_00001 (score = 0.092845)\n",
      "\n",
      "2023-09-19 19:42:58,449\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00025692275518296177 --- (resample) --> 0.00030175267940052555\n",
      "gamma : 0.9773332571096557 --- (* 0.8) --> 0.7818666056877246\n",
      "clip_param : 0.28569313310357386 --- (* 1.2) --> 0.34283175972428864\n",
      "kl_coeff : 0.6291429332679751 --- (resample) --> 0.992307664297368\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25261)\u001b[0m 2023-09-19 19:43:00,915\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25259)\u001b[0m 2023-09-19 19:43:00,915\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25264)\u001b[0m 2023-09-19 19:43:02,781\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25261)\u001b[0m 2023-09-19 19:43:04,509\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25261)\u001b[0m 2023-09-19 19:43:04,535\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_6fc13104c7374271994c3ade0ae033c5\n",
      "\u001b[2m\u001b[36m(PPO pid=25261)\u001b[0m 2023-09-19 19:43:04,535\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1179, '_timesteps_total': None, '_time_total': 232.16422080993652, '_episodes_total': 386}\n",
      "\u001b[2m\u001b[36m(PPO pid=25271)\u001b[0m 2023-09-19 19:43:19,017\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25267)\u001b[0m 2023-09-19 19:43:19,017\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25272)\u001b[0m 2023-09-19 19:43:20,963\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25271)\u001b[0m 2023-09-19 19:43:22,687\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25271)\u001b[0m 2023-09-19 19:43:22,716\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_007f5bc8ab15475d836ba1d5616f0dcc\n",
      "\u001b[2m\u001b[36m(PPO pid=25271)\u001b[0m 2023-09-19 19:43:22,716\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1179, '_timesteps_total': None, '_time_total': 232.16422080993652, '_episodes_total': 386}\n",
      "2023-09-19 19:43:34,059\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.100341) into trial 76be2_00001 (score = 0.098517)\n",
      "\n",
      "2023-09-19 19:43:34,059\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00025692275518296177 --- (* 1.2) --> 0.0003083073062195541\n",
      "gamma : 0.9773332571096557 --- (resample) --> 0.9747639737384324\n",
      "clip_param : 0.28569313310357386 --- (resample) --> 0.28950311588628963\n",
      "kl_coeff : 0.6291429332679751 --- (* 0.8) --> 0.5033143466143801\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25279)\u001b[0m 2023-09-19 19:43:37,069\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25276)\u001b[0m 2023-09-19 19:43:37,069\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25282)\u001b[0m 2023-09-19 19:43:38,954\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25279)\u001b[0m 2023-09-19 19:43:40,671\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25279)\u001b[0m 2023-09-19 19:43:40,698\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_489f6acf496c4362bf7b32d9ab7538c0\n",
      "\u001b[2m\u001b[36m(PPO pid=25279)\u001b[0m 2023-09-19 19:43:40,698\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1231, '_timesteps_total': None, '_time_total': 242.19500970840454, '_episodes_total': 403}\n",
      "2023-09-19 19:43:51,841\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=25287)\u001b[0m 2023-09-19 19:43:53,998\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25286)\u001b[0m 2023-09-19 19:43:53,998\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25288)\u001b[0m 2023-09-19 19:43:55,898\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25287)\u001b[0m 2023-09-19 19:43:57,612\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25287)\u001b[0m 2023-09-19 19:43:57,639\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_0cbc6590d3224021a3164f87d63f7b3e\n",
      "\u001b[2m\u001b[36m(PPO pid=25287)\u001b[0m 2023-09-19 19:43:57,639\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1231, '_timesteps_total': None, '_time_total': 242.19500970840454, '_episodes_total': 403}\n",
      "\u001b[2m\u001b[36m(PPO pid=25293)\u001b[0m 2023-09-19 19:44:12,146\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25292)\u001b[0m 2023-09-19 19:44:12,146\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25294)\u001b[0m 2023-09-19 19:44:13,981\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25293)\u001b[0m 2023-09-19 19:44:15,755\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25293)\u001b[0m 2023-09-19 19:44:15,784\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_4363386f541c467d86bf6bc1d51b6d0a\n",
      "\u001b[2m\u001b[36m(PPO pid=25293)\u001b[0m 2023-09-19 19:44:15,785\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1283, '_timesteps_total': None, '_time_total': 252.20186972618103, '_episodes_total': 420}\n",
      "2023-09-19 19:44:27,086\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.098595) into trial 76be2_00000 (score = 0.096330)\n",
      "\n",
      "2023-09-19 19:44:27,087\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.0003083073062195541 --- (* 0.8) --> 0.0002466458449756433\n",
      "gamma : 0.9747639737384324 --- (* 1.2) --> 1.1697167684861187\n",
      "clip_param : 0.28950311588628963 --- (* 0.8) --> 0.23160249270903172\n",
      "kl_coeff : 0.5033143466143801 --- (resample) --> 0.8391945282945905\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25301)\u001b[0m 2023-09-19 19:44:30,133\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25298)\u001b[0m 2023-09-19 19:44:30,133\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25304)\u001b[0m 2023-09-19 19:44:32,033\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25301)\u001b[0m 2023-09-19 19:44:33,735\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25301)\u001b[0m 2023-09-19 19:44:33,764\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_377f900658a64490a407e1a5f5b47225\n",
      "\u001b[2m\u001b[36m(PPO pid=25301)\u001b[0m 2023-09-19 19:44:33,764\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1283, '_timesteps_total': None, '_time_total': 252.27047204971313, '_episodes_total': 420}\n",
      "2023-09-19 19:44:45,000\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=25315)\u001b[0m 2023-09-19 19:44:47,883\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25307)\u001b[0m 2023-09-19 19:44:47,883\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25316)\u001b[0m 2023-09-19 19:44:49,747\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25315)\u001b[0m 2023-09-19 19:44:51,426\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25315)\u001b[0m 2023-09-19 19:44:51,450\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_2154360ba3ce495691a9f36865da66e1\n",
      "\u001b[2m\u001b[36m(PPO pid=25315)\u001b[0m 2023-09-19 19:44:51,450\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1283, '_timesteps_total': None, '_time_total': 252.27047204971313, '_episodes_total': 420}\n",
      "2023-09-19 19:45:02,867\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=25322)\u001b[0m 2023-09-19 19:45:06,203\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25319)\u001b[0m 2023-09-19 19:45:06,203\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25323)\u001b[0m 2023-09-19 19:45:08,092\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25322)\u001b[0m 2023-09-19 19:45:09,814\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25322)\u001b[0m 2023-09-19 19:45:09,846\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_8eff73abc2ab425caa0cee19e6bbd7ec\n",
      "\u001b[2m\u001b[36m(PPO pid=25322)\u001b[0m 2023-09-19 19:45:09,846\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1335, '_timesteps_total': None, '_time_total': 262.35465693473816, '_episodes_total': 437}\n",
      "\u001b[2m\u001b[36m(PPO pid=25328)\u001b[0m 2023-09-19 19:45:24,220\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25326)\u001b[0m 2023-09-19 19:45:24,220\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25329)\u001b[0m 2023-09-19 19:45:26,023\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "2023-09-19 19:45:39,097\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.116569) into trial 76be2_00000 (score = 0.090318)\n",
      "\n",
      "2023-09-19 19:45:39,097\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.0003083073062195541 --- (* 0.8) --> 0.0002466458449756433\n",
      "gamma : 0.9747639737384324 --- (* 1.2) --> 1.1697167684861187\n",
      "clip_param : 0.28950311588628963 --- (* 1.2) --> 0.34740373906354755\n",
      "kl_coeff : 0.5033143466143801 --- (* 0.8) --> 0.40265147729150413\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25337)\u001b[0m 2023-09-19 19:45:42,115\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25332)\u001b[0m 2023-09-19 19:45:42,115\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25338)\u001b[0m 2023-09-19 19:45:43,962\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25337)\u001b[0m 2023-09-19 19:45:45,663\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25337)\u001b[0m 2023-09-19 19:45:45,701\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ec7494cea54e40d29bb8e49c4b1eee1e\n",
      "\u001b[2m\u001b[36m(PPO pid=25337)\u001b[0m 2023-09-19 19:45:45,701\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1387, '_timesteps_total': None, '_time_total': 272.43343472480774, '_episodes_total': 454}\n",
      "\u001b[2m\u001b[36m(PPO pid=25343)\u001b[0m 2023-09-19 19:46:00,264\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25341)\u001b[0m 2023-09-19 19:46:00,264\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25344)\u001b[0m 2023-09-19 19:46:02,073\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25343)\u001b[0m 2023-09-19 19:46:03,826\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25343)\u001b[0m 2023-09-19 19:46:03,851\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_08a9271416a54be986c121478299c554\n",
      "\u001b[2m\u001b[36m(PPO pid=25343)\u001b[0m 2023-09-19 19:46:03,851\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1387, '_timesteps_total': None, '_time_total': 272.43343472480774, '_episodes_total': 454}\n",
      "\u001b[2m\u001b[36m(PPO pid=25348)\u001b[0m 2023-09-19 19:46:18,026\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25347)\u001b[0m 2023-09-19 19:46:18,026\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25349)\u001b[0m 2023-09-19 19:46:19,881\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25348)\u001b[0m 2023-09-19 19:46:21,573\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25348)\u001b[0m 2023-09-19 19:46:21,599\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_3469ed568b39418f9e555c25533f72aa\n",
      "\u001b[2m\u001b[36m(PPO pid=25348)\u001b[0m 2023-09-19 19:46:21,599\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1440, '_timesteps_total': None, '_time_total': 282.50581908226013, '_episodes_total': 471}\n",
      "\u001b[2m\u001b[36m(PPO pid=25356)\u001b[0m 2023-09-19 19:46:36,044\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25352)\u001b[0m 2023-09-19 19:46:36,044\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25357)\u001b[0m 2023-09-19 19:46:37,855\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25356)\u001b[0m 2023-09-19 19:46:39,573\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25356)\u001b[0m 2023-09-19 19:46:39,602\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_10dfae3e398943abb599a38c6e734b94\n",
      "\u001b[2m\u001b[36m(PPO pid=25356)\u001b[0m 2023-09-19 19:46:39,602\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1440, '_timesteps_total': None, '_time_total': 282.58401703834534, '_episodes_total': 471}\n",
      "2023-09-19 19:46:50,889\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.110897) into trial 76be2_00000 (score = 0.099899)\n",
      "\n",
      "2023-09-19 19:46:50,889\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.0003083073062195541 --- (* 0.8) --> 0.0002466458449756433\n",
      "gamma : 0.9747639737384324 --- (* 1.2) --> 1.1697167684861187\n",
      "clip_param : 0.28950311588628963 --- (* 1.2) --> 0.34740373906354755\n",
      "kl_coeff : 0.5033143466143801 --- (* 0.8) --> 0.40265147729150413\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25363)\u001b[0m 2023-09-19 19:46:54,251\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25360)\u001b[0m 2023-09-19 19:46:54,251\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25364)\u001b[0m 2023-09-19 19:46:56,098\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25363)\u001b[0m 2023-09-19 19:46:57,796\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25363)\u001b[0m 2023-09-19 19:46:57,824\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d69fed31ef7d47dda577840e770ca069\n",
      "\u001b[2m\u001b[36m(PPO pid=25363)\u001b[0m 2023-09-19 19:46:57,824\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1492, '_timesteps_total': None, '_time_total': 292.5789430141449, '_episodes_total': 488}\n",
      "2023-09-19 19:47:09,109\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=25369)\u001b[0m 2023-09-19 19:47:12,335\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25368)\u001b[0m 2023-09-19 19:47:12,335\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=25369)\u001b[0m 2023-09-19 19:47:15,891\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25369)\u001b[0m 2023-09-19 19:47:15,917\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_3cf6831dc0fa418ebc60ebc440a60c35\n",
      "\u001b[2m\u001b[36m(PPO pid=25369)\u001b[0m 2023-09-19 19:47:15,917\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1492, '_timesteps_total': None, '_time_total': 292.5789430141449, '_episodes_total': 488}\n",
      "\u001b[2m\u001b[36m(PPO pid=25374)\u001b[0m 2023-09-19 19:47:30,207\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25373)\u001b[0m 2023-09-19 19:47:30,207\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25375)\u001b[0m 2023-09-19 19:47:32,087\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25374)\u001b[0m 2023-09-19 19:47:33,766\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25374)\u001b[0m 2023-09-19 19:47:33,792\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_4384b8ebc6324ed29c17a5a43c83d462\n",
      "\u001b[2m\u001b[36m(PPO pid=25374)\u001b[0m 2023-09-19 19:47:33,792\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1544, '_timesteps_total': None, '_time_total': 302.60615158081055, '_episodes_total': 505}\n",
      "\u001b[2m\u001b[36m(PPO pid=25382)\u001b[0m 2023-09-19 19:47:48,311\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25379)\u001b[0m 2023-09-19 19:47:48,311\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25383)\u001b[0m 2023-09-19 19:47:50,166\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25382)\u001b[0m 2023-09-19 19:47:51,854\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25382)\u001b[0m 2023-09-19 19:47:51,879\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_71ea815ddb1548dc89bb34ac32013e0c\n",
      "\u001b[2m\u001b[36m(PPO pid=25382)\u001b[0m 2023-09-19 19:47:51,880\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1544, '_timesteps_total': None, '_time_total': 302.582804441452, '_episodes_total': 505}\n",
      "2023-09-19 19:48:03,139\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.130949) into trial 76be2_00000 (score = 0.100344)\n",
      "\n",
      "2023-09-19 19:48:03,140\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.0003083073062195541 --- (* 1.2) --> 0.00036996876746346494\n",
      "gamma : 0.9747639737384324 --- (* 1.2) --> 1.1697167684861187\n",
      "clip_param : 0.28950311588628963 --- (* 0.8) --> 0.23160249270903172\n",
      "kl_coeff : 0.5033143466143801 --- (* 0.8) --> 0.40265147729150413\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25395)\u001b[0m 2023-09-19 19:48:06,368\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25386)\u001b[0m 2023-09-19 19:48:06,368\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25398)\u001b[0m 2023-09-19 19:48:08,236\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25395)\u001b[0m 2023-09-19 19:48:09,930\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25395)\u001b[0m 2023-09-19 19:48:09,957\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ebe2c8920dbf4cdc9d6fde27859b3cb1\n",
      "\u001b[2m\u001b[36m(PPO pid=25395)\u001b[0m 2023-09-19 19:48:09,957\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1596, '_timesteps_total': None, '_time_total': 312.7766969203949, '_episodes_total': 522}\n",
      "\u001b[2m\u001b[36m(PPO pid=25406)\u001b[0m 2023-09-19 19:48:24,183\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25401)\u001b[0m 2023-09-19 19:48:24,183\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25408)\u001b[0m 2023-09-19 19:48:26,042\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25406)\u001b[0m 2023-09-19 19:48:27,730\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25406)\u001b[0m 2023-09-19 19:48:27,758\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_1efecc8548744bce8da40458fd8f31fb\n",
      "\u001b[2m\u001b[36m(PPO pid=25406)\u001b[0m 2023-09-19 19:48:27,758\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1596, '_timesteps_total': None, '_time_total': 312.7766969203949, '_episodes_total': 522}\n",
      "\u001b[2m\u001b[36m(PPO pid=25450)\u001b[0m 2023-09-19 19:48:42,860\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25411)\u001b[0m 2023-09-19 19:48:42,860\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=25450)\u001b[0m 2023-09-19 19:48:46,723\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25450)\u001b[0m 2023-09-19 19:48:46,754\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_7110214262fb4fe69a28afffb59242ff\n",
      "\u001b[2m\u001b[36m(PPO pid=25450)\u001b[0m 2023-09-19 19:48:46,754\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1649, '_timesteps_total': None, '_time_total': 322.8627007007599, '_episodes_total': 539}\n",
      "2023-09-19 19:48:58,030\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.116831) into trial 76be2_00001 (score = 0.105822)\n",
      "\n",
      "2023-09-19 19:48:58,031\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00036996876746346494 --- (* 0.8) --> 0.000295975013970772\n",
      "gamma : 1.1697167684861187 --- (* 1.2) --> 1.4036601221833425\n",
      "clip_param : 0.23160249270903172 --- (* 0.8) --> 0.18528199416722538\n",
      "kl_coeff : 0.40265147729150413 --- (* 0.8) --> 0.3221211818332033\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25472)\u001b[0m 2023-09-19 19:49:01,674\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25466)\u001b[0m 2023-09-19 19:49:01,674\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25475)\u001b[0m 2023-09-19 19:49:03,936\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25472)\u001b[0m 2023-09-19 19:49:05,850\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25472)\u001b[0m 2023-09-19 19:49:05,880\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_dd29eb1479e04f1bb1c3194445e0d2b2\n",
      "\u001b[2m\u001b[36m(PPO pid=25472)\u001b[0m 2023-09-19 19:49:05,880\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1648, '_timesteps_total': None, '_time_total': 322.9172294139862, '_episodes_total': 539}\n",
      "\u001b[2m\u001b[36m(PPO pid=25481)\u001b[0m 2023-09-19 19:49:20,547\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25478)\u001b[0m 2023-09-19 19:49:20,547\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25482)\u001b[0m 2023-09-19 19:49:22,575\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25481)\u001b[0m 2023-09-19 19:49:24,327\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25481)\u001b[0m 2023-09-19 19:49:24,362\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_8134b6a1015241719ce11e813f39cf47\n",
      "\u001b[2m\u001b[36m(PPO pid=25481)\u001b[0m 2023-09-19 19:49:24,362\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1648, '_timesteps_total': None, '_time_total': 322.9172294139862, '_episodes_total': 539}\n",
      "2023-09-19 19:49:35,621\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.110566) into trial 76be2_00001 (score = 0.108756)\n",
      "\n",
      "2023-09-19 19:49:35,621\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00036996876746346494 --- (* 0.8) --> 0.000295975013970772\n",
      "gamma : 1.1697167684861187 --- (resample) --> 0.9546700365632005\n",
      "clip_param : 0.23160249270903172 --- (* 0.8) --> 0.18528199416722538\n",
      "kl_coeff : 0.40265147729150413 --- (* 0.8) --> 0.3221211818332033\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25487)\u001b[0m 2023-09-19 19:49:38,552\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25485)\u001b[0m 2023-09-19 19:49:38,552\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25489)\u001b[0m 2023-09-19 19:49:40,520\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25487)\u001b[0m 2023-09-19 19:49:42,231\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25487)\u001b[0m 2023-09-19 19:49:42,259\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_0449a28673ec4dfa81a85bd9a3469f0c\n",
      "\u001b[2m\u001b[36m(PPO pid=25487)\u001b[0m 2023-09-19 19:49:42,259\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1700, '_timesteps_total': None, '_time_total': 332.98320841789246, '_episodes_total': 556}\n",
      "2023-09-19 19:49:53,482\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=25509)\u001b[0m 2023-09-19 19:49:56,321\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25492)\u001b[0m 2023-09-19 19:49:56,321\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25510)\u001b[0m 2023-09-19 19:49:58,291\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25509)\u001b[0m 2023-09-19 19:50:00,041\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25509)\u001b[0m 2023-09-19 19:50:00,072\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_fc96314b30b4484796c1a2e51c0d09f2\n",
      "\u001b[2m\u001b[36m(PPO pid=25509)\u001b[0m 2023-09-19 19:50:00,072\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1700, '_timesteps_total': None, '_time_total': 332.98320841789246, '_episodes_total': 556}\n",
      "2023-09-19 19:50:11,271\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=25541)\u001b[0m 2023-09-19 19:50:14,599\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25514)\u001b[0m 2023-09-19 19:50:14,599\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25542)\u001b[0m 2023-09-19 19:50:16,565\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25541)\u001b[0m 2023-09-19 19:50:18,260\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25541)\u001b[0m 2023-09-19 19:50:18,289\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_3c3b0f0e00d94b6fa47e376e5f0be9aa\n",
      "\u001b[2m\u001b[36m(PPO pid=25541)\u001b[0m 2023-09-19 19:50:18,289\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1752, '_timesteps_total': None, '_time_total': 343.012149810791, '_episodes_total': 573}\n",
      "\u001b[2m\u001b[36m(PPO pid=25552)\u001b[0m 2023-09-19 19:50:32,469\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25545)\u001b[0m 2023-09-19 19:50:32,469\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25553)\u001b[0m 2023-09-19 19:50:34,388\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25552)\u001b[0m 2023-09-19 19:50:36,135\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25552)\u001b[0m 2023-09-19 19:50:36,173\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_23ae31ebb8a94fdb9c32ce113bc231cf\n",
      "\u001b[2m\u001b[36m(PPO pid=25552)\u001b[0m 2023-09-19 19:50:36,174\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1750, '_timesteps_total': None, '_time_total': 343.0260248184204, '_episodes_total': 573}\n",
      "2023-09-19 19:50:47,642\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.111249) into trial 76be2_00001 (score = 0.092392)\n",
      "\n",
      "2023-09-19 19:50:47,642\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00036996876746346494 --- (* 0.8) --> 0.000295975013970772\n",
      "gamma : 1.1697167684861187 --- (* 1.2) --> 1.4036601221833425\n",
      "clip_param : 0.23160249270903172 --- (* 1.2) --> 0.277922991250838\n",
      "kl_coeff : 0.40265147729150413 --- (resample) --> 0.7461905263931523\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25559)\u001b[0m 2023-09-19 19:50:50,632\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25557)\u001b[0m 2023-09-19 19:50:50,632\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25562)\u001b[0m 2023-09-19 19:50:52,538\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25559)\u001b[0m 2023-09-19 19:50:54,247\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25559)\u001b[0m 2023-09-19 19:50:54,279\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_a61f6ce7ba6647faa3dcb96834ccf98b\n",
      "\u001b[2m\u001b[36m(PPO pid=25559)\u001b[0m 2023-09-19 19:50:54,279\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1804, '_timesteps_total': None, '_time_total': 353.08978486061096, '_episodes_total': 590}\n",
      "\u001b[2m\u001b[36m(PPO pid=25568)\u001b[0m 2023-09-19 19:51:08,397\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25565)\u001b[0m 2023-09-19 19:51:08,397\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25569)\u001b[0m 2023-09-19 19:51:10,256\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25574)\u001b[0m 2023-09-19 19:51:26,475\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25572)\u001b[0m 2023-09-19 19:51:26,475\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25575)\u001b[0m 2023-09-19 19:51:28,355\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25574)\u001b[0m 2023-09-19 19:51:30,051\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25574)\u001b[0m 2023-09-19 19:51:30,084\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_479a8a418d2f4ea082825ee68cc00acc\n",
      "\u001b[2m\u001b[36m(PPO pid=25574)\u001b[0m 2023-09-19 19:51:30,084\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1856, '_timesteps_total': None, '_time_total': 363.10447454452515, '_episodes_total': 607}\n",
      "2023-09-19 19:51:41,462\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.112294) into trial 76be2_00000 (score = 0.089350)\n",
      "\n",
      "2023-09-19 19:51:41,462\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.000295975013970772 --- (* 1.2) --> 0.0003551700167649264\n",
      "gamma : 1.4036601221833425 --- (resample) --> 0.9595240160177386\n",
      "clip_param : 0.277922991250838 --- (resample) --> 0.16787263695230073\n",
      "kl_coeff : 0.7461905263931523 --- (* 1.2) --> 0.8954286316717828\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25583)\u001b[0m 2023-09-19 19:51:44,632\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25578)\u001b[0m 2023-09-19 19:51:44,632\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25585)\u001b[0m 2023-09-19 19:51:46,517\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25583)\u001b[0m 2023-09-19 19:51:48,207\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25583)\u001b[0m 2023-09-19 19:51:48,238\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_26751a8b75d34fd2af5d85f12f9fd0f1\n",
      "\u001b[2m\u001b[36m(PPO pid=25583)\u001b[0m 2023-09-19 19:51:48,238\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1856, '_timesteps_total': None, '_time_total': 363.11547207832336, '_episodes_total': 607}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25591)\u001b[0m 2023-09-19 19:52:04,585\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25590)\u001b[0m 2023-09-19 19:52:06,305\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25590)\u001b[0m 2023-09-19 19:52:06,331\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_b77785f2f4fc4b9a9ea61c12705bbbb4\n",
      "\u001b[2m\u001b[36m(PPO pid=25590)\u001b[0m 2023-09-19 19:52:06,331\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1856, '_timesteps_total': None, '_time_total': 363.11547207832336, '_episodes_total': 607}\n",
      "\u001b[2m\u001b[36m(PPO pid=25595)\u001b[0m 2023-09-19 19:52:20,604\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25594)\u001b[0m 2023-09-19 19:52:20,604\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25596)\u001b[0m 2023-09-19 19:52:22,433\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25595)\u001b[0m 2023-09-19 19:52:24,201\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25595)\u001b[0m 2023-09-19 19:52:24,239\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_2e524b89cf084c72a34b5c9c764a9f43\n",
      "\u001b[2m\u001b[36m(PPO pid=25595)\u001b[0m 2023-09-19 19:52:24,239\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1908, '_timesteps_total': None, '_time_total': 373.2281742095947, '_episodes_total': 624}\n",
      "2023-09-19 19:52:35,440\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.130723) into trial 76be2_00001 (score = 0.121098)\n",
      "\n",
      "2023-09-19 19:52:35,441\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.0003551700167649264 --- (* 0.8) --> 0.00028413601341194115\n",
      "gamma : 0.9595240160177386 --- (* 0.8) --> 0.767619212814191\n",
      "clip_param : 0.16787263695230073 --- (* 0.8) --> 0.1342981095618406\n",
      "kl_coeff : 0.8954286316717828 --- (resample) --> 1.447341845232305\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25613)\u001b[0m 2023-09-19 19:52:38,737\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25599)\u001b[0m 2023-09-19 19:52:38,737\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25616)\u001b[0m 2023-09-19 19:52:40,643\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25613)\u001b[0m 2023-09-19 19:52:42,383\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25613)\u001b[0m 2023-09-19 19:52:42,420\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_67cb15aba8314e088504fdf2b9e7b7cd\n",
      "\u001b[2m\u001b[36m(PPO pid=25613)\u001b[0m 2023-09-19 19:52:42,420\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1908, '_timesteps_total': None, '_time_total': 373.1391108036041, '_episodes_total': 624}\n",
      "\u001b[2m\u001b[36m(PPO pid=25621)\u001b[0m 2023-09-19 19:52:56,555\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25619)\u001b[0m 2023-09-19 19:52:56,555\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25622)\u001b[0m 2023-09-19 19:52:58,410\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25621)\u001b[0m 2023-09-19 19:53:00,179\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25621)\u001b[0m 2023-09-19 19:53:00,211\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_0c0acec5c2374ad78288c573fd3e1346\n",
      "\u001b[2m\u001b[36m(PPO pid=25621)\u001b[0m 2023-09-19 19:53:00,211\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1908, '_timesteps_total': None, '_time_total': 373.1391108036041, '_episodes_total': 624}\n",
      "2023-09-19 19:53:11,441\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.140994) into trial 76be2_00001 (score = 0.122250)\n",
      "\n",
      "2023-09-19 19:53:11,442\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.0003551700167649264 --- (resample) --> 0.000889795548189673\n",
      "gamma : 0.9595240160177386 --- (* 1.2) --> 1.1514288192212863\n",
      "clip_param : 0.16787263695230073 --- (* 0.8) --> 0.1342981095618406\n",
      "kl_coeff : 0.8954286316717828 --- (* 0.8) --> 0.7163429053374263\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25628)\u001b[0m 2023-09-19 19:53:14,694\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25626)\u001b[0m 2023-09-19 19:53:14,694\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25631)\u001b[0m 2023-09-19 19:53:16,538\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25628)\u001b[0m 2023-09-19 19:53:18,322\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25628)\u001b[0m 2023-09-19 19:53:18,352\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_34cfaa0af6964b7a842f50e74c42f41a\n",
      "\u001b[2m\u001b[36m(PPO pid=25628)\u001b[0m 2023-09-19 19:53:18,352\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1961, '_timesteps_total': None, '_time_total': 383.2582151889801, '_episodes_total': 641}\n",
      "\u001b[2m\u001b[36m(PPO pid=25639)\u001b[0m 2023-09-19 19:53:32,642\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25634)\u001b[0m 2023-09-19 19:53:32,642\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25640)\u001b[0m 2023-09-19 19:53:34,596\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25639)\u001b[0m 2023-09-19 19:53:36,288\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25639)\u001b[0m 2023-09-19 19:53:36,318\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d2f92c5b66c3412b9ca20afd873f2647\n",
      "\u001b[2m\u001b[36m(PPO pid=25639)\u001b[0m 2023-09-19 19:53:36,318\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 1961, '_timesteps_total': None, '_time_total': 383.2582151889801, '_episodes_total': 641}\n",
      "\u001b[2m\u001b[36m(PPO pid=25644)\u001b[0m 2023-09-19 19:53:50,641\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25643)\u001b[0m 2023-09-19 19:53:50,641\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25645)\u001b[0m 2023-09-19 19:53:52,455\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25644)\u001b[0m 2023-09-19 19:53:54,311\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25644)\u001b[0m 2023-09-19 19:53:54,340\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_18db19dfabdd4ef9b0930214f16dc6ae\n",
      "\u001b[2m\u001b[36m(PPO pid=25644)\u001b[0m 2023-09-19 19:53:54,340\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2013, '_timesteps_total': None, '_time_total': 393.3553533554077, '_episodes_total': 658}\n",
      "\u001b[2m\u001b[36m(PPO pid=25650)\u001b[0m 2023-09-19 19:54:08,602\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25648)\u001b[0m 2023-09-19 19:54:08,602\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25651)\u001b[0m 2023-09-19 19:54:10,483\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25650)\u001b[0m 2023-09-19 19:54:12,179\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25650)\u001b[0m 2023-09-19 19:54:12,212\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_493733c92cab4a1c8889ea93033165b5\n",
      "\u001b[2m\u001b[36m(PPO pid=25650)\u001b[0m 2023-09-19 19:54:12,212\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2013, '_timesteps_total': None, '_time_total': 393.3792073726654, '_episodes_total': 658}\n",
      "2023-09-19 19:54:23,354\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.137590) into trial 76be2_00001 (score = 0.135402)\n",
      "\n",
      "2023-09-19 19:54:23,354\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.0003551700167649264 --- (* 0.8) --> 0.00028413601341194115\n",
      "gamma : 0.9595240160177386 --- (* 0.8) --> 0.767619212814191\n",
      "clip_param : 0.16787263695230073 --- (* 1.2) --> 0.20144716434276086\n",
      "kl_coeff : 0.8954286316717828 --- (* 1.2) --> 1.0745143580061394\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25656)\u001b[0m 2023-09-19 19:54:25,809\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25654)\u001b[0m 2023-09-19 19:54:25,809\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25658)\u001b[0m 2023-09-19 19:54:27,684\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25656)\u001b[0m 2023-09-19 19:54:29,426\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25656)\u001b[0m 2023-09-19 19:54:29,462\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_cadff534dee84f0fbeabab0a1185e641\n",
      "\u001b[2m\u001b[36m(PPO pid=25656)\u001b[0m 2023-09-19 19:54:29,462\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2065, '_timesteps_total': None, '_time_total': 403.43900060653687, '_episodes_total': 675}\n",
      "2023-09-19 19:54:40,726\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=25675)\u001b[0m 2023-09-19 19:54:43,793\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25661)\u001b[0m 2023-09-19 19:54:43,793\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25676)\u001b[0m 2023-09-19 19:54:45,689\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25675)\u001b[0m 2023-09-19 19:54:47,393\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25675)\u001b[0m 2023-09-19 19:54:47,422\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_67e89782948749b8be2fc0bf1d903137\n",
      "\u001b[2m\u001b[36m(PPO pid=25675)\u001b[0m 2023-09-19 19:54:47,422\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2065, '_timesteps_total': None, '_time_total': 403.43900060653687, '_episodes_total': 675}\n",
      "\u001b[2m\u001b[36m(PPO pid=25683)\u001b[0m 2023-09-19 19:55:01,813\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25679)\u001b[0m 2023-09-19 19:55:01,813\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25684)\u001b[0m 2023-09-19 19:55:03,744\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25683)\u001b[0m 2023-09-19 19:55:05,453\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25683)\u001b[0m 2023-09-19 19:55:05,491\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_be94d8a2c9114a629384580a613f841f\n",
      "\u001b[2m\u001b[36m(PPO pid=25683)\u001b[0m 2023-09-19 19:55:05,491\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2117, '_timesteps_total': None, '_time_total': 413.5513744354248, '_episodes_total': 692}\n",
      "\u001b[2m\u001b[36m(PPO pid=25689)\u001b[0m 2023-09-19 19:55:19,848\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25687)\u001b[0m 2023-09-19 19:55:19,848\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25690)\u001b[0m 2023-09-19 19:55:21,694\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25689)\u001b[0m 2023-09-19 19:55:23,489\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25689)\u001b[0m 2023-09-19 19:55:23,518\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_81cfaac1654b4581b9a237a54e521c04\n",
      "\u001b[2m\u001b[36m(PPO pid=25689)\u001b[0m 2023-09-19 19:55:23,518\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2117, '_timesteps_total': None, '_time_total': 413.50280141830444, '_episodes_total': 692}\n",
      "2023-09-19 19:55:34,666\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.157468) into trial 76be2_00001 (score = 0.125299)\n",
      "\n",
      "2023-09-19 19:55:34,667\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.0003551700167649264 --- (* 1.2) --> 0.00042620402011791164\n",
      "gamma : 0.9595240160177386 --- (* 0.8) --> 0.767619212814191\n",
      "clip_param : 0.16787263695230073 --- (resample) --> 0.17033279107656701\n",
      "kl_coeff : 0.8954286316717828 --- (* 1.2) --> 1.0745143580061394\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25695)\u001b[0m 2023-09-19 19:55:36,657\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25693)\u001b[0m 2023-09-19 19:55:36,657\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25700)\u001b[0m 2023-09-19 19:55:38,552\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25695)\u001b[0m 2023-09-19 19:55:40,330\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25695)\u001b[0m 2023-09-19 19:55:40,357\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_0313cc6b50e24fd1a14986bbe5deb4c9\n",
      "\u001b[2m\u001b[36m(PPO pid=25695)\u001b[0m 2023-09-19 19:55:40,357\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2169, '_timesteps_total': None, '_time_total': 423.65394473075867, '_episodes_total': 709}\n",
      "\u001b[2m\u001b[36m(PPO pid=25706)\u001b[0m 2023-09-19 19:55:54,621\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25703)\u001b[0m 2023-09-19 19:55:54,621\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25707)\u001b[0m 2023-09-19 19:55:56,476\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25706)\u001b[0m 2023-09-19 19:55:58,217\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25706)\u001b[0m 2023-09-19 19:55:58,249\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_7d6c390a7bc344999b6aa2cc180553b3\n",
      "\u001b[2m\u001b[36m(PPO pid=25706)\u001b[0m 2023-09-19 19:55:58,250\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2169, '_timesteps_total': None, '_time_total': 423.65394473075867, '_episodes_total': 709}\n",
      "\u001b[2m\u001b[36m(PPO pid=25714)\u001b[0m 2023-09-19 19:56:12,742\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25710)\u001b[0m 2023-09-19 19:56:12,742\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25715)\u001b[0m 2023-09-19 19:56:14,629\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25714)\u001b[0m 2023-09-19 19:56:16,412\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25714)\u001b[0m 2023-09-19 19:56:16,441\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_30619609be104d8b810a7725065fb54f\n",
      "\u001b[2m\u001b[36m(PPO pid=25714)\u001b[0m 2023-09-19 19:56:16,441\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2221, '_timesteps_total': None, '_time_total': 433.69952154159546, '_episodes_total': 726}\n",
      "2023-09-19 19:56:27,684\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.151433) into trial 76be2_00000 (score = 0.139538)\n",
      "\n",
      "2023-09-19 19:56:27,685\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00042620402011791164 --- (* 0.8) --> 0.00034096321609432934\n",
      "gamma : 0.767619212814191 --- (* 1.2) --> 0.9211430553770291\n",
      "clip_param : 0.17033279107656701 --- (* 0.8) --> 0.1362662328612536\n",
      "kl_coeff : 1.0745143580061394 --- (resample) --> 1.1318989117008895\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25719)\u001b[0m 2023-09-19 19:56:30,823\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25718)\u001b[0m 2023-09-19 19:56:30,823\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25722)\u001b[0m 2023-09-19 19:56:32,644\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25719)\u001b[0m 2023-09-19 19:56:34,427\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25719)\u001b[0m 2023-09-19 19:56:34,459\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_0099377315a84dc6a123de52455af889\n",
      "\u001b[2m\u001b[36m(PPO pid=25719)\u001b[0m 2023-09-19 19:56:34,459\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2221, '_timesteps_total': None, '_time_total': 433.6730034351349, '_episodes_total': 726}\n",
      "\u001b[2m\u001b[36m(PPO pid=25727)\u001b[0m 2023-09-19 19:56:48,764\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25725)\u001b[0m 2023-09-19 19:56:48,764\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25728)\u001b[0m 2023-09-19 19:56:50,705\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25727)\u001b[0m 2023-09-19 19:56:52,437\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25727)\u001b[0m 2023-09-19 19:56:52,467\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_251ac0d8edb94791a645b4fc1f9549a9\n",
      "\u001b[2m\u001b[36m(PPO pid=25727)\u001b[0m 2023-09-19 19:56:52,467\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2221, '_timesteps_total': None, '_time_total': 433.6730034351349, '_episodes_total': 726}\n",
      "2023-09-19 19:57:03,780\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.163239) into trial 76be2_00000 (score = 0.142096)\n",
      "\n",
      "2023-09-19 19:57:03,780\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00042620402011791164 --- (* 1.2) --> 0.000511444824141494\n",
      "gamma : 0.767619212814191 --- (* 1.2) --> 0.9211430553770291\n",
      "clip_param : 0.17033279107656701 --- (* 0.8) --> 0.1362662328612536\n",
      "kl_coeff : 1.0745143580061394 --- (* 0.8) --> 0.8596114864049116\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25734)\u001b[0m 2023-09-19 19:57:07,013\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25732)\u001b[0m 2023-09-19 19:57:07,013\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25735)\u001b[0m 2023-09-19 19:57:08,947\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25734)\u001b[0m 2023-09-19 19:57:10,672\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25734)\u001b[0m 2023-09-19 19:57:10,702\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c41689031428414683850047e1e042e5\n",
      "\u001b[2m\u001b[36m(PPO pid=25734)\u001b[0m 2023-09-19 19:57:10,702\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2273, '_timesteps_total': None, '_time_total': 443.8630976676941, '_episodes_total': 743}\n",
      "\u001b[2m\u001b[36m(PPO pid=25739)\u001b[0m 2023-09-19 19:57:24,967\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25738)\u001b[0m 2023-09-19 19:57:24,967\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25740)\u001b[0m 2023-09-19 19:57:26,831\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25739)\u001b[0m 2023-09-19 19:57:28,561\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25739)\u001b[0m 2023-09-19 19:57:28,590\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c2dd49eed827426b98236ce49cb55551\n",
      "\u001b[2m\u001b[36m(PPO pid=25739)\u001b[0m 2023-09-19 19:57:28,590\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2273, '_timesteps_total': None, '_time_total': 443.8630976676941, '_episodes_total': 743}\n",
      "\u001b[2m\u001b[36m(PPO pid=25745)\u001b[0m 2023-09-19 19:57:42,945\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25743)\u001b[0m 2023-09-19 19:57:42,945\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25746)\u001b[0m 2023-09-19 19:57:44,951\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25745)\u001b[0m 2023-09-19 19:57:46,683\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25745)\u001b[0m 2023-09-19 19:57:46,711\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_7f3c08992b714da386a3bfc7b6ad2181\n",
      "\u001b[2m\u001b[36m(PPO pid=25745)\u001b[0m 2023-09-19 19:57:46,711\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2326, '_timesteps_total': None, '_time_total': 454.0533175468445, '_episodes_total': 760}\n",
      "2023-09-19 19:57:57,856\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.153327) into trial 76be2_00001 (score = 0.144186)\n",
      "\n",
      "2023-09-19 19:57:57,857\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.000511444824141494 --- (* 0.8) --> 0.0004091558593131952\n",
      "gamma : 0.9211430553770291 --- (resample) --> 0.9751874713288992\n",
      "clip_param : 0.1362662328612536 --- (* 1.2) --> 0.16351947943350434\n",
      "kl_coeff : 0.8596114864049116 --- (* 0.8) --> 0.6876891891239293\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25750)\u001b[0m 2023-09-19 19:57:59,706\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25749)\u001b[0m 2023-09-19 19:57:59,706\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25753)\u001b[0m 2023-09-19 19:58:01,678\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25750)\u001b[0m 2023-09-19 19:58:03,409\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25750)\u001b[0m 2023-09-19 19:58:03,438\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_36de46ba8fbe40018d29972df7ab68c6\n",
      "\u001b[2m\u001b[36m(PPO pid=25750)\u001b[0m 2023-09-19 19:58:03,438\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2325, '_timesteps_total': None, '_time_total': 453.9417130947113, '_episodes_total': 760}\n",
      "\u001b[2m\u001b[36m(PPO pid=25759)\u001b[0m 2023-09-19 19:58:18,102\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25757)\u001b[0m 2023-09-19 19:58:18,102\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25760)\u001b[0m 2023-09-19 19:58:19,938\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25759)\u001b[0m 2023-09-19 19:58:21,731\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25759)\u001b[0m 2023-09-19 19:58:21,760\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_54337bf64c59433588f75cd754bc5088\n",
      "\u001b[2m\u001b[36m(PPO pid=25759)\u001b[0m 2023-09-19 19:58:21,760\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2325, '_timesteps_total': None, '_time_total': 453.9417130947113, '_episodes_total': 760}\n",
      "2023-09-19 19:58:33,027\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.148264) into trial 76be2_00001 (score = 0.140287)\n",
      "\n",
      "2023-09-19 19:58:33,028\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.000511444824141494 --- (* 0.8) --> 0.0004091558593131952\n",
      "gamma : 0.9211430553770291 --- (* 1.2) --> 1.105371666452435\n",
      "clip_param : 0.1362662328612536 --- (* 0.8) --> 0.1090129862890029\n",
      "kl_coeff : 0.8596114864049116 --- (* 0.8) --> 0.6876891891239293\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25765)\u001b[0m 2023-09-19 19:58:35,920\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25763)\u001b[0m 2023-09-19 19:58:35,920\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25766)\u001b[0m 2023-09-19 19:58:37,763\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25765)\u001b[0m 2023-09-19 19:58:39,595\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25765)\u001b[0m 2023-09-19 19:58:39,627\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_919bac03d24745149ff4eac54f1a72cb\n",
      "\u001b[2m\u001b[36m(PPO pid=25765)\u001b[0m 2023-09-19 19:58:39,627\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2377, '_timesteps_total': None, '_time_total': 464.0292191505432, '_episodes_total': 777}\n",
      "2023-09-19 19:58:50,930\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=25772)\u001b[0m 2023-09-19 19:58:54,056\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25769)\u001b[0m 2023-09-19 19:58:54,056\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25773)\u001b[0m 2023-09-19 19:58:55,966\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25772)\u001b[0m 2023-09-19 19:58:57,714\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25772)\u001b[0m 2023-09-19 19:58:57,747\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_9248f408b84240fdbf876302c7efecb9\n",
      "\u001b[2m\u001b[36m(PPO pid=25772)\u001b[0m 2023-09-19 19:58:57,747\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2377, '_timesteps_total': None, '_time_total': 464.0292191505432, '_episodes_total': 777}\n",
      "\u001b[2m\u001b[36m(PPO pid=25779)\u001b[0m 2023-09-19 19:59:11,875\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25776)\u001b[0m 2023-09-19 19:59:11,875\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25780)\u001b[0m 2023-09-19 19:59:13,770\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25779)\u001b[0m 2023-09-19 19:59:15,548\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25779)\u001b[0m 2023-09-19 19:59:15,593\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_690284c89ac34d54b9b096aa06920a0f\n",
      "\u001b[2m\u001b[36m(PPO pid=25779)\u001b[0m 2023-09-19 19:59:15,593\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2429, '_timesteps_total': None, '_time_total': 474.111328125, '_episodes_total': 794}\n",
      "\u001b[2m\u001b[36m(PPO pid=25784)\u001b[0m 2023-09-19 19:59:29,922\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25783)\u001b[0m 2023-09-19 19:59:29,922\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25785)\u001b[0m 2023-09-19 19:59:31,811\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25784)\u001b[0m 2023-09-19 19:59:33,609\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25784)\u001b[0m 2023-09-19 19:59:33,638\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c3cb6fc8de634a97804b30689e0ed582\n",
      "\u001b[2m\u001b[36m(PPO pid=25784)\u001b[0m 2023-09-19 19:59:33,638\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2430, '_timesteps_total': None, '_time_total': 474.2039918899536, '_episodes_total': 794}\n",
      "\u001b[2m\u001b[36m(PPO pid=25791)\u001b[0m 2023-09-19 19:59:47,846\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25788)\u001b[0m 2023-09-19 19:59:47,846\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25792)\u001b[0m 2023-09-19 19:59:49,786\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25791)\u001b[0m 2023-09-19 19:59:51,506\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25791)\u001b[0m 2023-09-19 19:59:51,534\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c444b17ff1224d12b57218aaf2abd0a1\n",
      "\u001b[2m\u001b[36m(PPO pid=25791)\u001b[0m 2023-09-19 19:59:51,534\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2481, '_timesteps_total': None, '_time_total': 484.207053899765, '_episodes_total': 811}\n",
      "\u001b[2m\u001b[36m(PPO pid=25797)\u001b[0m 2023-09-19 20:00:05,985\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25795)\u001b[0m 2023-09-19 20:00:05,985\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25798)\u001b[0m 2023-09-19 20:00:07,984\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25797)\u001b[0m 2023-09-19 20:00:09,702\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25797)\u001b[0m 2023-09-19 20:00:09,745\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ced95b21864643dc8c06bfad21b61f45\n",
      "\u001b[2m\u001b[36m(PPO pid=25797)\u001b[0m 2023-09-19 20:00:09,745\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2482, '_timesteps_total': None, '_time_total': 484.2476499080658, '_episodes_total': 811}\n",
      "\u001b[2m\u001b[36m(PPO pid=25803)\u001b[0m 2023-09-19 20:00:24,069\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25801)\u001b[0m 2023-09-19 20:00:24,069\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25804)\u001b[0m 2023-09-19 20:00:26,186\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25803)\u001b[0m 2023-09-19 20:00:27,899\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25803)\u001b[0m 2023-09-19 20:00:27,935\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_e0305d48a5014089b3206d5212b84bad\n",
      "\u001b[2m\u001b[36m(PPO pid=25803)\u001b[0m 2023-09-19 20:00:27,935\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2532, '_timesteps_total': None, '_time_total': 494.2384102344513, '_episodes_total': 828}\n",
      "\u001b[2m\u001b[36m(PPO pid=25810)\u001b[0m 2023-09-19 20:00:42,170\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25807)\u001b[0m 2023-09-19 20:00:42,170\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25811)\u001b[0m 2023-09-19 20:00:44,292\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25810)\u001b[0m 2023-09-19 20:00:46,086\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25810)\u001b[0m 2023-09-19 20:00:46,115\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_a7b8b5e6f9ba41bc92eb74ae2863ad6b\n",
      "\u001b[2m\u001b[36m(PPO pid=25810)\u001b[0m 2023-09-19 20:00:46,115\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2533, '_timesteps_total': None, '_time_total': 494.2519977092743, '_episodes_total': 828}\n",
      "2023-09-19 20:00:57,378\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.150640) into trial 76be2_00001 (score = 0.141638)\n",
      "\n",
      "2023-09-19 20:00:57,378\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.000511444824141494 --- (* 1.2) --> 0.0006137337889697928\n",
      "gamma : 0.9211430553770291 --- (* 1.2) --> 1.105371666452435\n",
      "clip_param : 0.1362662328612536 --- (* 1.2) --> 0.16351947943350434\n",
      "kl_coeff : 0.8596114864049116 --- (* 0.8) --> 0.6876891891239293\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25816)\u001b[0m 2023-09-19 20:01:00,156\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25814)\u001b[0m 2023-09-19 20:01:00,156\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25819)\u001b[0m 2023-09-19 20:01:02,284\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25816)\u001b[0m 2023-09-19 20:01:04,110\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25816)\u001b[0m 2023-09-19 20:01:04,139\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c8107ce2aa044b289be3c6f7efbe395d\n",
      "\u001b[2m\u001b[36m(PPO pid=25816)\u001b[0m 2023-09-19 20:01:04,139\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2583, '_timesteps_total': None, '_time_total': 504.4389913082123, '_episodes_total': 845}\n",
      "2023-09-19 20:01:15,464\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=25824)\u001b[0m 2023-09-19 20:01:18,034\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25823)\u001b[0m 2023-09-19 20:01:18,034\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25825)\u001b[0m 2023-09-19 20:01:20,135\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25824)\u001b[0m 2023-09-19 20:01:21,914\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25824)\u001b[0m 2023-09-19 20:01:21,951\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_cf0fe600a72147d388ba2391a22b27a1\n",
      "\u001b[2m\u001b[36m(PPO pid=25824)\u001b[0m 2023-09-19 20:01:21,951\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2583, '_timesteps_total': None, '_time_total': 504.4389913082123, '_episodes_total': 845}\n",
      "2023-09-19 20:01:33,231\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=25829)\u001b[0m 2023-09-19 20:01:36,243\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25828)\u001b[0m 2023-09-19 20:01:36,243\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25830)\u001b[0m 2023-09-19 20:01:38,400\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25829)\u001b[0m 2023-09-19 20:01:40,179\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25829)\u001b[0m 2023-09-19 20:01:40,208\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_4513e2e72abb46e3b433137e9a758428\n",
      "\u001b[2m\u001b[36m(PPO pid=25829)\u001b[0m 2023-09-19 20:01:40,208\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2633, '_timesteps_total': None, '_time_total': 514.5299038887024, '_episodes_total': 862}\n",
      "\u001b[2m\u001b[36m(PPO pid=25835)\u001b[0m 2023-09-19 20:01:54,079\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25833)\u001b[0m 2023-09-19 20:01:54,079\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25836)\u001b[0m 2023-09-19 20:01:56,350\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25835)\u001b[0m 2023-09-19 20:01:58,175\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25835)\u001b[0m 2023-09-19 20:01:58,206\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_48dad1e4071d46b59b9d94be49600674\n",
      "\u001b[2m\u001b[36m(PPO pid=25835)\u001b[0m 2023-09-19 20:01:58,206\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2634, '_timesteps_total': None, '_time_total': 514.6052091121674, '_episodes_total': 862}\n",
      "2023-09-19 20:02:09,336\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.133327) into trial 76be2_00001 (score = 0.128641)\n",
      "\n",
      "2023-09-19 20:02:09,337\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.000511444824141494 --- (resample) --> 0.00012978252181352118\n",
      "gamma : 0.9211430553770291 --- (resample) --> 0.9711624947197661\n",
      "clip_param : 0.1362662328612536 --- (* 0.8) --> 0.1090129862890029\n",
      "kl_coeff : 0.8596114864049116 --- (resample) --> 1.1706737624972519\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25841)\u001b[0m 2023-09-19 20:02:12,284\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25839)\u001b[0m 2023-09-19 20:02:12,284\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25844)\u001b[0m 2023-09-19 20:02:14,395\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25841)\u001b[0m 2023-09-19 20:02:16,153\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25841)\u001b[0m 2023-09-19 20:02:16,182\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_f7fc98562380473bab36b71e292be6b5\n",
      "\u001b[2m\u001b[36m(PPO pid=25841)\u001b[0m 2023-09-19 20:02:16,183\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2684, '_timesteps_total': None, '_time_total': 524.7017931938171, '_episodes_total': 879}\n",
      "\u001b[2m\u001b[36m(PPO pid=25850)\u001b[0m 2023-09-19 20:02:30,084\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25847)\u001b[0m 2023-09-19 20:02:30,084\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25851)\u001b[0m 2023-09-19 20:02:32,152\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25850)\u001b[0m 2023-09-19 20:02:33,912\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25850)\u001b[0m 2023-09-19 20:02:33,941\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_a11e190185ba4a45a1f6bdcd8ce99d70\n",
      "\u001b[2m\u001b[36m(PPO pid=25850)\u001b[0m 2023-09-19 20:02:33,941\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2684, '_timesteps_total': None, '_time_total': 524.7017931938171, '_episodes_total': 879}\n",
      "2023-09-19 20:02:45,083\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.142694) into trial 76be2_00001 (score = 0.140357)\n",
      "\n",
      "2023-09-19 20:02:45,084\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.000511444824141494 --- (* 0.8) --> 0.0004091558593131952\n",
      "gamma : 0.9211430553770291 --- (* 1.2) --> 1.105371666452435\n",
      "clip_param : 0.1362662328612536 --- (* 1.2) --> 0.16351947943350434\n",
      "kl_coeff : 0.8596114864049116 --- (* 1.2) --> 1.0315337836858938\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25856)\u001b[0m 2023-09-19 20:02:47,137\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25854)\u001b[0m 2023-09-19 20:02:47,137\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=25856)\u001b[0m 2023-09-19 20:02:51,134\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25856)\u001b[0m 2023-09-19 20:02:51,171\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_88957963a7d346f29c76d523c9b60fbb\n",
      "\u001b[2m\u001b[36m(PPO pid=25856)\u001b[0m 2023-09-19 20:02:51,172\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2735, '_timesteps_total': None, '_time_total': 534.7069981098175, '_episodes_total': 896}\n",
      "2023-09-19 20:03:02,337\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=25864)\u001b[0m 2023-09-19 20:03:05,279\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25861)\u001b[0m 2023-09-19 20:03:05,279\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25865)\u001b[0m 2023-09-19 20:03:07,387\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25864)\u001b[0m 2023-09-19 20:03:09,111\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25864)\u001b[0m 2023-09-19 20:03:09,142\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_9d97cd5f63bb4f8e9042c1800a9bf01b\n",
      "\u001b[2m\u001b[36m(PPO pid=25864)\u001b[0m 2023-09-19 20:03:09,142\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2735, '_timesteps_total': None, '_time_total': 534.7069981098175, '_episodes_total': 896}\n",
      "\u001b[2m\u001b[36m(PPO pid=25878)\u001b[0m 2023-09-19 20:03:23,268\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25868)\u001b[0m 2023-09-19 20:03:23,268\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25879)\u001b[0m 2023-09-19 20:03:25,386\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25878)\u001b[0m 2023-09-19 20:03:27,138\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25878)\u001b[0m 2023-09-19 20:03:27,174\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c0eddee817404a63ba96452f91d69d52\n",
      "\u001b[2m\u001b[36m(PPO pid=25878)\u001b[0m 2023-09-19 20:03:27,174\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2785, '_timesteps_total': None, '_time_total': 544.7654507160187, '_episodes_total': 913}\n",
      "2023-09-19 20:03:38,267\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.138361) into trial 76be2_00000 (score = 0.124421)\n",
      "\n",
      "2023-09-19 20:03:38,267\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.0004091558593131952 --- (* 1.2) --> 0.0004909870311758343\n",
      "gamma : 1.105371666452435 --- (* 0.8) --> 0.8842973331619479\n",
      "clip_param : 0.16351947943350434 --- (* 1.2) --> 0.1962233753202052\n",
      "kl_coeff : 1.0315337836858938 --- (* 0.8) --> 0.8252270269487151\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25886)\u001b[0m 2023-09-19 20:03:41,024\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25882)\u001b[0m 2023-09-19 20:03:41,024\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25888)\u001b[0m 2023-09-19 20:03:43,093\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25886)\u001b[0m 2023-09-19 20:03:44,876\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25886)\u001b[0m 2023-09-19 20:03:44,906\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_2fb8d12b918a4e2b804581c6face0473\n",
      "\u001b[2m\u001b[36m(PPO pid=25886)\u001b[0m 2023-09-19 20:03:44,906\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2786, '_timesteps_total': None, '_time_total': 544.8656740188599, '_episodes_total': 913}\n",
      "\u001b[2m\u001b[36m(PPO pid=25895)\u001b[0m 2023-09-19 20:03:59,259\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25891)\u001b[0m 2023-09-19 20:03:59,259\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25896)\u001b[0m 2023-09-19 20:04:01,369\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25895)\u001b[0m 2023-09-19 20:04:03,090\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25895)\u001b[0m 2023-09-19 20:04:03,118\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_f7402d6285f54510858fc017e6bfc7d6\n",
      "\u001b[2m\u001b[36m(PPO pid=25895)\u001b[0m 2023-09-19 20:04:03,118\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2786, '_timesteps_total': None, '_time_total': 544.8656740188599, '_episodes_total': 913}\n",
      "2023-09-19 20:04:14,347\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.138263) into trial 76be2_00000 (score = 0.125510)\n",
      "\n",
      "2023-09-19 20:04:14,347\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.0004091558593131952 --- (* 0.8) --> 0.0003273246874505562\n",
      "gamma : 1.105371666452435 --- (* 0.8) --> 0.8842973331619479\n",
      "clip_param : 0.16351947943350434 --- (* 1.2) --> 0.1962233753202052\n",
      "kl_coeff : 1.0315337836858938 --- (resample) --> 0.944715225796841\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25901)\u001b[0m 2023-09-19 20:04:17,149\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25899)\u001b[0m 2023-09-19 20:04:17,149\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25904)\u001b[0m 2023-09-19 20:04:19,231\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25901)\u001b[0m 2023-09-19 20:04:21,032\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25901)\u001b[0m 2023-09-19 20:04:21,064\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_04862b0f41a546959513869f0b7e180e\n",
      "\u001b[2m\u001b[36m(PPO pid=25901)\u001b[0m 2023-09-19 20:04:21,064\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2837, '_timesteps_total': None, '_time_total': 554.9146151542664, '_episodes_total': 930}\n",
      "\u001b[2m\u001b[36m(PPO pid=25910)\u001b[0m 2023-09-19 20:04:35,323\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25907)\u001b[0m 2023-09-19 20:04:35,323\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25911)\u001b[0m 2023-09-19 20:04:37,374\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25910)\u001b[0m 2023-09-19 20:04:39,126\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25910)\u001b[0m 2023-09-19 20:04:39,154\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_fbf171495eae4f4d8a6a9e671dd97799\n",
      "\u001b[2m\u001b[36m(PPO pid=25910)\u001b[0m 2023-09-19 20:04:39,154\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2837, '_timesteps_total': None, '_time_total': 554.9146151542664, '_episodes_total': 930}\n",
      "2023-09-19 20:04:50,407\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.138724) into trial 76be2_00000 (score = 0.117347)\n",
      "\n",
      "2023-09-19 20:04:50,407\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.0004091558593131952 --- (* 1.2) --> 0.0004909870311758343\n",
      "gamma : 1.105371666452435 --- (* 1.2) --> 1.3264459997429219\n",
      "clip_param : 0.16351947943350434 --- (* 1.2) --> 0.1962233753202052\n",
      "kl_coeff : 1.0315337836858938 --- (* 0.8) --> 0.8252270269487151\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25917)\u001b[0m 2023-09-19 20:04:53,205\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25914)\u001b[0m 2023-09-19 20:04:53,205\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=25917)\u001b[0m 2023-09-19 20:04:57,132\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25917)\u001b[0m 2023-09-19 20:04:57,163\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c56fe8dd6a24409da973c66d4e121c1b\n",
      "\u001b[2m\u001b[36m(PPO pid=25917)\u001b[0m 2023-09-19 20:04:57,163\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2887, '_timesteps_total': None, '_time_total': 564.9249358177185, '_episodes_total': 947}\n",
      "\u001b[2m\u001b[36m(PPO pid=25929)\u001b[0m 2023-09-19 20:05:11,415\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25924)\u001b[0m 2023-09-19 20:05:11,415\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25930)\u001b[0m 2023-09-19 20:05:13,597\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25929)\u001b[0m 2023-09-19 20:05:15,308\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25929)\u001b[0m 2023-09-19 20:05:15,335\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_f2a3176174bf4434bfc131f6d6013cea\n",
      "\u001b[2m\u001b[36m(PPO pid=25929)\u001b[0m 2023-09-19 20:05:15,335\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2887, '_timesteps_total': None, '_time_total': 564.9249358177185, '_episodes_total': 947}\n",
      "\u001b[2m\u001b[36m(PPO pid=25945)\u001b[0m 2023-09-19 20:05:29,294\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25933)\u001b[0m 2023-09-19 20:05:29,294\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25946)\u001b[0m 2023-09-19 20:05:31,479\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25945)\u001b[0m 2023-09-19 20:05:33,228\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25945)\u001b[0m 2023-09-19 20:05:33,258\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_a38a6d72a88140b7a01be45e96fc3ed3\n",
      "\u001b[2m\u001b[36m(PPO pid=25945)\u001b[0m 2023-09-19 20:05:33,258\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2937, '_timesteps_total': None, '_time_total': 575.1188378334045, '_episodes_total': 964}\n",
      "2023-09-19 20:05:44,461\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.145955) into trial 76be2_00001 (score = 0.112224)\n",
      "\n",
      "2023-09-19 20:05:44,462\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.0004909870311758343 --- (* 0.8) --> 0.00039278962494066746\n",
      "gamma : 1.3264459997429219 --- (* 1.2) --> 1.5917351996915061\n",
      "clip_param : 0.1962233753202052 --- (* 0.8) --> 0.15697870025616417\n",
      "kl_coeff : 0.8252270269487151 --- (resample) --> 1.0040109361577447\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25951)\u001b[0m 2023-09-19 20:05:47,389\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25949)\u001b[0m 2023-09-19 20:05:47,389\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25954)\u001b[0m 2023-09-19 20:05:49,579\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25951)\u001b[0m 2023-09-19 20:05:51,332\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25951)\u001b[0m 2023-09-19 20:05:51,368\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d81b72dca49e4fd7929d3767c1559857\n",
      "\u001b[2m\u001b[36m(PPO pid=25951)\u001b[0m 2023-09-19 20:05:51,368\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2936, '_timesteps_total': None, '_time_total': 575.0530934333801, '_episodes_total': 962}\n",
      "\u001b[2m\u001b[36m(PPO pid=25960)\u001b[0m 2023-09-19 20:06:05,442\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25957)\u001b[0m 2023-09-19 20:06:05,442\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25961)\u001b[0m 2023-09-19 20:06:07,624\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25960)\u001b[0m 2023-09-19 20:06:09,389\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25960)\u001b[0m 2023-09-19 20:06:09,417\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_03f1949e764b4d9bbb10e9c5b0cbdca6\n",
      "\u001b[2m\u001b[36m(PPO pid=25960)\u001b[0m 2023-09-19 20:06:09,417\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2936, '_timesteps_total': None, '_time_total': 575.0530934333801, '_episodes_total': 962}\n",
      "\u001b[2m\u001b[36m(PPO pid=25966)\u001b[0m 2023-09-19 20:06:23,128\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25964)\u001b[0m 2023-09-19 20:06:23,128\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25967)\u001b[0m 2023-09-19 20:06:25,365\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25966)\u001b[0m 2023-09-19 20:06:27,184\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25966)\u001b[0m 2023-09-19 20:06:27,219\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_6fabe10ca5e54e21a4e067cff58e5db6\n",
      "\u001b[2m\u001b[36m(PPO pid=25966)\u001b[0m 2023-09-19 20:06:27,219\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2985, '_timesteps_total': None, '_time_total': 585.0885963439941, '_episodes_total': 977}\n",
      "2023-09-19 20:06:38,341\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.147472) into trial 76be2_00000 (score = 0.146325)\n",
      "\n",
      "2023-09-19 20:06:38,342\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00039278962494066746 --- (* 0.8) --> 0.00031423169995253397\n",
      "gamma : 1.5917351996915061 --- (* 0.8) --> 1.273388159753205\n",
      "clip_param : 0.15697870025616417 --- (* 0.8) --> 0.12558296020493134\n",
      "kl_coeff : 1.0040109361577447 --- (resample) --> 0.9568306387173839\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=25973)\u001b[0m 2023-09-19 20:06:41,501\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25971)\u001b[0m 2023-09-19 20:06:41,501\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25976)\u001b[0m 2023-09-19 20:06:43,679\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25973)\u001b[0m 2023-09-19 20:06:45,455\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25973)\u001b[0m 2023-09-19 20:06:45,482\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ab7abd2a9dae4b90be83705a9d0dc7bf\n",
      "\u001b[2m\u001b[36m(PPO pid=25973)\u001b[0m 2023-09-19 20:06:45,482\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2985, '_timesteps_total': None, '_time_total': 585.1164584159851, '_episodes_total': 977}\n",
      "2023-09-19 20:06:56,772\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=25983)\u001b[0m 2023-09-19 20:06:59,288\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25979)\u001b[0m 2023-09-19 20:06:59,288\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25984)\u001b[0m 2023-09-19 20:07:01,550\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25983)\u001b[0m 2023-09-19 20:07:03,426\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25983)\u001b[0m 2023-09-19 20:07:03,457\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_61ca1b7a00824436b4bc839b6ce6df7a\n",
      "\u001b[2m\u001b[36m(PPO pid=25983)\u001b[0m 2023-09-19 20:07:03,457\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 2985, '_timesteps_total': None, '_time_total': 585.1164584159851, '_episodes_total': 977}\n",
      "2023-09-19 20:07:14,669\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=25990)\u001b[0m 2023-09-19 20:07:17,548\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25987)\u001b[0m 2023-09-19 20:07:17,548\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25991)\u001b[0m 2023-09-19 20:07:19,727\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25990)\u001b[0m 2023-09-19 20:07:21,491\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25990)\u001b[0m 2023-09-19 20:07:21,519\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_4e8a00068c5448a6be81863f9a7222ef\n",
      "\u001b[2m\u001b[36m(PPO pid=25990)\u001b[0m 2023-09-19 20:07:21,519\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3034, '_timesteps_total': None, '_time_total': 595.2592446804047, '_episodes_total': 992}\n",
      "\u001b[2m\u001b[36m(PPO pid=25996)\u001b[0m 2023-09-19 20:07:35,283\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25994)\u001b[0m 2023-09-19 20:07:35,283\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=25996)\u001b[0m 2023-09-19 20:07:39,330\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25996)\u001b[0m 2023-09-19 20:07:39,356\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_20b59a5e4b0d410db9ae41cbe2df9ee2\n",
      "\u001b[2m\u001b[36m(PPO pid=25996)\u001b[0m 2023-09-19 20:07:39,356\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3031, '_timesteps_total': None, '_time_total': 595.2304012775421, '_episodes_total': 992}\n",
      "2023-09-19 20:07:50,607\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.146296) into trial 76be2_00000 (score = 0.123028)\n",
      "\n",
      "2023-09-19 20:07:50,607\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00039278962494066746 --- (resample) --> 0.0007280492864707276\n",
      "gamma : 1.5917351996915061 --- (* 1.2) --> 1.9100822396298072\n",
      "clip_param : 0.15697870025616417 --- (* 1.2) --> 0.188374440307397\n",
      "kl_coeff : 1.0040109361577447 --- (resample) --> 0.7964583881297731\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26004)\u001b[0m 2023-09-19 20:07:53,531\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26000)\u001b[0m 2023-09-19 20:07:53,531\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26006)\u001b[0m 2023-09-19 20:07:55,729\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26004)\u001b[0m 2023-09-19 20:07:57,511\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26004)\u001b[0m 2023-09-19 20:07:57,537\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_e3d3babb5cb04d3bbb9cea65062593ba\n",
      "\u001b[2m\u001b[36m(PPO pid=26004)\u001b[0m 2023-09-19 20:07:57,537\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3082, '_timesteps_total': None, '_time_total': 605.3056879043579, '_episodes_total': 1007}\n",
      "\u001b[2m\u001b[36m(PPO pid=26011)\u001b[0m 2023-09-19 20:08:11,236\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26009)\u001b[0m 2023-09-19 20:08:11,236\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26012)\u001b[0m 2023-09-19 20:08:13,530\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26011)\u001b[0m 2023-09-19 20:08:15,299\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26011)\u001b[0m 2023-09-19 20:08:15,335\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_86cc0c2c52ae4d408042acdb4ea43d33\n",
      "\u001b[2m\u001b[36m(PPO pid=26011)\u001b[0m 2023-09-19 20:08:15,335\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3082, '_timesteps_total': None, '_time_total': 605.3056879043579, '_episodes_total': 1007}\n",
      "2023-09-19 20:08:26,513\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.138089) into trial 76be2_00000 (score = 0.124374)\n",
      "\n",
      "2023-09-19 20:08:26,514\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00039278962494066746 --- (resample) --> 0.0001659113150399291\n",
      "gamma : 1.5917351996915061 --- (* 1.2) --> 1.9100822396298072\n",
      "clip_param : 0.15697870025616417 --- (* 1.2) --> 0.188374440307397\n",
      "kl_coeff : 1.0040109361577447 --- (* 0.8) --> 0.8032087489261959\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26017)\u001b[0m 2023-09-19 20:08:29,604\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26015)\u001b[0m 2023-09-19 20:08:29,604\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26019)\u001b[0m 2023-09-19 20:08:31,941\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26017)\u001b[0m 2023-09-19 20:08:33,989\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26017)\u001b[0m 2023-09-19 20:08:34,029\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_09466fdcfa2846fa8d1e1b167f33892f\n",
      "\u001b[2m\u001b[36m(PPO pid=26017)\u001b[0m 2023-09-19 20:08:34,030\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3130, '_timesteps_total': None, '_time_total': 615.4243030548096, '_episodes_total': 1022}\n",
      "\u001b[2m\u001b[36m(PPO pid=26047)\u001b[0m 2023-09-19 20:08:48,283\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26022)\u001b[0m 2023-09-19 20:08:48,283\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26048)\u001b[0m 2023-09-19 20:08:50,599\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26047)\u001b[0m 2023-09-19 20:08:52,361\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26047)\u001b[0m 2023-09-19 20:08:52,388\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_3c30063d98a14cdc958b0137e2849643\n",
      "\u001b[2m\u001b[36m(PPO pid=26047)\u001b[0m 2023-09-19 20:08:52,388\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3130, '_timesteps_total': None, '_time_total': 615.4243030548096, '_episodes_total': 1022}\n",
      "\u001b[2m\u001b[36m(PPO pid=26056)\u001b[0m 2023-09-19 20:09:06,578\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26051)\u001b[0m 2023-09-19 20:09:06,578\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=26056)\u001b[0m 2023-09-19 20:09:10,732\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26056)\u001b[0m 2023-09-19 20:09:10,758\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_1cde26d05b974ded8562a35aec64a630\n",
      "\u001b[2m\u001b[36m(PPO pid=26056)\u001b[0m 2023-09-19 20:09:10,759\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3175, '_timesteps_total': None, '_time_total': 625.4441282749176, '_episodes_total': 1037}\n",
      "2023-09-19 20:09:22,042\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.149503) into trial 76be2_00001 (score = 0.108675)\n",
      "\n",
      "2023-09-19 20:09:22,043\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.0001659113150399291 --- (* 0.8) --> 0.00013272905203194328\n",
      "gamma : 1.9100822396298072 --- (* 1.2) --> 2.2920986875557685\n",
      "clip_param : 0.188374440307397 --- (* 0.8) --> 0.1506995522459176\n",
      "kl_coeff : 0.8032087489261959 --- (* 1.2) --> 0.963850498711435\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26065)\u001b[0m 2023-09-19 20:09:25,347\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26060)\u001b[0m 2023-09-19 20:09:25,347\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26068)\u001b[0m 2023-09-19 20:09:27,588\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26065)\u001b[0m 2023-09-19 20:09:29,323\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26065)\u001b[0m 2023-09-19 20:09:29,352\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_9adf258211ad48abaea84e574227b1ed\n",
      "\u001b[2m\u001b[36m(PPO pid=26065)\u001b[0m 2023-09-19 20:09:29,352\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3178, '_timesteps_total': None, '_time_total': 625.5477590560913, '_episodes_total': 1037}\n",
      "\u001b[2m\u001b[36m(PPO pid=26079)\u001b[0m 2023-09-19 20:09:43,338\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26073)\u001b[0m 2023-09-19 20:09:43,338\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26080)\u001b[0m 2023-09-19 20:09:45,804\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26079)\u001b[0m 2023-09-19 20:09:47,594\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26079)\u001b[0m 2023-09-19 20:09:47,622\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d71ca0295d534b38b053e16ad22c8d35\n",
      "\u001b[2m\u001b[36m(PPO pid=26079)\u001b[0m 2023-09-19 20:09:47,622\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3178, '_timesteps_total': None, '_time_total': 625.5477590560913, '_episodes_total': 1037}\n",
      "\u001b[2m\u001b[36m(PPO pid=26085)\u001b[0m 2023-09-19 20:10:01,335\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26083)\u001b[0m 2023-09-19 20:10:01,335\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26086)\u001b[0m 2023-09-19 20:10:03,809\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26085)\u001b[0m 2023-09-19 20:10:05,693\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26085)\u001b[0m 2023-09-19 20:10:05,731\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_6b80a8b300e7457cbdff6c8061ae8302\n",
      "\u001b[2m\u001b[36m(PPO pid=26085)\u001b[0m 2023-09-19 20:10:05,731\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3225, '_timesteps_total': None, '_time_total': 635.7452051639557, '_episodes_total': 1052}\n",
      "2023-09-19 20:10:16,990\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.147889) into trial 76be2_00000 (score = 0.139640)\n",
      "\n",
      "2023-09-19 20:10:16,991\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00013272905203194328 --- (* 0.8) --> 0.00010618324162555463\n",
      "gamma : 2.2920986875557685 --- (resample) --> 0.9601155767927451\n",
      "clip_param : 0.1506995522459176 --- (resample) --> 0.1423467077128195\n",
      "kl_coeff : 0.963850498711435 --- (resample) --> 1.406397859501363\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26111)\u001b[0m 2023-09-19 20:10:20,381\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26090)\u001b[0m 2023-09-19 20:10:20,381\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26113)\u001b[0m 2023-09-19 20:10:22,618\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26111)\u001b[0m 2023-09-19 20:10:24,402\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26111)\u001b[0m 2023-09-19 20:10:24,428\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_189201f3b2a04553ad8020c38245fb7a\n",
      "\u001b[2m\u001b[36m(PPO pid=26111)\u001b[0m 2023-09-19 20:10:24,428\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3225, '_timesteps_total': None, '_time_total': 635.7177541255951, '_episodes_total': 1052}\n",
      "2023-09-19 20:10:35,737\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=26122)\u001b[0m 2023-09-19 20:10:38,381\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26116)\u001b[0m 2023-09-19 20:10:38,381\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26123)\u001b[0m 2023-09-19 20:10:40,668\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26122)\u001b[0m 2023-09-19 20:10:42,440\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26122)\u001b[0m 2023-09-19 20:10:42,464\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_a4a51dc19bd64207a400728c9cfb66d8\n",
      "\u001b[2m\u001b[36m(PPO pid=26122)\u001b[0m 2023-09-19 20:10:42,464\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3225, '_timesteps_total': None, '_time_total': 635.7177541255951, '_episodes_total': 1052}\n",
      "\u001b[2m\u001b[36m(PPO pid=26150)\u001b[0m 2023-09-19 20:10:56,577\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26126)\u001b[0m 2023-09-19 20:10:56,577\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26152)\u001b[0m 2023-09-19 20:10:58,849\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "2023-09-19 20:11:11,800\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.134750) into trial 76be2_00001 (score = 0.117811)\n",
      "\n",
      "2023-09-19 20:11:11,801\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00010618324162555463 --- (* 0.8) --> 8.494659330044371e-05\n",
      "gamma : 0.9601155767927451 --- (* 0.8) --> 0.7680924614341961\n",
      "clip_param : 0.1423467077128195 --- (* 1.2) --> 0.17081604925538338\n",
      "kl_coeff : 1.406397859501363 --- (* 1.2) --> 1.6876774314016356\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26170)\u001b[0m 2023-09-19 20:11:14,338\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26155)\u001b[0m 2023-09-19 20:11:14,338\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26175)\u001b[0m 2023-09-19 20:11:16,654\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26170)\u001b[0m 2023-09-19 20:11:18,464\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26170)\u001b[0m 2023-09-19 20:11:18,492\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_b94e989317034271827b38d0115f088b\n",
      "\u001b[2m\u001b[36m(PPO pid=26170)\u001b[0m 2023-09-19 20:11:18,492\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3272, '_timesteps_total': None, '_time_total': 645.7365982532501, '_episodes_total': 1067}\n",
      "2023-09-19 20:11:29,685\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=26182)\u001b[0m 2023-09-19 20:11:32,532\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26178)\u001b[0m 2023-09-19 20:11:32,532\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26183)\u001b[0m 2023-09-19 20:11:34,794\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26182)\u001b[0m 2023-09-19 20:11:36,569\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26182)\u001b[0m 2023-09-19 20:11:36,595\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_11756c6581e24e5786dec5752a45e885\n",
      "\u001b[2m\u001b[36m(PPO pid=26182)\u001b[0m 2023-09-19 20:11:36,595\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3272, '_timesteps_total': None, '_time_total': 645.7365982532501, '_episodes_total': 1067}\n",
      "\u001b[2m\u001b[36m(PPO pid=26190)\u001b[0m 2023-09-19 20:11:50,623\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26187)\u001b[0m 2023-09-19 20:11:50,623\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26191)\u001b[0m 2023-09-19 20:11:52,937\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26190)\u001b[0m 2023-09-19 20:11:54,656\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26190)\u001b[0m 2023-09-19 20:11:54,687\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d9efbaf8ee2246738eae26d2ea64c0e1\n",
      "\u001b[2m\u001b[36m(PPO pid=26190)\u001b[0m 2023-09-19 20:11:54,687\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3320, '_timesteps_total': None, '_time_total': 655.8211307525635, '_episodes_total': 1082}\n",
      "\u001b[2m\u001b[36m(PPO pid=26196)\u001b[0m 2023-09-19 20:12:08,711\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26194)\u001b[0m 2023-09-19 20:12:08,711\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26197)\u001b[0m 2023-09-19 20:12:11,033\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26196)\u001b[0m 2023-09-19 20:12:12,890\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26196)\u001b[0m 2023-09-19 20:12:12,926\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_243e2f3ff4c14319bd861b00a3509187\n",
      "\u001b[2m\u001b[36m(PPO pid=26196)\u001b[0m 2023-09-19 20:12:12,926\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3320, '_timesteps_total': None, '_time_total': 655.8101515769958, '_episodes_total': 1082}\n",
      "2023-09-19 20:12:24,340\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.151186) into trial 76be2_00001 (score = 0.120717)\n",
      "\n",
      "2023-09-19 20:12:24,340\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00010618324162555463 --- (* 1.2) --> 0.00012741988995066555\n",
      "gamma : 0.9601155767927451 --- (* 0.8) --> 0.7680924614341961\n",
      "clip_param : 0.1423467077128195 --- (* 0.8) --> 0.1138773661702556\n",
      "kl_coeff : 1.406397859501363 --- (* 1.2) --> 1.6876774314016356\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26201)\u001b[0m 2023-09-19 20:12:27,534\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26200)\u001b[0m 2023-09-19 20:12:27,534\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26204)\u001b[0m 2023-09-19 20:12:29,708\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26201)\u001b[0m 2023-09-19 20:12:31,486\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26201)\u001b[0m 2023-09-19 20:12:31,512\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_3e788afea7314f32a8f87a62bc7f12eb\n",
      "\u001b[2m\u001b[36m(PPO pid=26201)\u001b[0m 2023-09-19 20:12:31,512\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3366, '_timesteps_total': None, '_time_total': 665.8673839569092, '_episodes_total': 1097}\n",
      "\u001b[2m\u001b[36m(PPO pid=26219)\u001b[0m 2023-09-19 20:12:45,459\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26207)\u001b[0m 2023-09-19 20:12:45,459\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26220)\u001b[0m 2023-09-19 20:12:47,770\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26219)\u001b[0m 2023-09-19 20:12:49,567\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26219)\u001b[0m 2023-09-19 20:12:49,596\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_2eaa3a38dce2467196d932ba812e72c3\n",
      "\u001b[2m\u001b[36m(PPO pid=26219)\u001b[0m 2023-09-19 20:12:49,596\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3366, '_timesteps_total': None, '_time_total': 665.8673839569092, '_episodes_total': 1097}\n",
      "\u001b[2m\u001b[36m(PPO pid=26225)\u001b[0m 2023-09-19 20:13:03,649\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26223)\u001b[0m 2023-09-19 20:13:03,649\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26226)\u001b[0m 2023-09-19 20:13:06,081\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26225)\u001b[0m 2023-09-19 20:13:07,877\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26225)\u001b[0m 2023-09-19 20:13:07,913\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ea9eb8e645a34ed0bb6b8ce2a2bebf52\n",
      "\u001b[2m\u001b[36m(PPO pid=26225)\u001b[0m 2023-09-19 20:13:07,913\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3413, '_timesteps_total': None, '_time_total': 675.8878171443939, '_episodes_total': 1112}\n",
      "2023-09-19 20:13:19,046\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.163740) into trial 76be2_00000 (score = 0.138119)\n",
      "\n",
      "2023-09-19 20:13:19,047\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00012741988995066555 --- (* 1.2) --> 0.00015290386794079866\n",
      "gamma : 0.7680924614341961 --- (* 0.8) --> 0.6144739691473569\n",
      "clip_param : 0.1138773661702556 --- (* 1.2) --> 0.1366528394043067\n",
      "kl_coeff : 1.6876774314016356 --- (* 1.2) --> 2.0252129176819627\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26233)\u001b[0m 2023-09-19 20:13:22,814\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26230)\u001b[0m 2023-09-19 20:13:22,814\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26234)\u001b[0m 2023-09-19 20:13:25,359\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26233)\u001b[0m 2023-09-19 20:13:27,178\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26233)\u001b[0m 2023-09-19 20:13:27,204\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_f4e52aefbf0746bfaa5be4d2ca66d3bb\n",
      "\u001b[2m\u001b[36m(PPO pid=26233)\u001b[0m 2023-09-19 20:13:27,204\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3414, '_timesteps_total': None, '_time_total': 676.0377690792084, '_episodes_total': 1112}\n",
      "\u001b[2m\u001b[36m(PPO pid=26249)\u001b[0m 2023-09-19 20:13:41,794\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26237)\u001b[0m 2023-09-19 20:13:41,794\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26250)\u001b[0m 2023-09-19 20:13:44,066\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26249)\u001b[0m 2023-09-19 20:13:45,828\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26249)\u001b[0m 2023-09-19 20:13:45,857\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_deede283bbb74d4095cabc192cb9ab5e\n",
      "\u001b[2m\u001b[36m(PPO pid=26249)\u001b[0m 2023-09-19 20:13:45,857\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3414, '_timesteps_total': None, '_time_total': 676.0377690792084, '_episodes_total': 1112}\n",
      "\u001b[2m\u001b[36m(PPO pid=26258)\u001b[0m 2023-09-19 20:13:59,490\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26255)\u001b[0m 2023-09-19 20:13:59,490\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26259)\u001b[0m 2023-09-19 20:14:01,978\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26258)\u001b[0m 2023-09-19 20:14:03,792\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26258)\u001b[0m 2023-09-19 20:14:03,821\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_8c376b17da654cf4a1f6b6756d033557\n",
      "\u001b[2m\u001b[36m(PPO pid=26258)\u001b[0m 2023-09-19 20:14:03,821\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3460, '_timesteps_total': None, '_time_total': 686.1646718978882, '_episodes_total': 1127}\n",
      "2023-09-19 20:14:14,956\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.145622) into trial 76be2_00001 (score = 0.119777)\n",
      "\n",
      "2023-09-19 20:14:14,956\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00015290386794079866 --- (* 1.2) --> 0.00018348464152895838\n",
      "gamma : 0.6144739691473569 --- (* 1.2) --> 0.7373687629768282\n",
      "clip_param : 0.1366528394043067 --- (* 1.2) --> 0.16398340728516803\n",
      "kl_coeff : 2.0252129176819627 --- (resample) --> 0.3983292233761918\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26265)\u001b[0m 2023-09-19 20:14:17,742\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26262)\u001b[0m 2023-09-19 20:14:17,742\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26268)\u001b[0m 2023-09-19 20:14:20,121\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26265)\u001b[0m 2023-09-19 20:14:22,002\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26265)\u001b[0m 2023-09-19 20:14:22,030\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_0ee13598d47c43c4be43f7c911822716\n",
      "\u001b[2m\u001b[36m(PPO pid=26265)\u001b[0m 2023-09-19 20:14:22,030\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3461, '_timesteps_total': None, '_time_total': 686.1264567375183, '_episodes_total': 1127}\n",
      "\u001b[2m\u001b[36m(PPO pid=26273)\u001b[0m 2023-09-19 20:14:36,675\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26271)\u001b[0m 2023-09-19 20:14:36,675\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26274)\u001b[0m 2023-09-19 20:14:38,880\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26273)\u001b[0m 2023-09-19 20:14:40,982\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26273)\u001b[0m 2023-09-19 20:14:41,021\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_25a8bac16c0842698b4e27519caabe12\n",
      "\u001b[2m\u001b[36m(PPO pid=26273)\u001b[0m 2023-09-19 20:14:41,021\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3461, '_timesteps_total': None, '_time_total': 686.1264567375183, '_episodes_total': 1127}\n",
      "2023-09-19 20:14:52,420\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.155794) into trial 76be2_00001 (score = 0.147478)\n",
      "\n",
      "2023-09-19 20:14:52,420\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00015290386794079866 --- (* 0.8) --> 0.00012232309435263893\n",
      "gamma : 0.6144739691473569 --- (* 1.2) --> 0.7373687629768282\n",
      "clip_param : 0.1366528394043067 --- (* 0.8) --> 0.10932227152344537\n",
      "kl_coeff : 2.0252129176819627 --- (* 0.8) --> 1.6201703341455702\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26295)\u001b[0m 2023-09-19 20:14:55,889\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26278)\u001b[0m 2023-09-19 20:14:55,889\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26297)\u001b[0m 2023-09-19 20:14:58,170\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26295)\u001b[0m 2023-09-19 20:14:59,923\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26295)\u001b[0m 2023-09-19 20:14:59,953\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_f869eb1014e24d3d844303bd07d5fbd3\n",
      "\u001b[2m\u001b[36m(PPO pid=26295)\u001b[0m 2023-09-19 20:14:59,953\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3507, '_timesteps_total': None, '_time_total': 696.2290482521057, '_episodes_total': 1142}\n",
      "2023-09-19 20:15:11,290\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=26306)\u001b[0m 2023-09-19 20:15:13,844\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26300)\u001b[0m 2023-09-19 20:15:13,844\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26307)\u001b[0m 2023-09-19 20:15:16,417\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26306)\u001b[0m 2023-09-19 20:15:18,275\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26306)\u001b[0m 2023-09-19 20:15:18,316\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_3d1a3c2c7378454ab6d6827078ce487b\n",
      "\u001b[2m\u001b[36m(PPO pid=26306)\u001b[0m 2023-09-19 20:15:18,316\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3507, '_timesteps_total': None, '_time_total': 696.2290482521057, '_episodes_total': 1142}\n",
      "\u001b[2m\u001b[36m(PPO pid=26311)\u001b[0m 2023-09-19 20:15:32,941\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26310)\u001b[0m 2023-09-19 20:15:32,941\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=26311)\u001b[0m 2023-09-19 20:15:37,060\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26311)\u001b[0m 2023-09-19 20:15:37,089\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_e9d99099e9f048cca05fdc60767a52ac\n",
      "\u001b[2m\u001b[36m(PPO pid=26311)\u001b[0m 2023-09-19 20:15:37,089\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3554, '_timesteps_total': None, '_time_total': 706.3163042068481, '_episodes_total': 1157}\n",
      "2023-09-19 20:15:48,424\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.144297) into trial 76be2_00000 (score = 0.144088)\n",
      "\n",
      "2023-09-19 20:15:48,424\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00012232309435263893 --- (* 0.8) --> 9.785847548211115e-05\n",
      "gamma : 0.7373687629768282 --- (resample) --> 0.9534731375854059\n",
      "clip_param : 0.10932227152344537 --- (resample) --> 0.2111199594346228\n",
      "kl_coeff : 1.6201703341455702 --- (* 1.2) --> 1.9442044009746842\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26318)\u001b[0m 2023-09-19 20:15:51,861\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26315)\u001b[0m 2023-09-19 20:15:51,861\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26320)\u001b[0m 2023-09-19 20:15:54,157\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26318)\u001b[0m 2023-09-19 20:15:55,950\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26318)\u001b[0m 2023-09-19 20:15:55,986\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_00e0ccf68f2a4f748a351e2486480a57\n",
      "\u001b[2m\u001b[36m(PPO pid=26318)\u001b[0m 2023-09-19 20:15:55,986\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3552, '_timesteps_total': None, '_time_total': 706.355062007904, '_episodes_total': 1157}\n",
      "\u001b[2m\u001b[36m(PPO pid=26326)\u001b[0m 2023-09-19 20:16:09,939\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26324)\u001b[0m 2023-09-19 20:16:09,939\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26327)\u001b[0m 2023-09-19 20:16:12,363\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26326)\u001b[0m 2023-09-19 20:16:14,214\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26326)\u001b[0m 2023-09-19 20:16:14,243\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d6690fc5c75e41968264097dd96a71d8\n",
      "\u001b[2m\u001b[36m(PPO pid=26326)\u001b[0m 2023-09-19 20:16:14,243\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3552, '_timesteps_total': None, '_time_total': 706.355062007904, '_episodes_total': 1157}\n",
      "2023-09-19 20:16:25,591\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.152967) into trial 76be2_00000 (score = 0.146483)\n",
      "\n",
      "2023-09-19 20:16:25,592\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00012232309435263893 --- (* 1.2) --> 0.0001467877132231667\n",
      "gamma : 0.7373687629768282 --- (* 1.2) --> 0.8848425155721938\n",
      "clip_param : 0.10932227152344537 --- (resample) --> 0.14785539694725358\n",
      "kl_coeff : 1.6201703341455702 --- (resample) --> 0.7887160921174232\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26331)\u001b[0m 2023-09-19 20:16:28,794\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26330)\u001b[0m 2023-09-19 20:16:28,794\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26332)\u001b[0m 2023-09-19 20:16:31,078\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26331)\u001b[0m 2023-09-19 20:16:32,878\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26331)\u001b[0m 2023-09-19 20:16:32,920\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_fcf241b6bdb14e36b72decbba6bb9c7d\n",
      "\u001b[2m\u001b[36m(PPO pid=26331)\u001b[0m 2023-09-19 20:16:32,920\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3598, '_timesteps_total': None, '_time_total': 716.5025858879089, '_episodes_total': 1172}\n",
      "2023-09-19 20:16:44,110\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=26336)\u001b[0m 2023-09-19 20:16:46,827\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26335)\u001b[0m 2023-09-19 20:16:46,827\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26337)\u001b[0m 2023-09-19 20:16:49,167\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26336)\u001b[0m 2023-09-19 20:16:50,979\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26336)\u001b[0m 2023-09-19 20:16:51,037\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_5157908a9c044063ba96ff8bef4443fa\n",
      "\u001b[2m\u001b[36m(PPO pid=26336)\u001b[0m 2023-09-19 20:16:51,037\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3598, '_timesteps_total': None, '_time_total': 716.5025858879089, '_episodes_total': 1172}\n",
      "2023-09-19 20:17:02,550\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=26344)\u001b[0m 2023-09-19 20:17:04,971\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26340)\u001b[0m 2023-09-19 20:17:04,971\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26345)\u001b[0m 2023-09-19 20:17:07,388\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26344)\u001b[0m 2023-09-19 20:17:09,233\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26344)\u001b[0m 2023-09-19 20:17:09,260\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_4f9e188d59ef4fcba1f101d51d2b9bbf\n",
      "\u001b[2m\u001b[36m(PPO pid=26344)\u001b[0m 2023-09-19 20:17:09,260\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3645, '_timesteps_total': None, '_time_total': 726.5552859306335, '_episodes_total': 1187}\n",
      "2023-09-19 20:17:20,413\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=26353)\u001b[0m 2023-09-19 20:17:23,972\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26350)\u001b[0m 2023-09-19 20:17:23,972\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26354)\u001b[0m 2023-09-19 20:17:26,071\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26353)\u001b[0m 2023-09-19 20:17:27,790\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26353)\u001b[0m 2023-09-19 20:17:27,820\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_3a45d56d40a74a92b62dc4ce499a76cf\n",
      "\u001b[2m\u001b[36m(PPO pid=26353)\u001b[0m 2023-09-19 20:17:27,820\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3645, '_timesteps_total': None, '_time_total': 726.6552948951721, '_episodes_total': 1187}\n",
      "\u001b[2m\u001b[36m(PPO pid=26373)\u001b[0m 2023-09-19 20:17:42,074\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26357)\u001b[0m 2023-09-19 20:17:42,074\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26374)\u001b[0m 2023-09-19 20:17:44,531\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26373)\u001b[0m 2023-09-19 20:17:46,424\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26373)\u001b[0m 2023-09-19 20:17:46,479\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ab9e367a93ca4ff1b07375f0df67330e\n",
      "\u001b[2m\u001b[36m(PPO pid=26373)\u001b[0m 2023-09-19 20:17:46,479\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3693, '_timesteps_total': None, '_time_total': 736.6057941913605, '_episodes_total': 1202}\n",
      "2023-09-19 20:17:57,808\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.134910) into trial 76be2_00001 (score = 0.134215)\n",
      "\n",
      "2023-09-19 20:17:57,808\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.0001467877132231667 --- (* 1.2) --> 0.00017614525586780004\n",
      "gamma : 0.8848425155721938 --- (* 1.2) --> 1.0618110186866325\n",
      "clip_param : 0.14785539694725358 --- (resample) --> 0.2940090295374247\n",
      "kl_coeff : 0.7887160921174232 --- (resample) --> 0.21559619067267535\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26381)\u001b[0m 2023-09-19 20:18:00,980\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26377)\u001b[0m 2023-09-19 20:18:00,980\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26384)\u001b[0m 2023-09-19 20:18:03,486\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26381)\u001b[0m 2023-09-19 20:18:05,429\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26381)\u001b[0m 2023-09-19 20:18:05,459\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_09b23eb464de472ba33e63fbeea8528a\n",
      "\u001b[2m\u001b[36m(PPO pid=26381)\u001b[0m 2023-09-19 20:18:05,459\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3692, '_timesteps_total': None, '_time_total': 736.7974090576172, '_episodes_total': 1202}\n",
      "2023-09-19 20:18:16,685\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=26398)\u001b[0m 2023-09-19 20:18:20,077\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26388)\u001b[0m 2023-09-19 20:18:20,077\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26400)\u001b[0m 2023-09-19 20:18:22,083\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26398)\u001b[0m 2023-09-19 20:18:23,821\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26398)\u001b[0m 2023-09-19 20:18:23,846\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d807818c5fa04002a927b6788906438c\n",
      "\u001b[2m\u001b[36m(PPO pid=26398)\u001b[0m 2023-09-19 20:18:23,846\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3692, '_timesteps_total': None, '_time_total': 736.7974090576172, '_episodes_total': 1202}\n",
      "\u001b[2m\u001b[36m(PPO pid=26412)\u001b[0m 2023-09-19 20:18:37,938\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26404)\u001b[0m 2023-09-19 20:18:37,938\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26413)\u001b[0m 2023-09-19 20:18:39,883\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26412)\u001b[0m 2023-09-19 20:18:41,709\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26412)\u001b[0m 2023-09-19 20:18:41,737\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_fbcbc023af9040b89e882ff3e8d41650\n",
      "\u001b[2m\u001b[36m(PPO pid=26412)\u001b[0m 2023-09-19 20:18:41,737\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3737, '_timesteps_total': None, '_time_total': 746.958114862442, '_episodes_total': 1217}\n",
      "2023-09-19 20:18:53,078\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.142619) into trial 76be2_00000 (score = 0.138451)\n",
      "\n",
      "2023-09-19 20:18:53,080\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00017614525586780004 --- (* 1.2) --> 0.00021137430704136004\n",
      "gamma : 1.0618110186866325 --- (resample) --> 0.9802583957804991\n",
      "clip_param : 0.2940090295374247 --- (* 1.2) --> 0.3528108354449096\n",
      "kl_coeff : 0.21559619067267535 --- (* 0.8) --> 0.1724769525381403\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26430)\u001b[0m 2023-09-19 20:18:56,089\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26426)\u001b[0m 2023-09-19 20:18:56,089\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26433)\u001b[0m 2023-09-19 20:18:58,048\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26430)\u001b[0m 2023-09-19 20:18:59,789\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26430)\u001b[0m 2023-09-19 20:18:59,816\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_30e11d9c1ac749e093f96becebc81092\n",
      "\u001b[2m\u001b[36m(PPO pid=26430)\u001b[0m 2023-09-19 20:18:59,816\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3744, '_timesteps_total': None, '_time_total': 746.9255359172821, '_episodes_total': 1219}\n",
      "\u001b[2m\u001b[36m(PPO pid=26441)\u001b[0m 2023-09-19 20:19:14,125\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26436)\u001b[0m 2023-09-19 20:19:14,125\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26442)\u001b[0m 2023-09-19 20:19:16,305\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26441)\u001b[0m 2023-09-19 20:19:18,034\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26441)\u001b[0m 2023-09-19 20:19:18,061\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_554468d0f3e14cc590d5ba026d4abf3b\n",
      "\u001b[2m\u001b[36m(PPO pid=26441)\u001b[0m 2023-09-19 20:19:18,061\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3744, '_timesteps_total': None, '_time_total': 746.9255359172821, '_episodes_total': 1219}\n",
      "2023-09-19 20:19:29,519\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.141437) into trial 76be2_00000 (score = 0.134542)\n",
      "\n",
      "2023-09-19 20:19:29,519\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00017614525586780004 --- (* 1.2) --> 0.00021137430704136004\n",
      "gamma : 1.0618110186866325 --- (* 0.8) --> 0.849448814949306\n",
      "clip_param : 0.2940090295374247 --- (* 0.8) --> 0.23520722362993976\n",
      "kl_coeff : 0.21559619067267535 --- (resample) --> 0.76729485012293\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26460)\u001b[0m 2023-09-19 20:19:32,134\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26446)\u001b[0m 2023-09-19 20:19:32,134\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26463)\u001b[0m 2023-09-19 20:19:34,278\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26460)\u001b[0m 2023-09-19 20:19:36,216\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26460)\u001b[0m 2023-09-19 20:19:36,255\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_b7d58be0f5154cb6ab98d75740b7d573\n",
      "\u001b[2m\u001b[36m(PPO pid=26460)\u001b[0m 2023-09-19 20:19:36,255\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3794, '_timesteps_total': None, '_time_total': 757.0666506290436, '_episodes_total': 1236}\n",
      "2023-09-19 20:19:47,416\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=26489)\u001b[0m 2023-09-19 20:19:51,116\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26466)\u001b[0m 2023-09-19 20:19:51,116\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26490)\u001b[0m 2023-09-19 20:19:53,072\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26489)\u001b[0m 2023-09-19 20:19:54,881\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26489)\u001b[0m 2023-09-19 20:19:54,912\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_33756cadd04148f8b7bd2503463d9330\n",
      "\u001b[2m\u001b[36m(PPO pid=26489)\u001b[0m 2023-09-19 20:19:54,912\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3794, '_timesteps_total': None, '_time_total': 757.0666506290436, '_episodes_total': 1236}\n",
      "\u001b[2m\u001b[36m(PPO pid=26507)\u001b[0m 2023-09-19 20:20:09,115\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26495)\u001b[0m 2023-09-19 20:20:09,115\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26510)\u001b[0m 2023-09-19 20:20:11,522\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26507)\u001b[0m 2023-09-19 20:20:13,618\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26507)\u001b[0m 2023-09-19 20:20:13,662\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_1c0967434ca143ba9e9cfa6036449f27\n",
      "\u001b[2m\u001b[36m(PPO pid=26507)\u001b[0m 2023-09-19 20:20:13,662\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3842, '_timesteps_total': None, '_time_total': 767.1282653808594, '_episodes_total': 1251}\n",
      "2023-09-19 20:20:24,969\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.145770) into trial 76be2_00001 (score = 0.114706)\n",
      "\n",
      "2023-09-19 20:20:24,970\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00021137430704136004 --- (* 0.8) --> 0.00016909944563308805\n",
      "gamma : 0.849448814949306 --- (* 0.8) --> 0.6795590519594449\n",
      "clip_param : 0.23520722362993976 --- (resample) --> 0.13683938369579302\n",
      "kl_coeff : 0.76729485012293 --- (* 1.2) --> 0.920753820147516\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26593)\u001b[0m 2023-09-19 20:20:28,379\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26530)\u001b[0m 2023-09-19 20:20:28,379\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26596)\u001b[0m 2023-09-19 20:20:30,384\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26593)\u001b[0m 2023-09-19 20:20:32,101\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26593)\u001b[0m 2023-09-19 20:20:32,128\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_554284f906984701baa18532f41b2081\n",
      "\u001b[2m\u001b[36m(PPO pid=26593)\u001b[0m 2023-09-19 20:20:32,128\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3844, '_timesteps_total': None, '_time_total': 767.1624953746796, '_episodes_total': 1253}\n",
      "\u001b[2m\u001b[36m(PPO pid=26602)\u001b[0m 2023-09-19 20:20:46,122\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26599)\u001b[0m 2023-09-19 20:20:46,122\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26603)\u001b[0m 2023-09-19 20:20:47,975\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26602)\u001b[0m 2023-09-19 20:20:49,777\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26602)\u001b[0m 2023-09-19 20:20:49,806\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_114ccd1ccd0d4bf9aa96c89467c15527\n",
      "\u001b[2m\u001b[36m(PPO pid=26602)\u001b[0m 2023-09-19 20:20:49,806\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3844, '_timesteps_total': None, '_time_total': 767.1624953746796, '_episodes_total': 1253}\n",
      "2023-09-19 20:21:01,136\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.157120) into trial 76be2_00001 (score = 0.144647)\n",
      "\n",
      "2023-09-19 20:21:01,137\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00021137430704136004 --- (resample) --> 0.0002268952440383059\n",
      "gamma : 0.849448814949306 --- (resample) --> 0.9572203117128998\n",
      "clip_param : 0.23520722362993976 --- (* 0.8) --> 0.1881657789039518\n",
      "kl_coeff : 0.76729485012293 --- (* 0.8) --> 0.613835880098344\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26609)\u001b[0m 2023-09-19 20:21:04,183\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26607)\u001b[0m 2023-09-19 20:21:04,183\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26611)\u001b[0m 2023-09-19 20:21:06,188\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26609)\u001b[0m 2023-09-19 20:21:08,069\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26609)\u001b[0m 2023-09-19 20:21:08,121\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_f5c7013732504b089d2e66179abac4fd\n",
      "\u001b[2m\u001b[36m(PPO pid=26609)\u001b[0m 2023-09-19 20:21:08,121\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3896, '_timesteps_total': None, '_time_total': 777.193660736084, '_episodes_total': 1270}\n",
      "2023-09-19 20:21:19,375\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=26628)\u001b[0m 2023-09-19 20:21:22,293\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26614)\u001b[0m 2023-09-19 20:21:22,293\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26629)\u001b[0m 2023-09-19 20:21:24,244\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26628)\u001b[0m 2023-09-19 20:21:26,009\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26628)\u001b[0m 2023-09-19 20:21:26,038\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_47acda61743c4e52afebc475c60a68af\n",
      "\u001b[2m\u001b[36m(PPO pid=26628)\u001b[0m 2023-09-19 20:21:26,038\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3896, '_timesteps_total': None, '_time_total': 777.193660736084, '_episodes_total': 1270}\n",
      "\u001b[2m\u001b[36m(PPO pid=26634)\u001b[0m 2023-09-19 20:21:40,199\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26632)\u001b[0m 2023-09-19 20:21:40,199\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26635)\u001b[0m 2023-09-19 20:21:42,160\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26634)\u001b[0m 2023-09-19 20:21:43,867\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26634)\u001b[0m 2023-09-19 20:21:43,903\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_e535fe78a18f4375a8a79135a0c58dd1\n",
      "\u001b[2m\u001b[36m(PPO pid=26634)\u001b[0m 2023-09-19 20:21:43,903\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3946, '_timesteps_total': None, '_time_total': 787.2654564380646, '_episodes_total': 1287}\n",
      "\u001b[2m\u001b[36m(PPO pid=26639)\u001b[0m 2023-09-19 20:21:58,059\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26638)\u001b[0m 2023-09-19 20:21:58,059\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26640)\u001b[0m 2023-09-19 20:22:00,096\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26639)\u001b[0m 2023-09-19 20:22:01,889\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26639)\u001b[0m 2023-09-19 20:22:01,927\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d6f62e0c93f847dfb805da1873134bbd\n",
      "\u001b[2m\u001b[36m(PPO pid=26639)\u001b[0m 2023-09-19 20:22:01,927\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3949, '_timesteps_total': None, '_time_total': 787.3712720870972, '_episodes_total': 1287}\n",
      "2023-09-19 20:22:13,149\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.153134) into trial 76be2_00001 (score = 0.135362)\n",
      "\n",
      "2023-09-19 20:22:13,149\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00021137430704136004 --- (* 1.2) --> 0.00025364916844963206\n",
      "gamma : 0.849448814949306 --- (* 0.8) --> 0.6795590519594449\n",
      "clip_param : 0.23520722362993976 --- (resample) --> 0.27411241116933344\n",
      "kl_coeff : 0.76729485012293 --- (* 0.8) --> 0.613835880098344\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26649)\u001b[0m 2023-09-19 20:22:16,293\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26644)\u001b[0m 2023-09-19 20:22:16,293\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26652)\u001b[0m 2023-09-19 20:22:18,230\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26649)\u001b[0m 2023-09-19 20:22:19,955\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26649)\u001b[0m 2023-09-19 20:22:19,992\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_16e24c515cfe497ba411cdf244429420\n",
      "\u001b[2m\u001b[36m(PPO pid=26649)\u001b[0m 2023-09-19 20:22:19,992\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3999, '_timesteps_total': None, '_time_total': 797.2990515232086, '_episodes_total': 1304}\n",
      "2023-09-19 20:22:31,199\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=26668)\u001b[0m 2023-09-19 20:22:34,254\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26655)\u001b[0m 2023-09-19 20:22:34,254\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26669)\u001b[0m 2023-09-19 20:22:36,086\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26668)\u001b[0m 2023-09-19 20:22:37,841\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26668)\u001b[0m 2023-09-19 20:22:37,869\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_81381f3a724d41dcaa547c4054497507\n",
      "\u001b[2m\u001b[36m(PPO pid=26668)\u001b[0m 2023-09-19 20:22:37,870\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3999, '_timesteps_total': None, '_time_total': 797.2990515232086, '_episodes_total': 1304}\n",
      "\u001b[2m\u001b[36m(PPO pid=26676)\u001b[0m 2023-09-19 20:22:52,205\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26672)\u001b[0m 2023-09-19 20:22:52,205\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26677)\u001b[0m 2023-09-19 20:22:54,120\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26676)\u001b[0m 2023-09-19 20:22:55,831\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26676)\u001b[0m 2023-09-19 20:22:55,860\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_9d40fd2c0fea4ac7949d40b9bd943bef\n",
      "\u001b[2m\u001b[36m(PPO pid=26676)\u001b[0m 2023-09-19 20:22:55,860\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4050, '_timesteps_total': None, '_time_total': 807.3663668632507, '_episodes_total': 1321}\n",
      "\u001b[2m\u001b[36m(PPO pid=26683)\u001b[0m 2023-09-19 20:23:10,104\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26680)\u001b[0m 2023-09-19 20:23:10,104\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26684)\u001b[0m 2023-09-19 20:23:11,971\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26689)\u001b[0m 2023-09-19 20:23:28,171\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26687)\u001b[0m 2023-09-19 20:23:28,171\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26690)\u001b[0m 2023-09-19 20:23:30,070\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26689)\u001b[0m 2023-09-19 20:23:31,787\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26689)\u001b[0m 2023-09-19 20:23:31,817\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_144cf96b4f0b4430909143532695b124\n",
      "\u001b[2m\u001b[36m(PPO pid=26689)\u001b[0m 2023-09-19 20:23:31,817\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4102, '_timesteps_total': None, '_time_total': 817.5005056858063, '_episodes_total': 1338}\n",
      "\u001b[2m\u001b[36m(PPO pid=26695)\u001b[0m 2023-09-19 20:23:46,380\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26693)\u001b[0m 2023-09-19 20:23:46,380\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26700)\u001b[0m 2023-09-19 20:23:48,228\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26695)\u001b[0m 2023-09-19 20:23:50,017\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26695)\u001b[0m 2023-09-19 20:23:50,052\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_4e5919782ec94e4ca565fff5ccb2a952\n",
      "\u001b[2m\u001b[36m(PPO pid=26695)\u001b[0m 2023-09-19 20:23:50,052\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4103, '_timesteps_total': None, '_time_total': 817.6057333946228, '_episodes_total': 1338}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26707)\u001b[0m 2023-09-19 20:24:06,340\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26706)\u001b[0m 2023-09-19 20:24:08,038\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26706)\u001b[0m 2023-09-19 20:24:08,069\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_174382c4753f45b5aa0c18ce8431fc09\n",
      "\u001b[2m\u001b[36m(PPO pid=26706)\u001b[0m 2023-09-19 20:24:08,069\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4154, '_timesteps_total': None, '_time_total': 827.6473352909088, '_episodes_total': 1355}\n",
      "2023-09-19 20:24:19,500\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.157939) into trial 76be2_00000 (score = 0.129037)\n",
      "\n",
      "2023-09-19 20:24:19,501\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00025364916844963206 --- (* 1.2) --> 0.00030437900213955846\n",
      "gamma : 0.6795590519594449 --- (* 1.2) --> 0.8154708623513338\n",
      "clip_param : 0.27411241116933344 --- (* 0.8) --> 0.21928992893546675\n",
      "kl_coeff : 0.613835880098344 --- (* 1.2) --> 0.7366030561180128\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26714)\u001b[0m 2023-09-19 20:24:22,324\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26710)\u001b[0m 2023-09-19 20:24:22,324\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26716)\u001b[0m 2023-09-19 20:24:24,205\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26714)\u001b[0m 2023-09-19 20:24:25,916\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26714)\u001b[0m 2023-09-19 20:24:25,946\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ccd26096f89c4865ac35c2489ac37768\n",
      "\u001b[2m\u001b[36m(PPO pid=26714)\u001b[0m 2023-09-19 20:24:25,946\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4155, '_timesteps_total': None, '_time_total': 827.6221494674683, '_episodes_total': 1355}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26722)\u001b[0m 2023-09-19 20:24:42,178\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26721)\u001b[0m 2023-09-19 20:24:43,942\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26721)\u001b[0m 2023-09-19 20:24:43,974\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_6a39d4f9d171409a8771731b63b42d05\n",
      "\u001b[2m\u001b[36m(PPO pid=26721)\u001b[0m 2023-09-19 20:24:43,974\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4155, '_timesteps_total': None, '_time_total': 827.6221494674683, '_episodes_total': 1355}\n",
      "\u001b[2m\u001b[36m(PPO pid=26726)\u001b[0m 2023-09-19 20:24:58,107\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26725)\u001b[0m 2023-09-19 20:24:58,107\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26728)\u001b[0m 2023-09-19 20:25:00,004\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26726)\u001b[0m 2023-09-19 20:25:01,753\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26726)\u001b[0m 2023-09-19 20:25:01,796\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_bd4aab4e66d34c87935452d04dc040c0\n",
      "\u001b[2m\u001b[36m(PPO pid=26726)\u001b[0m 2023-09-19 20:25:01,796\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4208, '_timesteps_total': None, '_time_total': 837.8128709793091, '_episodes_total': 1372}\n",
      "\u001b[2m\u001b[36m(PPO pid=26734)\u001b[0m 2023-09-19 20:25:16,458\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26731)\u001b[0m 2023-09-19 20:25:16,458\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26735)\u001b[0m 2023-09-19 20:25:18,357\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26734)\u001b[0m 2023-09-19 20:25:20,170\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26734)\u001b[0m 2023-09-19 20:25:20,218\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_972ce331a1b34e02a0cb975115f66bda\n",
      "\u001b[2m\u001b[36m(PPO pid=26734)\u001b[0m 2023-09-19 20:25:20,218\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4207, '_timesteps_total': None, '_time_total': 837.8111698627472, '_episodes_total': 1372}\n",
      "2023-09-19 20:25:31,519\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.167791) into trial 76be2_00000 (score = 0.133980)\n",
      "\n",
      "2023-09-19 20:25:31,520\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00025364916844963206 --- (resample) --> 0.0004986951931425221\n",
      "gamma : 0.6795590519594449 --- (* 1.2) --> 0.8154708623513338\n",
      "clip_param : 0.27411241116933344 --- (* 0.8) --> 0.21928992893546675\n",
      "kl_coeff : 0.613835880098344 --- (resample) --> 1.3126614439848772\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26744)\u001b[0m 2023-09-19 20:25:34,392\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26738)\u001b[0m 2023-09-19 20:25:34,392\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=26744)\u001b[0m 2023-09-19 20:25:38,087\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26744)\u001b[0m 2023-09-19 20:25:38,127\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_5f589e6bd5a348379d7c147ca1932d73\n",
      "\u001b[2m\u001b[36m(PPO pid=26744)\u001b[0m 2023-09-19 20:25:38,127\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4260, '_timesteps_total': None, '_time_total': 847.9061653614044, '_episodes_total': 1389}\n",
      "\u001b[2m\u001b[36m(PPO pid=26760)\u001b[0m 2023-09-19 20:25:52,475\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26752)\u001b[0m 2023-09-19 20:25:52,475\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26761)\u001b[0m 2023-09-19 20:25:54,310\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26760)\u001b[0m 2023-09-19 20:25:56,066\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26760)\u001b[0m 2023-09-19 20:25:56,093\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c6977924c4194b19af667c836fb7d886\n",
      "\u001b[2m\u001b[36m(PPO pid=26760)\u001b[0m 2023-09-19 20:25:56,093\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4260, '_timesteps_total': None, '_time_total': 847.9061653614044, '_episodes_total': 1389}\n",
      "2023-09-19 20:26:07,231\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.161664) into trial 76be2_00000 (score = 0.146486)\n",
      "\n",
      "2023-09-19 20:26:07,231\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00025364916844963206 --- (* 0.8) --> 0.00020291933475970566\n",
      "gamma : 0.6795590519594449 --- (resample) --> 0.9698789266893874\n",
      "clip_param : 0.27411241116933344 --- (resample) --> 0.13507991206588688\n",
      "kl_coeff : 0.613835880098344 --- (resample) --> 1.2326468777230382\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26766)\u001b[0m 2023-09-19 20:26:09,443\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26764)\u001b[0m 2023-09-19 20:26:09,443\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26769)\u001b[0m 2023-09-19 20:26:11,347\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26766)\u001b[0m 2023-09-19 20:26:13,173\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26766)\u001b[0m 2023-09-19 20:26:13,203\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ac9063095bf84e3a90b189d189d16a90\n",
      "\u001b[2m\u001b[36m(PPO pid=26766)\u001b[0m 2023-09-19 20:26:13,204\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4312, '_timesteps_total': None, '_time_total': 858.0112278461456, '_episodes_total': 1406}\n",
      "\u001b[2m\u001b[36m(PPO pid=26793)\u001b[0m 2023-09-19 20:26:27,494\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26772)\u001b[0m 2023-09-19 20:26:27,494\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26794)\u001b[0m 2023-09-19 20:26:29,447\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26793)\u001b[0m 2023-09-19 20:26:31,138\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26793)\u001b[0m 2023-09-19 20:26:31,166\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_e665e11f6aee4e8690658d24911ede80\n",
      "\u001b[2m\u001b[36m(PPO pid=26793)\u001b[0m 2023-09-19 20:26:31,166\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4312, '_timesteps_total': None, '_time_total': 858.0112278461456, '_episodes_total': 1406}\n",
      "\u001b[2m\u001b[36m(PPO pid=26819)\u001b[0m 2023-09-19 20:26:45,510\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26798)\u001b[0m 2023-09-19 20:26:45,510\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=26819)\u001b[0m 2023-09-19 20:26:49,189\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26819)\u001b[0m 2023-09-19 20:26:49,219\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_2d3b0b0138ae442f99bb91e2633d2007\n",
      "\u001b[2m\u001b[36m(PPO pid=26819)\u001b[0m 2023-09-19 20:26:49,219\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4365, '_timesteps_total': None, '_time_total': 868.1441760063171, '_episodes_total': 1423}\n",
      "2023-09-19 20:27:00,363\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.152313) into trial 76be2_00001 (score = 0.152223)\n",
      "\n",
      "2023-09-19 20:27:00,363\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00020291933475970566 --- (* 0.8) --> 0.00016233546780776453\n",
      "gamma : 0.9698789266893874 --- (* 1.2) --> 1.1638547120272649\n",
      "clip_param : 0.13507991206588688 --- (* 0.8) --> 0.1080639296527095\n",
      "kl_coeff : 1.2326468777230382 --- (* 0.8) --> 0.9861175021784305\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26838)\u001b[0m 2023-09-19 20:27:03,528\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26826)\u001b[0m 2023-09-19 20:27:03,528\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26841)\u001b[0m 2023-09-19 20:27:05,425\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26838)\u001b[0m 2023-09-19 20:27:07,125\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26838)\u001b[0m 2023-09-19 20:27:07,159\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c2903369696d4c1c9c18efc174509660\n",
      "\u001b[2m\u001b[36m(PPO pid=26838)\u001b[0m 2023-09-19 20:27:07,159\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4363, '_timesteps_total': None, '_time_total': 868.1128187179565, '_episodes_total': 1423}\n",
      "2023-09-19 20:27:18,584\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=26848)\u001b[0m 2023-09-19 20:27:21,493\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26844)\u001b[0m 2023-09-19 20:27:21,493\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26850)\u001b[0m 2023-09-19 20:27:23,447\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26848)\u001b[0m 2023-09-19 20:27:25,199\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26848)\u001b[0m 2023-09-19 20:27:25,229\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ee5d2271eeb347d98f146208ced00849\n",
      "\u001b[2m\u001b[36m(PPO pid=26848)\u001b[0m 2023-09-19 20:27:25,229\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4363, '_timesteps_total': None, '_time_total': 868.1128187179565, '_episodes_total': 1423}\n",
      "\u001b[2m\u001b[36m(PPO pid=26895)\u001b[0m 2023-09-19 20:27:39,649\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26853)\u001b[0m 2023-09-19 20:27:39,649\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26896)\u001b[0m 2023-09-19 20:27:41,523\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26895)\u001b[0m 2023-09-19 20:27:43,265\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26895)\u001b[0m 2023-09-19 20:27:43,295\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_786ce896fb2c4a7ea12a64616cedc28c\n",
      "\u001b[2m\u001b[36m(PPO pid=26895)\u001b[0m 2023-09-19 20:27:43,295\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4416, '_timesteps_total': None, '_time_total': 878.2688217163086, '_episodes_total': 1440}\n",
      "2023-09-19 20:27:54,592\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.155200) into trial 76be2_00000 (score = 0.144048)\n",
      "\n",
      "2023-09-19 20:27:54,593\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00016233546780776453 --- (* 0.8) --> 0.00012986837424621163\n",
      "gamma : 1.1638547120272649 --- (resample) --> 0.9639238984572966\n",
      "clip_param : 0.1080639296527095 --- (resample) --> 0.1058035606496045\n",
      "kl_coeff : 0.9861175021784305 --- (* 0.8) --> 0.7888940017427445\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26906)\u001b[0m 2023-09-19 20:27:57,547\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26899)\u001b[0m 2023-09-19 20:27:57,547\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26909)\u001b[0m 2023-09-19 20:27:59,570\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26906)\u001b[0m 2023-09-19 20:28:01,268\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26906)\u001b[0m 2023-09-19 20:28:01,309\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_4670f9fe1ead4d24a24860b1a797299b\n",
      "\u001b[2m\u001b[36m(PPO pid=26906)\u001b[0m 2023-09-19 20:28:01,309\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4415, '_timesteps_total': None, '_time_total': 878.2224290370941, '_episodes_total': 1440}\n",
      "2023-09-19 20:28:12,501\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=26917)\u001b[0m 2023-09-19 20:28:15,667\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26912)\u001b[0m 2023-09-19 20:28:15,667\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26919)\u001b[0m 2023-09-19 20:28:17,534\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26923)\u001b[0m 2023-09-19 20:28:33,651\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26922)\u001b[0m 2023-09-19 20:28:33,651\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26924)\u001b[0m 2023-09-19 20:28:35,704\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26923)\u001b[0m 2023-09-19 20:28:37,444\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26923)\u001b[0m 2023-09-19 20:28:37,479\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ca7bb60be2634f029c0f8aa1bb529492\n",
      "\u001b[2m\u001b[36m(PPO pid=26923)\u001b[0m 2023-09-19 20:28:37,479\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4467, '_timesteps_total': None, '_time_total': 888.3017070293427, '_episodes_total': 1457}\n",
      "\u001b[2m\u001b[36m(PPO pid=26930)\u001b[0m 2023-09-19 20:28:51,392\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26927)\u001b[0m 2023-09-19 20:28:51,392\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26932)\u001b[0m 2023-09-19 20:28:53,366\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26930)\u001b[0m 2023-09-19 20:28:55,087\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26930)\u001b[0m 2023-09-19 20:28:55,116\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_bc6b81d3150b4b289b9eefeaab82cb9f\n",
      "\u001b[2m\u001b[36m(PPO pid=26930)\u001b[0m 2023-09-19 20:28:55,116\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4467, '_timesteps_total': None, '_time_total': 888.362051486969, '_episodes_total': 1457}\n",
      "2023-09-19 20:29:06,347\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.160410) into trial 76be2_00000 (score = 0.134076)\n",
      "\n",
      "2023-09-19 20:29:06,348\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00016233546780776453 --- (* 0.8) --> 0.00012986837424621163\n",
      "gamma : 1.1638547120272649 --- (resample) --> 0.954985189838131\n",
      "clip_param : 0.1080639296527095 --- (* 0.8) --> 0.08645114372216761\n",
      "kl_coeff : 0.9861175021784305 --- (* 1.2) --> 1.1833410026141167\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26936)\u001b[0m 2023-09-19 20:29:09,728\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26935)\u001b[0m 2023-09-19 20:29:09,728\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26939)\u001b[0m 2023-09-19 20:29:11,744\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26936)\u001b[0m 2023-09-19 20:29:13,459\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26936)\u001b[0m 2023-09-19 20:29:13,486\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_b928dc3fe1bf40ccad252ee08aedd3cb\n",
      "\u001b[2m\u001b[36m(PPO pid=26936)\u001b[0m 2023-09-19 20:29:13,486\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4519, '_timesteps_total': None, '_time_total': 898.3422825336456, '_episodes_total': 1474}\n",
      "\u001b[2m\u001b[36m(PPO pid=26953)\u001b[0m 2023-09-19 20:29:27,740\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26943)\u001b[0m 2023-09-19 20:29:27,740\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26955)\u001b[0m 2023-09-19 20:29:29,608\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26953)\u001b[0m 2023-09-19 20:29:31,379\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26953)\u001b[0m 2023-09-19 20:29:31,410\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_af79e89267124970ad0906cad920944c\n",
      "\u001b[2m\u001b[36m(PPO pid=26953)\u001b[0m 2023-09-19 20:29:31,410\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4519, '_timesteps_total': None, '_time_total': 898.3422825336456, '_episodes_total': 1474}\n",
      "2023-09-19 20:29:42,748\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.187364) into trial 76be2_00000 (score = 0.136497)\n",
      "\n",
      "2023-09-19 20:29:42,749\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00016233546780776453 --- (* 1.2) --> 0.00019480256136931743\n",
      "gamma : 1.1638547120272649 --- (* 0.8) --> 0.9310837696218119\n",
      "clip_param : 0.1080639296527095 --- (resample) --> 0.13263289381409746\n",
      "kl_coeff : 0.9861175021784305 --- (resample) --> 0.6696272611824055\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26963)\u001b[0m 2023-09-19 20:29:45,626\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26958)\u001b[0m 2023-09-19 20:29:45,626\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26966)\u001b[0m 2023-09-19 20:29:47,591\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26963)\u001b[0m 2023-09-19 20:29:49,315\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26963)\u001b[0m 2023-09-19 20:29:49,344\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_81f08596258743e8aebe64d041254045\n",
      "\u001b[2m\u001b[36m(PPO pid=26963)\u001b[0m 2023-09-19 20:29:49,344\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4571, '_timesteps_total': None, '_time_total': 908.451247215271, '_episodes_total': 1491}\n",
      "\u001b[2m\u001b[36m(PPO pid=26971)\u001b[0m 2023-09-19 20:30:03,588\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26969)\u001b[0m 2023-09-19 20:30:03,588\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26974)\u001b[0m 2023-09-19 20:30:05,524\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26971)\u001b[0m 2023-09-19 20:30:07,316\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26971)\u001b[0m 2023-09-19 20:30:07,345\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_a5957ba2c13d48088a3e0a5ba5d454eb\n",
      "\u001b[2m\u001b[36m(PPO pid=26971)\u001b[0m 2023-09-19 20:30:07,345\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4571, '_timesteps_total': None, '_time_total': 908.451247215271, '_episodes_total': 1491}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26986)\u001b[0m 2023-09-19 20:30:23,791\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26982)\u001b[0m 2023-09-19 20:30:25,552\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26982)\u001b[0m 2023-09-19 20:30:25,591\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_6e16325cd0a341cb90799df8d86ec075\n",
      "\u001b[2m\u001b[36m(PPO pid=26982)\u001b[0m 2023-09-19 20:30:25,591\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4623, '_timesteps_total': None, '_time_total': 918.5236165523529, '_episodes_total': 1508}\n",
      "2023-09-19 20:30:37,005\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.156457) into trial 76be2_00001 (score = 0.131675)\n",
      "\n",
      "2023-09-19 20:30:37,006\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00019480256136931743 --- (* 0.8) --> 0.00015584204909545394\n",
      "gamma : 0.9310837696218119 --- (* 0.8) --> 0.7448670156974496\n",
      "clip_param : 0.13263289381409746 --- (* 0.8) --> 0.10610631505127797\n",
      "kl_coeff : 0.6696272611824055 --- (* 0.8) --> 0.5357018089459243\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=26991)\u001b[0m 2023-09-19 20:30:39,818\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26990)\u001b[0m 2023-09-19 20:30:39,818\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26994)\u001b[0m 2023-09-19 20:30:41,693\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26991)\u001b[0m 2023-09-19 20:30:43,466\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26991)\u001b[0m 2023-09-19 20:30:43,497\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_cae18e5814e849b19754faedd23441e4\n",
      "\u001b[2m\u001b[36m(PPO pid=26991)\u001b[0m 2023-09-19 20:30:43,497\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4623, '_timesteps_total': None, '_time_total': 918.5734395980835, '_episodes_total': 1508}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27000)\u001b[0m 2023-09-19 20:30:59,531\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=26999)\u001b[0m 2023-09-19 20:31:01,246\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=26999)\u001b[0m 2023-09-19 20:31:01,275\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_811e5ee4f00a46deb36ec1f7bee06887\n",
      "\u001b[2m\u001b[36m(PPO pid=26999)\u001b[0m 2023-09-19 20:31:01,275\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4623, '_timesteps_total': None, '_time_total': 918.5734395980835, '_episodes_total': 1508}\n",
      "\u001b[2m\u001b[36m(PPO pid=27006)\u001b[0m 2023-09-19 20:31:15,941\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27004)\u001b[0m 2023-09-19 20:31:15,941\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27007)\u001b[0m 2023-09-19 20:31:17,966\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27006)\u001b[0m 2023-09-19 20:31:19,722\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27006)\u001b[0m 2023-09-19 20:31:19,753\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_764f6440901648a99220e00e3909e2f0\n",
      "\u001b[2m\u001b[36m(PPO pid=27006)\u001b[0m 2023-09-19 20:31:19,753\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4675, '_timesteps_total': None, '_time_total': 928.7688872814178, '_episodes_total': 1525}\n",
      "2023-09-19 20:31:31,044\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.163986) into trial 76be2_00000 (score = 0.150567)\n",
      "\n",
      "2023-09-19 20:31:31,044\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00015584204909545394 --- (* 0.8) --> 0.00012467363927636316\n",
      "gamma : 0.7448670156974496 --- (* 0.8) --> 0.5958936125579597\n",
      "clip_param : 0.10610631505127797 --- (resample) --> 0.2709279959368939\n",
      "kl_coeff : 0.5357018089459243 --- (resample) --> 1.374970775179219\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27013)\u001b[0m 2023-09-19 20:31:33,906\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27010)\u001b[0m 2023-09-19 20:31:33,906\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27016)\u001b[0m 2023-09-19 20:31:35,852\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27013)\u001b[0m 2023-09-19 20:31:37,558\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27013)\u001b[0m 2023-09-19 20:31:37,587\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_7d1116e97089421c9aee2e89a560ebf5\n",
      "\u001b[2m\u001b[36m(PPO pid=27013)\u001b[0m 2023-09-19 20:31:37,587\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4676, '_timesteps_total': None, '_time_total': 928.6774573326111, '_episodes_total': 1525}\n",
      "\u001b[2m\u001b[36m(PPO pid=27022)\u001b[0m 2023-09-19 20:31:51,900\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27019)\u001b[0m 2023-09-19 20:31:51,900\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27023)\u001b[0m 2023-09-19 20:31:53,901\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27022)\u001b[0m 2023-09-19 20:31:55,623\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27022)\u001b[0m 2023-09-19 20:31:55,658\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c3fc31013d304602b0554e3d9f230792\n",
      "\u001b[2m\u001b[36m(PPO pid=27022)\u001b[0m 2023-09-19 20:31:55,658\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4676, '_timesteps_total': None, '_time_total': 928.6774573326111, '_episodes_total': 1525}\n",
      "2023-09-19 20:32:06,948\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.170703) into trial 76be2_00000 (score = 0.163098)\n",
      "\n",
      "2023-09-19 20:32:06,949\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00015584204909545394 --- (* 0.8) --> 0.00012467363927636316\n",
      "gamma : 0.7448670156974496 --- (resample) --> 0.9802353716075975\n",
      "clip_param : 0.10610631505127797 --- (* 0.8) --> 0.08488505204102238\n",
      "kl_coeff : 0.5357018089459243 --- (* 0.8) --> 0.4285614471567395\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27027)\u001b[0m 2023-09-19 20:32:10,057\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27026)\u001b[0m 2023-09-19 20:32:10,057\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27030)\u001b[0m 2023-09-19 20:32:12,060\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27027)\u001b[0m 2023-09-19 20:32:13,752\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27027)\u001b[0m 2023-09-19 20:32:13,793\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d5db80a23e7c47d3b16e0683ac56a403\n",
      "\u001b[2m\u001b[36m(PPO pid=27027)\u001b[0m 2023-09-19 20:32:13,793\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4728, '_timesteps_total': None, '_time_total': 938.8254585266113, '_episodes_total': 1542}\n",
      "2023-09-19 20:32:25,077\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=27050)\u001b[0m 2023-09-19 20:32:28,000\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27035)\u001b[0m 2023-09-19 20:32:28,000\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27051)\u001b[0m 2023-09-19 20:32:29,954\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27050)\u001b[0m 2023-09-19 20:32:31,664\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27050)\u001b[0m 2023-09-19 20:32:31,696\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_5106bb5699c24c789d78f191750c0d88\n",
      "\u001b[2m\u001b[36m(PPO pid=27050)\u001b[0m 2023-09-19 20:32:31,696\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4728, '_timesteps_total': None, '_time_total': 938.8254585266113, '_episodes_total': 1542}\n",
      "2023-09-19 20:32:42,889\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=27056)\u001b[0m 2023-09-19 20:32:46,087\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27054)\u001b[0m 2023-09-19 20:32:46,087\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27057)\u001b[0m 2023-09-19 20:32:47,999\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27056)\u001b[0m 2023-09-19 20:32:49,843\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_16205cf224594d59bedcffdc872f2d35\n",
      "\u001b[2m\u001b[36m(PPO pid=27056)\u001b[0m 2023-09-19 20:32:49,843\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4781, '_timesteps_total': None, '_time_total': 948.9870691299438, '_episodes_total': 1559}\n",
      "2023-09-19 20:33:01,072\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=27072)\u001b[0m 2023-09-19 20:33:04,046\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27060)\u001b[0m 2023-09-19 20:33:04,046\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27073)\u001b[0m 2023-09-19 20:33:06,041\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27072)\u001b[0m 2023-09-19 20:33:07,791\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27072)\u001b[0m 2023-09-19 20:33:07,829\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_7d318717f6004c208a5aca4179c6b94c\n",
      "\u001b[2m\u001b[36m(PPO pid=27072)\u001b[0m 2023-09-19 20:33:07,830\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4780, '_timesteps_total': None, '_time_total': 948.9451310634613, '_episodes_total': 1559}\n",
      "\u001b[2m\u001b[36m(PPO pid=27079)\u001b[0m 2023-09-19 20:33:22,095\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27076)\u001b[0m 2023-09-19 20:33:22,095\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27080)\u001b[0m 2023-09-19 20:33:24,273\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27079)\u001b[0m 2023-09-19 20:33:26,077\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27079)\u001b[0m 2023-09-19 20:33:26,115\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_01a60a966bff40feb2132b13c533de9e\n",
      "\u001b[2m\u001b[36m(PPO pid=27079)\u001b[0m 2023-09-19 20:33:26,115\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4833, '_timesteps_total': None, '_time_total': 959.0687503814697, '_episodes_total': 1576}\n",
      "2023-09-19 20:33:37,399\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.152942) into trial 76be2_00001 (score = 0.144832)\n",
      "\n",
      "2023-09-19 20:33:37,400\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00012467363927636316 --- (* 1.2) --> 0.0001496083671316358\n",
      "gamma : 0.9802353716075975 --- (* 1.2) --> 1.176282445929117\n",
      "clip_param : 0.08488505204102238 --- (* 0.8) --> 0.06790804163281791\n",
      "kl_coeff : 0.4285614471567395 --- (* 0.8) --> 0.3428491577253916\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27090)\u001b[0m 2023-09-19 20:33:40,123\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27083)\u001b[0m 2023-09-19 20:33:40,123\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27092)\u001b[0m 2023-09-19 20:33:42,434\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27090)\u001b[0m 2023-09-19 20:33:44,173\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27090)\u001b[0m 2023-09-19 20:33:44,205\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_09693dccf19245209885064a983d37ef\n",
      "\u001b[2m\u001b[36m(PPO pid=27090)\u001b[0m 2023-09-19 20:33:44,206\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4832, '_timesteps_total': None, '_time_total': 959.0713613033295, '_episodes_total': 1576}\n",
      "\u001b[2m\u001b[36m(PPO pid=27109)\u001b[0m 2023-09-19 20:33:58,196\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27095)\u001b[0m 2023-09-19 20:33:58,196\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27115)\u001b[0m 2023-09-19 20:34:00,435\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27109)\u001b[0m 2023-09-19 20:34:02,251\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27109)\u001b[0m 2023-09-19 20:34:02,285\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_5f45001231ac49bd9caffc5ad9d41fae\n",
      "\u001b[2m\u001b[36m(PPO pid=27109)\u001b[0m 2023-09-19 20:34:02,285\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4832, '_timesteps_total': None, '_time_total': 959.0713613033295, '_episodes_total': 1576}\n",
      "2023-09-19 20:34:13,548\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.156307) into trial 76be2_00001 (score = 0.131395)\n",
      "\n",
      "2023-09-19 20:34:13,549\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00012467363927636316 --- (resample) --> 0.00018428798861143303\n",
      "gamma : 0.9802353716075975 --- (* 0.8) --> 0.7841882972860781\n",
      "clip_param : 0.08488505204102238 --- (* 1.2) --> 0.10186206244922685\n",
      "kl_coeff : 0.4285614471567395 --- (resample) --> 0.4097657587366264\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27125)\u001b[0m 2023-09-19 20:34:17,206\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27118)\u001b[0m 2023-09-19 20:34:17,206\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27126)\u001b[0m 2023-09-19 20:34:19,308\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27125)\u001b[0m 2023-09-19 20:34:21,059\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27125)\u001b[0m 2023-09-19 20:34:21,087\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_282dc463bee444349a396cc9bbb56532\n",
      "\u001b[2m\u001b[36m(PPO pid=27125)\u001b[0m 2023-09-19 20:34:21,087\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4881, '_timesteps_total': None, '_time_total': 969.1552977561951, '_episodes_total': 1591}\n",
      "\u001b[2m\u001b[36m(PPO pid=27136)\u001b[0m 2023-09-19 20:34:35,167\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27130)\u001b[0m 2023-09-19 20:34:35,167\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27138)\u001b[0m 2023-09-19 20:34:37,445\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27136)\u001b[0m 2023-09-19 20:34:39,199\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27136)\u001b[0m 2023-09-19 20:34:39,237\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c1f12c70eee849ddb947a2199edc363d\n",
      "\u001b[2m\u001b[36m(PPO pid=27136)\u001b[0m 2023-09-19 20:34:39,237\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4881, '_timesteps_total': None, '_time_total': 969.1552977561951, '_episodes_total': 1591}\n",
      "2023-09-19 20:34:50,470\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.157888) into trial 76be2_00001 (score = 0.151858)\n",
      "\n",
      "2023-09-19 20:34:50,471\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00012467363927636316 --- (* 0.8) --> 9.973891142109054e-05\n",
      "gamma : 0.9802353716075975 --- (* 0.8) --> 0.7841882972860781\n",
      "clip_param : 0.08488505204102238 --- (* 1.2) --> 0.10186206244922685\n",
      "kl_coeff : 0.4285614471567395 --- (resample) --> 0.8913973521180099\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27148)\u001b[0m 2023-09-19 20:34:53,322\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27143)\u001b[0m 2023-09-19 20:34:53,322\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27165)\u001b[0m 2023-09-19 20:34:55,551\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27148)\u001b[0m 2023-09-19 20:34:57,309\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27148)\u001b[0m 2023-09-19 20:34:57,344\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d309ca94dbd04bad98cb7bdd8797e224\n",
      "\u001b[2m\u001b[36m(PPO pid=27148)\u001b[0m 2023-09-19 20:34:57,344\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4930, '_timesteps_total': None, '_time_total': 979.3736524581909, '_episodes_total': 1606}\n",
      "2023-09-19 20:35:08,706\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=27190)\u001b[0m 2023-09-19 20:35:12,245\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27168)\u001b[0m 2023-09-19 20:35:12,245\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27191)\u001b[0m 2023-09-19 20:35:14,404\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27190)\u001b[0m 2023-09-19 20:35:16,135\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27190)\u001b[0m 2023-09-19 20:35:16,166\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_885b267472b74833bd978f2cad3919f8\n",
      "\u001b[2m\u001b[36m(PPO pid=27190)\u001b[0m 2023-09-19 20:35:16,166\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4930, '_timesteps_total': None, '_time_total': 979.3736524581909, '_episodes_total': 1606}\n",
      "\u001b[2m\u001b[36m(PPO pid=27218)\u001b[0m 2023-09-19 20:35:30,346\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27195)\u001b[0m 2023-09-19 20:35:30,346\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27219)\u001b[0m 2023-09-19 20:35:32,596\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27218)\u001b[0m 2023-09-19 20:35:34,403\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27218)\u001b[0m 2023-09-19 20:35:34,436\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_b9a223739bcf4844a4a561e7ba4d2bed\n",
      "\u001b[2m\u001b[36m(PPO pid=27218)\u001b[0m 2023-09-19 20:35:34,436\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4978, '_timesteps_total': None, '_time_total': 989.4901444911957, '_episodes_total': 1621}\n",
      "2023-09-19 20:35:45,657\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.154643) into trial 76be2_00000 (score = 0.138557)\n",
      "\n",
      "2023-09-19 20:35:45,657\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 9.973891142109054e-05 --- (* 1.2) --> 0.00011968669370530864\n",
      "gamma : 0.7841882972860781 --- (* 0.8) --> 0.6273506378288625\n",
      "clip_param : 0.10186206244922685 --- (* 1.2) --> 0.12223447493907222\n",
      "kl_coeff : 0.8913973521180099 --- (* 1.2) --> 1.0696768225416118\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27223)\u001b[0m 2023-09-19 20:35:49,266\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27222)\u001b[0m 2023-09-19 20:35:49,266\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27226)\u001b[0m 2023-09-19 20:35:51,394\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27223)\u001b[0m 2023-09-19 20:35:53,117\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27223)\u001b[0m 2023-09-19 20:35:53,153\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_51e18936bfbc4279bbffe04d69d21362\n",
      "\u001b[2m\u001b[36m(PPO pid=27223)\u001b[0m 2023-09-19 20:35:53,153\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4978, '_timesteps_total': None, '_time_total': 989.5501675605774, '_episodes_total': 1621}\n",
      "\u001b[2m\u001b[36m(PPO pid=27233)\u001b[0m 2023-09-19 20:36:07,358\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27229)\u001b[0m 2023-09-19 20:36:07,358\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27234)\u001b[0m 2023-09-19 20:36:09,567\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27233)\u001b[0m 2023-09-19 20:36:11,322\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27233)\u001b[0m 2023-09-19 20:36:11,368\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_a62868c9dac64802ab60ab7a3212f654\n",
      "\u001b[2m\u001b[36m(PPO pid=27233)\u001b[0m 2023-09-19 20:36:11,368\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 4978, '_timesteps_total': None, '_time_total': 989.5501675605774, '_episodes_total': 1621}\n",
      "2023-09-19 20:36:22,677\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.155720) into trial 76be2_00000 (score = 0.147679)\n",
      "\n",
      "2023-09-19 20:36:22,678\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 9.973891142109054e-05 --- (resample) --> 0.00023053762707550267\n",
      "gamma : 0.7841882972860781 --- (* 1.2) --> 0.9410259567432937\n",
      "clip_param : 0.10186206244922685 --- (* 1.2) --> 0.12223447493907222\n",
      "kl_coeff : 0.8913973521180099 --- (* 1.2) --> 1.0696768225416118\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27240)\u001b[0m 2023-09-19 20:36:25,349\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27237)\u001b[0m 2023-09-19 20:36:25,349\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27243)\u001b[0m 2023-09-19 20:36:27,657\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "2023-09-19 20:36:40,710\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=27251)\u001b[0m 2023-09-19 20:36:44,408\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27247)\u001b[0m 2023-09-19 20:36:44,408\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27252)\u001b[0m 2023-09-19 20:36:46,524\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27251)\u001b[0m 2023-09-19 20:36:48,305\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27251)\u001b[0m 2023-09-19 20:36:48,341\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_aa241918005647c3b7abc8f776aae0b4\n",
      "\u001b[2m\u001b[36m(PPO pid=27251)\u001b[0m 2023-09-19 20:36:48,341\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5027, '_timesteps_total': None, '_time_total': 999.6193995475769, '_episodes_total': 1636}\n",
      "2023-09-19 20:36:59,454\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=27263)\u001b[0m 2023-09-19 20:37:02,380\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27255)\u001b[0m 2023-09-19 20:37:02,380\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27265)\u001b[0m 2023-09-19 20:37:04,651\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27263)\u001b[0m 2023-09-19 20:37:06,452\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27263)\u001b[0m 2023-09-19 20:37:06,481\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_3537774246304161bf5f57ad7df10fdb\n",
      "\u001b[2m\u001b[36m(PPO pid=27263)\u001b[0m 2023-09-19 20:37:06,481\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5075, '_timesteps_total': None, '_time_total': 1009.7623562812805, '_episodes_total': 1651}\n",
      "\u001b[2m\u001b[36m(PPO pid=27271)\u001b[0m 2023-09-19 20:37:21,493\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27268)\u001b[0m 2023-09-19 20:37:21,493\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27272)\u001b[0m 2023-09-19 20:37:23,587\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27271)\u001b[0m 2023-09-19 20:37:25,317\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27271)\u001b[0m 2023-09-19 20:37:25,352\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d2700f7a92c54be0a1e444ef56d76e0e\n",
      "\u001b[2m\u001b[36m(PPO pid=27271)\u001b[0m 2023-09-19 20:37:25,352\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5075, '_timesteps_total': None, '_time_total': 1009.6479339599609, '_episodes_total': 1651}\n",
      "2023-09-19 20:37:36,625\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.154964) into trial 76be2_00000 (score = 0.127583)\n",
      "\n",
      "2023-09-19 20:37:36,625\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 9.973891142109054e-05 --- (* 1.2) --> 0.00011968669370530864\n",
      "gamma : 0.7841882972860781 --- (* 0.8) --> 0.6273506378288625\n",
      "clip_param : 0.10186206244922685 --- (* 0.8) --> 0.08148964995938149\n",
      "kl_coeff : 0.8913973521180099 --- (* 1.2) --> 1.0696768225416118\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27285)\u001b[0m 2023-09-19 20:37:39,415\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27275)\u001b[0m 2023-09-19 20:37:39,415\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27287)\u001b[0m 2023-09-19 20:37:41,670\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27285)\u001b[0m 2023-09-19 20:37:43,486\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27285)\u001b[0m 2023-09-19 20:37:43,515\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_dc10779a9af7470388352c5dc67424a0\n",
      "\u001b[2m\u001b[36m(PPO pid=27285)\u001b[0m 2023-09-19 20:37:43,515\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5123, '_timesteps_total': None, '_time_total': 1019.9141356945038, '_episodes_total': 1666}\n",
      "\u001b[2m\u001b[36m(PPO pid=27293)\u001b[0m 2023-09-19 20:37:58,534\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27290)\u001b[0m 2023-09-19 20:37:58,534\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27294)\u001b[0m 2023-09-19 20:38:00,671\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27293)\u001b[0m 2023-09-19 20:38:02,424\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27293)\u001b[0m 2023-09-19 20:38:02,452\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_416334949ed3427e8701b85b07204887\n",
      "\u001b[2m\u001b[36m(PPO pid=27293)\u001b[0m 2023-09-19 20:38:02,452\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5123, '_timesteps_total': None, '_time_total': 1019.9141356945038, '_episodes_total': 1666}\n",
      "2023-09-19 20:38:13,770\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.164547) into trial 76be2_00000 (score = 0.163577)\n",
      "\n",
      "2023-09-19 20:38:13,771\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 9.973891142109054e-05 --- (* 1.2) --> 0.00011968669370530864\n",
      "gamma : 0.7841882972860781 --- (* 0.8) --> 0.6273506378288625\n",
      "clip_param : 0.10186206244922685 --- (resample) --> 0.16665702681442876\n",
      "kl_coeff : 0.8913973521180099 --- (resample) --> 1.3516264190697733\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27300)\u001b[0m 2023-09-19 20:38:16,534\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27297)\u001b[0m 2023-09-19 20:38:16,534\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27304)\u001b[0m 2023-09-19 20:38:18,900\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27300)\u001b[0m 2023-09-19 20:38:20,635\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27300)\u001b[0m 2023-09-19 20:38:20,676\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_eda369e5625d46449b146487e12f1969\n",
      "\u001b[2m\u001b[36m(PPO pid=27300)\u001b[0m 2023-09-19 20:38:20,676\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5171, '_timesteps_total': None, '_time_total': 1030.0465557575226, '_episodes_total': 1681}\n",
      "2023-09-19 20:38:31,803\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=27314)\u001b[0m 2023-09-19 20:38:34,515\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27307)\u001b[0m 2023-09-19 20:38:34,515\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27315)\u001b[0m 2023-09-19 20:38:36,810\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27314)\u001b[0m 2023-09-19 20:38:38,760\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27314)\u001b[0m 2023-09-19 20:38:38,788\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_fe9a2001aebd4a5c8a1642033b54993e\n",
      "\u001b[2m\u001b[36m(PPO pid=27314)\u001b[0m 2023-09-19 20:38:38,788\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5171, '_timesteps_total': None, '_time_total': 1030.0465557575226, '_episodes_total': 1681}\n",
      "2023-09-19 20:38:50,138\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=27321)\u001b[0m 2023-09-19 20:38:53,612\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27318)\u001b[0m 2023-09-19 20:38:53,612\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27323)\u001b[0m 2023-09-19 20:38:55,762\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27321)\u001b[0m 2023-09-19 20:38:57,527\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27321)\u001b[0m 2023-09-19 20:38:57,568\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_184beaec3ad54f91abf2fb78eaa9286b\n",
      "\u001b[2m\u001b[36m(PPO pid=27321)\u001b[0m 2023-09-19 20:38:57,568\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5218, '_timesteps_total': None, '_time_total': 1040.0874075889587, '_episodes_total': 1696}\n",
      "\u001b[2m\u001b[36m(PPO pid=27327)\u001b[0m 2023-09-19 20:39:11,578\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27326)\u001b[0m 2023-09-19 20:39:11,578\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27328)\u001b[0m 2023-09-19 20:39:13,886\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27327)\u001b[0m 2023-09-19 20:39:15,641\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27327)\u001b[0m 2023-09-19 20:39:15,679\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_8b1a6e1e1059452f84656eb7157bba65\n",
      "\u001b[2m\u001b[36m(PPO pid=27327)\u001b[0m 2023-09-19 20:39:15,679\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5219, '_timesteps_total': None, '_time_total': 1040.149878025055, '_episodes_total': 1696}\n",
      "2023-09-19 20:39:27,119\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.158055) into trial 76be2_00000 (score = 0.130841)\n",
      "\n",
      "2023-09-19 20:39:27,120\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 9.973891142109054e-05 --- (* 0.8) --> 7.979112913687243e-05\n",
      "gamma : 0.7841882972860781 --- (resample) --> 0.9550285702248836\n",
      "clip_param : 0.10186206244922685 --- (* 0.8) --> 0.08148964995938149\n",
      "kl_coeff : 0.8913973521180099 --- (* 1.2) --> 1.0696768225416118\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27338)\u001b[0m 2023-09-19 20:39:30,588\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27331)\u001b[0m 2023-09-19 20:39:30,588\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27340)\u001b[0m 2023-09-19 20:39:32,714\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27338)\u001b[0m 2023-09-19 20:39:34,505\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27338)\u001b[0m 2023-09-19 20:39:34,535\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_37b88799936d461796cb55e8c4ee5da0\n",
      "\u001b[2m\u001b[36m(PPO pid=27338)\u001b[0m 2023-09-19 20:39:34,535\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5266, '_timesteps_total': None, '_time_total': 1050.2375872135162, '_episodes_total': 1711}\n",
      "\u001b[2m\u001b[36m(PPO pid=27346)\u001b[0m 2023-09-19 20:39:48,608\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27343)\u001b[0m 2023-09-19 20:39:48,608\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27347)\u001b[0m 2023-09-19 20:39:50,706\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27346)\u001b[0m 2023-09-19 20:39:52,453\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27346)\u001b[0m 2023-09-19 20:39:52,494\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_2a5bd5ce32f4432f914751deb89ae6cf\n",
      "\u001b[2m\u001b[36m(PPO pid=27346)\u001b[0m 2023-09-19 20:39:52,494\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5266, '_timesteps_total': None, '_time_total': 1050.2375872135162, '_episodes_total': 1711}\n",
      "\u001b[2m\u001b[36m(PPO pid=27351)\u001b[0m 2023-09-19 20:40:06,613\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27350)\u001b[0m 2023-09-19 20:40:06,613\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27354)\u001b[0m 2023-09-19 20:40:08,664\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27351)\u001b[0m 2023-09-19 20:40:10,428\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27351)\u001b[0m 2023-09-19 20:40:10,461\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_45861ed25a9a4ccd946efd5dad318019\n",
      "\u001b[2m\u001b[36m(PPO pid=27351)\u001b[0m 2023-09-19 20:40:10,461\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5317, '_timesteps_total': None, '_time_total': 1060.3316440582275, '_episodes_total': 1728}\n",
      "2023-09-19 20:40:21,762\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.158819) into trial 76be2_00001 (score = 0.122693)\n",
      "\n",
      "2023-09-19 20:40:21,762\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 7.979112913687243e-05 --- (resample) --> 0.0003103497551884614\n",
      "gamma : 0.9550285702248836 --- (resample) --> 0.959161673343328\n",
      "clip_param : 0.08148964995938149 --- (* 0.8) --> 0.0651917199675052\n",
      "kl_coeff : 1.0696768225416118 --- (* 0.8) --> 0.8557414580332895\n",
      "\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27363)\u001b[0m 2023-09-19 20:40:26,700\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27360)\u001b[0m 2023-09-19 20:40:28,412\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27360)\u001b[0m 2023-09-19 20:40:28,457\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_abb0acdc2a3e4eaf9634bf1b013336c5\n",
      "\u001b[2m\u001b[36m(PPO pid=27360)\u001b[0m 2023-09-19 20:40:28,457\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5318, '_timesteps_total': None, '_time_total': 1060.4122614860535, '_episodes_total': 1728}\n",
      "\u001b[2m\u001b[36m(PPO pid=27372)\u001b[0m 2023-09-19 20:40:42,718\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27366)\u001b[0m 2023-09-19 20:40:42,718\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27373)\u001b[0m 2023-09-19 20:40:44,624\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27372)\u001b[0m 2023-09-19 20:40:46,409\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27372)\u001b[0m 2023-09-19 20:40:46,438\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_a9229c15bf594d6485d00f046a6e8907\n",
      "\u001b[2m\u001b[36m(PPO pid=27372)\u001b[0m 2023-09-19 20:40:46,438\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5318, '_timesteps_total': None, '_time_total': 1060.4122614860535, '_episodes_total': 1728}\n",
      "2023-09-19 20:40:57,622\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.152625) into trial 76be2_00001 (score = 0.144762)\n",
      "\n",
      "2023-09-19 20:40:57,622\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 7.979112913687243e-05 --- (resample) --> 0.000530323517434946\n",
      "gamma : 0.9550285702248836 --- (resample) --> 0.970148560107414\n",
      "clip_param : 0.08148964995938149 --- (* 0.8) --> 0.0651917199675052\n",
      "kl_coeff : 1.0696768225416118 --- (* 0.8) --> 0.8557414580332895\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27377)\u001b[0m 2023-09-19 20:41:00,762\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27376)\u001b[0m 2023-09-19 20:41:00,762\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27378)\u001b[0m 2023-09-19 20:41:02,631\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27377)\u001b[0m 2023-09-19 20:41:04,366\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27377)\u001b[0m 2023-09-19 20:41:04,394\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ccbab8d3bf9c43309f1d01bc206c30c8\n",
      "\u001b[2m\u001b[36m(PPO pid=27377)\u001b[0m 2023-09-19 20:41:04,394\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5370, '_timesteps_total': None, '_time_total': 1070.548644542694, '_episodes_total': 1745}\n",
      "2023-09-19 20:41:15,692\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=27385)\u001b[0m 2023-09-19 20:41:18,768\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27381)\u001b[0m 2023-09-19 20:41:18,768\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27386)\u001b[0m 2023-09-19 20:41:20,576\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27385)\u001b[0m 2023-09-19 20:41:22,360\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27385)\u001b[0m 2023-09-19 20:41:22,396\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_80e9b7e9d1874f16b92c842c135164be\n",
      "\u001b[2m\u001b[36m(PPO pid=27385)\u001b[0m 2023-09-19 20:41:22,396\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5370, '_timesteps_total': None, '_time_total': 1070.548644542694, '_episodes_total': 1745}\n",
      "\u001b[2m\u001b[36m(PPO pid=27391)\u001b[0m 2023-09-19 20:41:36,819\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27389)\u001b[0m 2023-09-19 20:41:36,819\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27392)\u001b[0m 2023-09-19 20:41:38,723\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27391)\u001b[0m 2023-09-19 20:41:40,426\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27391)\u001b[0m 2023-09-19 20:41:40,454\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_3220d61a6a8042edb7bce9f7753cd3f6\n",
      "\u001b[2m\u001b[36m(PPO pid=27391)\u001b[0m 2023-09-19 20:41:40,454\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5422, '_timesteps_total': None, '_time_total': 1080.5961654186249, '_episodes_total': 1762}\n",
      "\u001b[2m\u001b[36m(PPO pid=27396)\u001b[0m 2023-09-19 20:41:54,839\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27395)\u001b[0m 2023-09-19 20:41:54,839\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27397)\u001b[0m 2023-09-19 20:41:57,024\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27396)\u001b[0m 2023-09-19 20:41:58,821\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27396)\u001b[0m 2023-09-19 20:41:58,852\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c3dee952c3d84368bbe5ac312a2423e0\n",
      "\u001b[2m\u001b[36m(PPO pid=27396)\u001b[0m 2023-09-19 20:41:58,852\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5422, '_timesteps_total': None, '_time_total': 1080.694277048111, '_episodes_total': 1762}\n",
      "2023-09-19 20:42:10,126\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.163804) into trial 76be2_00001 (score = 0.126123)\n",
      "\n",
      "2023-09-19 20:42:10,127\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 7.979112913687243e-05 --- (* 1.2) --> 9.574935496424691e-05\n",
      "gamma : 0.9550285702248836 --- (* 1.2) --> 1.1460342842698603\n",
      "clip_param : 0.08148964995938149 --- (* 0.8) --> 0.0651917199675052\n",
      "kl_coeff : 1.0696768225416118 --- (* 1.2) --> 1.2836121870499342\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27402)\u001b[0m 2023-09-19 20:42:12,831\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27400)\u001b[0m 2023-09-19 20:42:12,831\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27405)\u001b[0m 2023-09-19 20:42:14,705\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27402)\u001b[0m 2023-09-19 20:42:16,478\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27402)\u001b[0m 2023-09-19 20:42:16,508\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_3e15cfd58a2b442da4b6d528627ae811\n",
      "\u001b[2m\u001b[36m(PPO pid=27402)\u001b[0m 2023-09-19 20:42:16,508\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5473, '_timesteps_total': None, '_time_total': 1090.617492198944, '_episodes_total': 1779}\n",
      "\u001b[2m\u001b[36m(PPO pid=27410)\u001b[0m 2023-09-19 20:42:30,772\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27408)\u001b[0m 2023-09-19 20:42:30,772\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=27410)\u001b[0m 2023-09-19 20:42:34,574\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27410)\u001b[0m 2023-09-19 20:42:34,624\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_7e8cd44755744fd794ef16f7d6c61966\n",
      "\u001b[2m\u001b[36m(PPO pid=27410)\u001b[0m 2023-09-19 20:42:34,624\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5473, '_timesteps_total': None, '_time_total': 1090.617492198944, '_episodes_total': 1779}\n",
      "2023-09-19 20:42:46,066\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.153667) into trial 76be2_00001 (score = 0.140650)\n",
      "\n",
      "2023-09-19 20:42:46,066\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 7.979112913687243e-05 --- (* 1.2) --> 9.574935496424691e-05\n",
      "gamma : 0.9550285702248836 --- (* 1.2) --> 1.1460342842698603\n",
      "clip_param : 0.08148964995938149 --- (* 1.2) --> 0.09778757995125778\n",
      "kl_coeff : 1.0696768225416118 --- (* 0.8) --> 0.8557414580332895\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27416)\u001b[0m 2023-09-19 20:42:48,927\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27415)\u001b[0m 2023-09-19 20:42:48,927\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27417)\u001b[0m 2023-09-19 20:42:50,828\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27416)\u001b[0m 2023-09-19 20:42:52,531\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27416)\u001b[0m 2023-09-19 20:42:52,559\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_9cd23ef4f95c4e23842eca142a3e2612\n",
      "\u001b[2m\u001b[36m(PPO pid=27416)\u001b[0m 2023-09-19 20:42:52,559\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5526, '_timesteps_total': None, '_time_total': 1100.6396985054016, '_episodes_total': 1796}\n",
      "2023-09-19 20:43:03,993\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=27422)\u001b[0m 2023-09-19 20:43:06,918\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27420)\u001b[0m 2023-09-19 20:43:06,918\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27423)\u001b[0m 2023-09-19 20:43:08,815\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27422)\u001b[0m 2023-09-19 20:43:10,519\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27422)\u001b[0m 2023-09-19 20:43:10,547\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_a9bed23bb804428c8d0af1566af1d7bd\n",
      "\u001b[2m\u001b[36m(PPO pid=27422)\u001b[0m 2023-09-19 20:43:10,547\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5526, '_timesteps_total': None, '_time_total': 1100.6396985054016, '_episodes_total': 1796}\n",
      "\u001b[2m\u001b[36m(PPO pid=27428)\u001b[0m 2023-09-19 20:43:24,936\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27426)\u001b[0m 2023-09-19 20:43:24,936\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27429)\u001b[0m 2023-09-19 20:43:26,845\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27428)\u001b[0m 2023-09-19 20:43:28,619\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27428)\u001b[0m 2023-09-19 20:43:28,649\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_9da3fac2e2ae47b9ac4d82990913a620\n",
      "\u001b[2m\u001b[36m(PPO pid=27428)\u001b[0m 2023-09-19 20:43:28,649\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5579, '_timesteps_total': None, '_time_total': 1110.7659561634064, '_episodes_total': 1813}\n",
      "2023-09-19 20:43:39,984\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.155815) into trial 76be2_00000 (score = 0.133474)\n",
      "\n",
      "2023-09-19 20:43:39,985\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 9.574935496424691e-05 --- (* 0.8) --> 7.659948397139753e-05\n",
      "gamma : 1.1460342842698603 --- (resample) --> 0.9748177164867969\n",
      "clip_param : 0.09778757995125778 --- (resample) --> 0.21328745781380354\n",
      "kl_coeff : 0.8557414580332895 --- (resample) --> 0.22674134118676997\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27444)\u001b[0m 2023-09-19 20:43:43,005\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27432)\u001b[0m 2023-09-19 20:43:43,005\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27447)\u001b[0m 2023-09-19 20:43:45,140\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27444)\u001b[0m 2023-09-19 20:43:46,877\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27444)\u001b[0m 2023-09-19 20:43:46,911\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_90d2eb6ed9b540cda655593e65a2ebfd\n",
      "\u001b[2m\u001b[36m(PPO pid=27444)\u001b[0m 2023-09-19 20:43:46,911\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5577, '_timesteps_total': None, '_time_total': 1110.6524555683136, '_episodes_total': 1813}\n",
      "\u001b[2m\u001b[36m(PPO pid=27454)\u001b[0m 2023-09-19 20:44:00,980\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27450)\u001b[0m 2023-09-19 20:44:00,980\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27455)\u001b[0m 2023-09-19 20:44:02,904\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27454)\u001b[0m 2023-09-19 20:44:04,625\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27454)\u001b[0m 2023-09-19 20:44:04,656\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d6692d9e02af4c9d980b4ad8c78578a3\n",
      "\u001b[2m\u001b[36m(PPO pid=27454)\u001b[0m 2023-09-19 20:44:04,656\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5577, '_timesteps_total': None, '_time_total': 1110.6524555683136, '_episodes_total': 1813}\n",
      "2023-09-19 20:44:15,947\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.172175) into trial 76be2_00000 (score = 0.149006)\n",
      "\n",
      "2023-09-19 20:44:15,947\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 9.574935496424691e-05 --- (* 1.2) --> 0.0001148992259570963\n",
      "gamma : 1.1460342842698603 --- (resample) --> 0.9711484091338632\n",
      "clip_param : 0.09778757995125778 --- (* 1.2) --> 0.11734509594150933\n",
      "kl_coeff : 0.8557414580332895 --- (* 0.8) --> 0.6845931664266316\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27460)\u001b[0m 2023-09-19 20:44:19,058\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27458)\u001b[0m 2023-09-19 20:44:19,058\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27463)\u001b[0m 2023-09-19 20:44:21,010\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27460)\u001b[0m 2023-09-19 20:44:22,721\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27460)\u001b[0m 2023-09-19 20:44:22,756\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_c74e1623586a4b7a9baafafabdaa4fea\n",
      "\u001b[2m\u001b[36m(PPO pid=27460)\u001b[0m 2023-09-19 20:44:22,756\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5628, '_timesteps_total': None, '_time_total': 1120.7302124500275, '_episodes_total': 1830}\n",
      "\u001b[2m\u001b[36m(PPO pid=27471)\u001b[0m 2023-09-19 20:44:37,064\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27466)\u001b[0m 2023-09-19 20:44:37,064\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27473)\u001b[0m 2023-09-19 20:44:39,002\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27471)\u001b[0m 2023-09-19 20:44:40,732\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27471)\u001b[0m 2023-09-19 20:44:40,775\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_0d1b28184a5341fcb1a50deced1e277e\n",
      "\u001b[2m\u001b[36m(PPO pid=27471)\u001b[0m 2023-09-19 20:44:40,775\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5628, '_timesteps_total': None, '_time_total': 1120.7302124500275, '_episodes_total': 1830}\n",
      "\u001b[2m\u001b[36m(PPO pid=27478)\u001b[0m 2023-09-19 20:44:54,952\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27476)\u001b[0m 2023-09-19 20:44:54,952\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27480)\u001b[0m 2023-09-19 20:44:56,908\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27478)\u001b[0m 2023-09-19 20:44:58,647\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27478)\u001b[0m 2023-09-19 20:44:58,677\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d3d2e82b7dfb4a7b825040b16b25e995\n",
      "\u001b[2m\u001b[36m(PPO pid=27478)\u001b[0m 2023-09-19 20:44:58,677\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5680, '_timesteps_total': None, '_time_total': 1130.7557866573334, '_episodes_total': 1847}\n",
      "2023-09-19 20:45:09,993\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.164318) into trial 76be2_00001 (score = 0.164255)\n",
      "\n",
      "2023-09-19 20:45:09,994\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.0001148992259570963 --- (* 1.2) --> 0.00013787907114851556\n",
      "gamma : 0.9711484091338632 --- (* 0.8) --> 0.7769187273070907\n",
      "clip_param : 0.11734509594150933 --- (* 0.8) --> 0.09387607675320747\n",
      "kl_coeff : 0.6845931664266316 --- (* 1.2) --> 0.8215117997119579\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27485)\u001b[0m 2023-09-19 20:45:13,106\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27483)\u001b[0m 2023-09-19 20:45:13,106\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27488)\u001b[0m 2023-09-19 20:45:15,009\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27485)\u001b[0m 2023-09-19 20:45:16,766\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27485)\u001b[0m 2023-09-19 20:45:16,810\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_9060ab4735c041cf8a49d18aabc7cc9c\n",
      "\u001b[2m\u001b[36m(PPO pid=27485)\u001b[0m 2023-09-19 20:45:16,811\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5680, '_timesteps_total': None, '_time_total': 1130.8428432941437, '_episodes_total': 1847}\n",
      "2023-09-19 20:45:28,025\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00000\n",
      "\u001b[2m\u001b[36m(PPO pid=27496)\u001b[0m 2023-09-19 20:45:31,112\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27491)\u001b[0m 2023-09-19 20:45:31,112\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27497)\u001b[0m 2023-09-19 20:45:33,018\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27496)\u001b[0m 2023-09-19 20:45:34,782\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27496)\u001b[0m 2023-09-19 20:45:34,825\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_82da0f39ccf24b08a13db70f1214647b\n",
      "\u001b[2m\u001b[36m(PPO pid=27496)\u001b[0m 2023-09-19 20:45:34,825\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5680, '_timesteps_total': None, '_time_total': 1130.8428432941437, '_episodes_total': 1847}\n",
      "\u001b[2m\u001b[36m(PPO pid=27502)\u001b[0m 2023-09-19 20:45:49,198\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27500)\u001b[0m 2023-09-19 20:45:49,198\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27503)\u001b[0m 2023-09-19 20:45:51,176\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27502)\u001b[0m 2023-09-19 20:45:52,952\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27502)\u001b[0m 2023-09-19 20:45:52,981\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_59a879a29ddc487c95b31d31930b246b\n",
      "\u001b[2m\u001b[36m(PPO pid=27502)\u001b[0m 2023-09-19 20:45:52,981\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5732, '_timesteps_total': None, '_time_total': 1140.9534459114075, '_episodes_total': 1864}\n",
      "2023-09-19 20:46:04,274\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.138615) into trial 76be2_00000 (score = 0.137653)\n",
      "\n",
      "2023-09-19 20:46:04,274\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00013787907114851556 --- (* 1.2) --> 0.00016545488537821868\n",
      "gamma : 0.7769187273070907 --- (* 1.2) --> 0.9323024727685087\n",
      "clip_param : 0.09387607675320747 --- (resample) --> 0.150352242236993\n",
      "kl_coeff : 0.8215117997119579 --- (* 1.2) --> 0.9858141596543494\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27508)\u001b[0m 2023-09-19 20:46:07,147\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27506)\u001b[0m 2023-09-19 20:46:07,147\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27512)\u001b[0m 2023-09-19 20:46:09,168\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27508)\u001b[0m 2023-09-19 20:46:10,886\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27508)\u001b[0m 2023-09-19 20:46:10,915\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_9606397c3eab4a6e824f527ab3236259\n",
      "\u001b[2m\u001b[36m(PPO pid=27508)\u001b[0m 2023-09-19 20:46:10,915\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5733, '_timesteps_total': None, '_time_total': 1140.9760336875916, '_episodes_total': 1864}\n",
      "\u001b[2m\u001b[36m(PPO pid=27528)\u001b[0m 2023-09-19 20:46:25,190\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27515)\u001b[0m 2023-09-19 20:46:25,190\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27529)\u001b[0m 2023-09-19 20:46:27,066\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27528)\u001b[0m 2023-09-19 20:46:28,865\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27528)\u001b[0m 2023-09-19 20:46:28,898\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_3a1e914066c044b280fcd46ada87f79e\n",
      "\u001b[2m\u001b[36m(PPO pid=27528)\u001b[0m 2023-09-19 20:46:28,898\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5733, '_timesteps_total': None, '_time_total': 1140.9760336875916, '_episodes_total': 1864}\n",
      "2023-09-19 20:46:40,158\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00001 (score = 0.140208) into trial 76be2_00000 (score = 0.133172)\n",
      "\n",
      "2023-09-19 20:46:40,159\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00000:\n",
      "lr : 0.00013787907114851556 --- (* 0.8) --> 0.00011030325691881245\n",
      "gamma : 0.7769187273070907 --- (* 1.2) --> 0.9323024727685087\n",
      "clip_param : 0.09387607675320747 --- (* 0.8) --> 0.07510086140256599\n",
      "kl_coeff : 0.8215117997119579 --- (* 0.8) --> 0.6572094397695664\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27534)\u001b[0m 2023-09-19 20:46:43,212\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27532)\u001b[0m 2023-09-19 20:46:43,212\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27537)\u001b[0m 2023-09-19 20:46:45,179\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27534)\u001b[0m 2023-09-19 20:46:46,914\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27534)\u001b[0m 2023-09-19 20:46:46,947\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_9453753e21a74ba894815649db45b1be\n",
      "\u001b[2m\u001b[36m(PPO pid=27534)\u001b[0m 2023-09-19 20:46:46,947\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5785, '_timesteps_total': None, '_time_total': 1150.9984118938446, '_episodes_total': 1881}\n",
      "2023-09-19 20:46:58,446\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PPO_wrapped_trading_env_76be2_00001\n",
      "\u001b[2m\u001b[36m(PPO pid=27544)\u001b[0m 2023-09-19 20:47:01,239\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27540)\u001b[0m 2023-09-19 20:47:01,239\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27545)\u001b[0m 2023-09-19 20:47:03,268\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27544)\u001b[0m 2023-09-19 20:47:05,121\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27544)\u001b[0m 2023-09-19 20:47:05,147\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_4250b5be8d844cb3a60f68c2f5ba35c4\n",
      "\u001b[2m\u001b[36m(PPO pid=27544)\u001b[0m 2023-09-19 20:47:05,148\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5785, '_timesteps_total': None, '_time_total': 1150.9984118938446, '_episodes_total': 1881}\n",
      "\u001b[2m\u001b[36m(PPO pid=27550)\u001b[0m 2023-09-19 20:47:19,221\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27548)\u001b[0m 2023-09-19 20:47:19,221\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27553)\u001b[0m 2023-09-19 20:47:21,250\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27550)\u001b[0m 2023-09-19 20:47:22,985\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27550)\u001b[0m 2023-09-19 20:47:23,020\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_779a82ae538c49c5b37d5d8a2c65ac27\n",
      "\u001b[2m\u001b[36m(PPO pid=27550)\u001b[0m 2023-09-19 20:47:23,020\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5837, '_timesteps_total': None, '_time_total': 1161.1366753578186, '_episodes_total': 1898}\n",
      "2023-09-19 20:47:34,397\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.139443) into trial 76be2_00001 (score = 0.119923)\n",
      "\n",
      "2023-09-19 20:47:34,398\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00011030325691881245 --- (resample) --> 0.0006150544025563119\n",
      "gamma : 0.9323024727685087 --- (* 1.2) --> 1.1187629673222104\n",
      "clip_param : 0.07510086140256599 --- (resample) --> 0.16247534861164004\n",
      "kl_coeff : 0.6572094397695664 --- (resample) --> 0.6905857352766741\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27568)\u001b[0m 2023-09-19 20:47:37,313\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27566)\u001b[0m 2023-09-19 20:47:37,313\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27571)\u001b[0m 2023-09-19 20:47:39,239\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27568)\u001b[0m 2023-09-19 20:47:41,058\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27568)\u001b[0m 2023-09-19 20:47:41,090\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_9acde8fc2ef540de8110e79da3666309\n",
      "\u001b[2m\u001b[36m(PPO pid=27568)\u001b[0m 2023-09-19 20:47:41,091\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5836, '_timesteps_total': None, '_time_total': 1161.0194339752197, '_episodes_total': 1898}\n",
      "\u001b[2m\u001b[36m(PPO pid=27579)\u001b[0m 2023-09-19 20:47:55,338\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27575)\u001b[0m 2023-09-19 20:47:55,338\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27580)\u001b[0m 2023-09-19 20:47:57,276\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27579)\u001b[0m 2023-09-19 20:47:58,998\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27579)\u001b[0m 2023-09-19 20:47:59,028\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_d8d11660202b41bfadb90dee3fff9898\n",
      "\u001b[2m\u001b[36m(PPO pid=27579)\u001b[0m 2023-09-19 20:47:59,028\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5836, '_timesteps_total': None, '_time_total': 1161.0194339752197, '_episodes_total': 1898}\n",
      "2023-09-19 20:48:10,240\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.142198) into trial 76be2_00001 (score = 0.127943)\n",
      "\n",
      "2023-09-19 20:48:10,240\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00011030325691881245 --- (* 1.2) --> 0.00013236390830257495\n",
      "gamma : 0.9323024727685087 --- (* 0.8) --> 0.745841978214807\n",
      "clip_param : 0.07510086140256599 --- (* 1.2) --> 0.09012103368307918\n",
      "kl_coeff : 0.6572094397695664 --- (* 0.8) --> 0.5257675518156532\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27585)\u001b[0m 2023-09-19 20:48:13,357\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27583)\u001b[0m 2023-09-19 20:48:13,357\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27588)\u001b[0m 2023-09-19 20:48:15,284\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27585)\u001b[0m 2023-09-19 20:48:17,009\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27585)\u001b[0m 2023-09-19 20:48:17,050\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_ccb49bc09ecc46a5a3963388c67d9292\n",
      "\u001b[2m\u001b[36m(PPO pid=27585)\u001b[0m 2023-09-19 20:48:17,050\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5889, '_timesteps_total': None, '_time_total': 1171.0964848995209, '_episodes_total': 1915}\n",
      "\u001b[2m\u001b[36m(PPO pid=27599)\u001b[0m 2023-09-19 20:48:31,370\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27591)\u001b[0m 2023-09-19 20:48:31,370\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27601)\u001b[0m 2023-09-19 20:48:33,457\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27599)\u001b[0m 2023-09-19 20:48:35,167\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27599)\u001b[0m 2023-09-19 20:48:35,215\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_6c3da03c004c4154b793499bf5f7699c\n",
      "\u001b[2m\u001b[36m(PPO pid=27599)\u001b[0m 2023-09-19 20:48:35,215\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5889, '_timesteps_total': None, '_time_total': 1171.0964848995209, '_episodes_total': 1915}\n",
      "\u001b[2m\u001b[36m(PPO pid=27605)\u001b[0m 2023-09-19 20:48:49,411\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27604)\u001b[0m 2023-09-19 20:48:49,411\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27606)\u001b[0m 2023-09-19 20:48:51,339\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27605)\u001b[0m 2023-09-19 20:48:53,185\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27605)\u001b[0m 2023-09-19 20:48:53,218\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_3d40f1897eed4bc8bb2b128d53e36a58\n",
      "\u001b[2m\u001b[36m(PPO pid=27605)\u001b[0m 2023-09-19 20:48:53,218\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5941, '_timesteps_total': None, '_time_total': 1181.177873134613, '_episodes_total': 1932}\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "\u001b[2m\u001b[36m(PPO pid=27611)\u001b[0m 2023-09-19 20:49:07,444\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27609)\u001b[0m 2023-09-19 20:49:07,444\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27612)\u001b[0m 2023-09-19 20:49:09,406\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27611)\u001b[0m 2023-09-19 20:49:11,124\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27611)\u001b[0m 2023-09-19 20:49:11,159\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_37036df6181549fd8105f71d2b63cff9\n",
      "\u001b[2m\u001b[36m(PPO pid=27611)\u001b[0m 2023-09-19 20:49:11,159\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5941, '_timesteps_total': None, '_time_total': 1181.150135755539, '_episodes_total': 1932}\n",
      "2023-09-19 20:49:22,555\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.154913) into trial 76be2_00001 (score = 0.139810)\n",
      "\n",
      "2023-09-19 20:49:22,555\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00011030325691881245 --- (* 1.2) --> 0.00013236390830257495\n",
      "gamma : 0.9323024727685087 --- (* 1.2) --> 1.1187629673222104\n",
      "clip_param : 0.07510086140256599 --- (* 0.8) --> 0.06008068912205279\n",
      "kl_coeff : 0.6572094397695664 --- (* 1.2) --> 0.7886513277234796\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27617)\u001b[0m 2023-09-19 20:49:25,451\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27615)\u001b[0m 2023-09-19 20:49:25,451\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=27617)\u001b[0m 2023-09-19 20:49:29,148\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27617)\u001b[0m 2023-09-19 20:49:29,178\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_cc07998c09eb47cc8d849259dcdba5cd\n",
      "\u001b[2m\u001b[36m(PPO pid=27617)\u001b[0m 2023-09-19 20:49:29,178\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5994, '_timesteps_total': None, '_time_total': 1191.3361313343048, '_episodes_total': 1949}\n",
      "\u001b[2m\u001b[36m(PPO pid=27627)\u001b[0m 2023-09-19 20:49:43,515\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27623)\u001b[0m 2023-09-19 20:49:43,515\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27628)\u001b[0m 2023-09-19 20:49:45,464\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27627)\u001b[0m 2023-09-19 20:49:47,188\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27627)\u001b[0m 2023-09-19 20:49:47,233\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_0b7fd4195b674429ad96515493b6aa69\n",
      "\u001b[2m\u001b[36m(PPO pid=27627)\u001b[0m 2023-09-19 20:49:47,233\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 5994, '_timesteps_total': None, '_time_total': 1191.3361313343048, '_episodes_total': 1949}\n",
      "2023-09-19 20:49:58,676\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.162105) into trial 76be2_00001 (score = 0.144232)\n",
      "\n",
      "2023-09-19 20:49:58,677\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00011030325691881245 --- (resample) --> 0.000590926312103499\n",
      "gamma : 0.9323024727685087 --- (* 1.2) --> 1.1187629673222104\n",
      "clip_param : 0.07510086140256599 --- (* 1.2) --> 0.09012103368307918\n",
      "kl_coeff : 0.6572094397695664 --- (resample) --> 1.3899272455035205\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27632)\u001b[0m 2023-09-19 20:50:01,517\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27631)\u001b[0m 2023-09-19 20:50:01,517\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27633)\u001b[0m 2023-09-19 20:50:03,442\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27632)\u001b[0m 2023-09-19 20:50:05,249\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27632)\u001b[0m 2023-09-19 20:50:05,277\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_0fe5fa46e04542c98a83981e13d2ef6b\n",
      "\u001b[2m\u001b[36m(PPO pid=27632)\u001b[0m 2023-09-19 20:50:05,277\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 6046, '_timesteps_total': None, '_time_total': 1201.377012014389, '_episodes_total': 1966}\n",
      "\u001b[2m\u001b[36m(PPO pid=27638)\u001b[0m 2023-09-19 20:50:19,589\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27637)\u001b[0m 2023-09-19 20:50:19,589\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27640)\u001b[0m 2023-09-19 20:50:21,531\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27638)\u001b[0m 2023-09-19 20:50:23,288\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27638)\u001b[0m 2023-09-19 20:50:23,318\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_2f6f7033c5a749e78109aaa79383aac9\n",
      "\u001b[2m\u001b[36m(PPO pid=27638)\u001b[0m 2023-09-19 20:50:23,318\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 6046, '_timesteps_total': None, '_time_total': 1201.377012014389, '_episodes_total': 1966}\n",
      "2023-09-19 20:50:34,713\tINFO pbt.py:808 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 76be2_00000 (score = 0.166442) into trial 76be2_00001 (score = 0.140684)\n",
      "\n",
      "2023-09-19 20:50:34,714\tINFO pbt.py:835 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial76be2_00001:\n",
      "lr : 0.00011030325691881245 --- (* 0.8) --> 8.824260553504997e-05\n",
      "gamma : 0.9323024727685087 --- (resample) --> 0.9750185945904175\n",
      "clip_param : 0.07510086140256599 --- (* 0.8) --> 0.06008068912205279\n",
      "kl_coeff : 0.6572094397695664 --- (* 0.8) --> 0.5257675518156532\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=27645)\u001b[0m 2023-09-19 20:50:37,568\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27643)\u001b[0m 2023-09-19 20:50:37,568\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27646)\u001b[0m 2023-09-19 20:50:39,581\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=27645)\u001b[0m 2023-09-19 20:50:41,327\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=27645)\u001b[0m 2023-09-19 20:50:41,358\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /var/folders/wn/s_tdy9qd66s8sxphly7lyhc40000gn/T/checkpoint_tmp_4b7d4b06e1e045f28ce5f1f1278f0fc3\n",
      "\u001b[2m\u001b[36m(PPO pid=27645)\u001b[0m 2023-09-19 20:50:41,358\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 6098, '_timesteps_total': None, '_time_total': 1211.5499584674835, '_episodes_total': 1983}\n",
      "2023-09-19 20:50:46,999\tINFO tune.py:1111 -- Total run time: 5001.08 seconds (5000.35 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "#import ray\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from ray import tune\n",
    "from ray.rllib.algorithms.ppo import PPO\n",
    "\n",
    "# Define a PBT scheduler\n",
    "pbt = PopulationBasedTraining(\n",
    "    time_attr=\"time_total_s\",\n",
    "    metric=\"episode_reward_mean\",\n",
    "    mode=\"max\",\n",
    "    perturbation_interval=10.0, # This defines how frequently (in seconds) to perturb hyperparameters.\n",
    "    hyperparam_mutations={\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-3),\n",
    "        \"gamma\": tune.uniform(0.95, 0.99),\n",
    "        \"clip_param\": tune.uniform(0.1, 0.3),\n",
    "        \"kl_coeff\" : tune.uniform(0.2, 1.5)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define a configuration\n",
    "config = {\n",
    "    \"env\": \"wrapped_trading_env\",\n",
    "    #\"monitor\": False,\n",
    "    #\"checkpoint_freq\": 10,  # Set the desired checkpoint frequency\n",
    "    #\"checkpoint_at_end\": True,  # Uncomment this line if you want to checkpoint at the end\n",
    "    \"env_config\": {\n",
    "        \"data_filepath\": train_data_path,\n",
    "        \"window_size\": 5,\n",
    "        #\"max_episodes_steps\": 60\n",
    "    },\n",
    "    \"evaluation_interval\": 1,\n",
    "    \"evaluation_duration\": 2,\n",
    "    \"evaluation_parallel_to_training\": True,\n",
    "    \"evaluation_config\": {\n",
    "        \"env\": \"wrapped_trading_env\",\n",
    "        \"env_config\": {\n",
    "        \"data_filepath\": validation_data_path,  # replace with your validation data\n",
    "        \"window_size\": 5,\n",
    "            #\"max_episode_steps\": 20  # replace with the maximum number of steps for your validation episodes\n",
    "        },\n",
    "        \"explore\": False,\n",
    "    },\n",
    "    \"batch_mode\": \"truncate_episodes\",\n",
    "    \"rollout_fragment_length\": 'auto',\n",
    "    \"evaluation_num_workers\": 1,\n",
    "    \"always_attach_evaluation_results\": True,\n",
    "    \"num_workers\": 3,\n",
    "    \"num_cpus_per_worker\": 1,\n",
    "    \"framework\" : 'torch',\n",
    "    \"num_gpus\": 0,\n",
    "    \"shuffle_sequences\": False,\n",
    "    \"vf_loss_coeff\": 0, \n",
    "    \"lr\": 0.0003,\n",
    "    \"gamma\": 0.99,\n",
    "    \"clip_param\": 0.2,\n",
    "    \"kl_coeff\": 0.5,\n",
    "    #\"kl_coeff\" : tune.uniform(0.1, 2.0),\n",
    "    \"num_sgd_iter\" : tune.randint(25, 50),\n",
    "    \"sgd_minibatch_size\" : tune.sample_from(lambda _: np.random.randint(2, 10)),\n",
    "    \"train_batch_size\": tune.sample_from(lambda _: np.random.randint(15, 30)),\n",
    "    #\"train_bath_size\": 32,\n",
    "    \"model\":{\n",
    "        \"fcnet_hiddens\": [64, 32],\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "        \"use_lstm\": False,    \n",
    "    },\n",
    "    \"log_level\": \"WARNING\"\n",
    "}\n",
    "stopper = EarlyStoppingStopper(patience=1000, eval_patience=1000, min_iterations=5000)\n",
    "\n",
    "# Run the Tune experiment\n",
    "analysis = tune.run(\n",
    "    PPO,\n",
    "    #resources_per_trial={\"cpu\": 1, \"gpu\": 0},\n",
    "    name=\"PPO_PBT_Trading\",\n",
    "    #reuse_actors=True,\n",
    "    scheduler=pbt,\n",
    "    #stop={\n",
    "    #    #\"evaluation/episode_reward_mean\": 0.02,\n",
    "    #    \"episode_reward_mean\": 0.15,\n",
    "    #    \"time_total_s\": 1000  # Stop after 2 hours\n",
    "    #    #\"timesteps_total\": 50000  # Or after 10,000 timesteps are trained\n",
    "    #},\n",
    "    stop = stopper,\n",
    "    config=config,\n",
    "    checkpoint_at_end=True,\n",
    "    checkpoint_freq=10,\n",
    "    num_samples=2,\n",
    "    verbose=1\n",
    "    #local_dir='/home/himanshu/ray_results/'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'env': 'wrapped_trading_env', 'env_config': {'data_filepath': '/Users/himanshuagrawal/rllib_project/train_file.csv', 'window_size': 5}, 'evaluation_interval': 1, 'evaluation_duration': 2, 'evaluation_parallel_to_training': True, 'evaluation_config': {'env': 'wrapped_trading_env', 'env_config': {'data_filepath': '/Users/himanshuagrawal/rllib_project/validation_file.csv', 'window_size': 5}, 'explore': False}, 'batch_mode': 'truncate_episodes', 'rollout_fragment_length': 'auto', 'evaluation_num_workers': 1, 'always_attach_evaluation_results': True, 'num_workers': 3, 'num_cpus_per_worker': 1, 'framework': 'torch', 'num_gpus': 0, 'shuffle_sequences': False, 'vf_loss_coeff': 0, 'lr': 0.00011030325691881245, 'gamma': 0.9323024727685087, 'clip_param': 0.07510086140256599, 'kl_coeff': 0.6572094397695664, 'num_sgd_iter': 43, 'sgd_minibatch_size': 8, 'train_batch_size': 29, 'model': {'fcnet_hiddens': [64, 32], 'fcnet_activation': 'relu', 'use_lstm': False}, 'log_level': 'WARNING'}\n",
      "Best trial final reward: 0.1824803221676105\n"
     ]
    }
   ],
   "source": [
    "# Get a dataframe for all the trials\n",
    "df = analysis.results_df\n",
    "\n",
    "# Get the trial with the highest mean reward\n",
    "best_trial = analysis.get_best_trial(\"episode_reward_mean\", \"max\", \"last\")\n",
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "print(\"Best trial final reward:\", best_trial.last_result[\"episode_reward_mean\"])\n",
    "\n",
    "# Get the model from the best trial\n",
    "#best_trained_model = PPO(\n",
    "#    config=best_trial.config,\n",
    "#    env=\"wrapped_trading_env\",\n",
    "#)\n",
    "# Load the weights from the best trial\n",
    "#best_trained_model.set_weights(best_trial.last_result[\"weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6120\n"
     ]
    }
   ],
   "source": [
    "total_iterations = df['training_iteration'].max()\n",
    "print(total_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_id\n",
      "76be2_00000    0.021723\n",
      "76be2_00001   -0.019431\n",
      "Name: evaluation/episode_reward_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['evaluation/episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "best_trial_evaluation_results = best_trial.last_result[\"evaluation\"]\n",
    "print(best_trial_evaluation_results[\"episode_reward_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = analysis.get_best_checkpoint(best_trial, metric=\"episode_reward_mean\", mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint(local_path=/Users/himanshuagrawal/ray_results/PPO_PBT_Trading/PPO_wrapped_trading_env_76be2_00000_0_num_sgd_iter=43_2023-09-19_19-27-25/checkpoint_003580)\n"
     ]
    }
   ],
   "source": [
    "print(best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.wrappers import EnvCompatibility\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "def create_compatible_trading_env(env_config):\n",
    "    env = TradingEnv(env_config)\n",
    "    return EnvCompatibility(env)\n",
    "\n",
    "register_env(\"testing_trading_env\", create_compatible_trading_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 02:07:42,136\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='wrapped_trading_env', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('wrapped_trading_env').build()` instead. This will raise an error in the future!\n",
      "/Users/himanshuagrawal/rllib_project/rllib_env/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:442: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/Users/himanshuagrawal/rllib_project/rllib_env/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/himanshuagrawal/rllib_project/rllib_env/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/himanshuagrawal/rllib_project/rllib_env/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30296)\u001b[0m 2023-09-20 02:07:45,075\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2023-09-20 02:07:46,827\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "2023-09-20 02:07:46,904\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /Users/himanshuagrawal/ray_results/PPO_PBT_Trading/PPO_wrapped_trading_env_76be2_00000_0_num_sgd_iter=43_2023-09-19_19-27-25/checkpoint_003580\n",
      "2023-09-20 02:07:46,907\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3580, '_timesteps_total': None, '_time_total': 712.39705991745, '_episodes_total': 1163}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best episode reward: 0.061915276537716876\n",
      "Actions in best episode: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 2, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]\n",
      "States in best episode: [array([[ 3.12788668e-03,  4.17976366e-02,  0.00000000e+00],\n",
      "       [-5.39665179e-03,  4.77476788e-02,  0.00000000e+00],\n",
      "       [-6.37432049e-03, -2.00942516e-02,  0.00000000e+00],\n",
      "       [-8.35535483e-04,  1.26973128e-02,  0.00000000e+00],\n",
      "       [ 6.52200869e-05, -2.34443429e-02,  0.00000000e+00]]), array([[ 3.12788668e-03,  4.17976366e-02,  0.00000000e+00],\n",
      "       [-5.39665179e-03,  4.77476788e-02,  0.00000000e+00],\n",
      "       [-6.37432049e-03, -2.00942516e-02,  0.00000000e+00],\n",
      "       [-8.35535483e-04,  1.26973128e-02,  0.00000000e+00],\n",
      "       [ 6.52200869e-05, -2.34443429e-02,  0.00000000e+00]]), array([[-5.39665179e-03,  4.77476788e-02,  0.00000000e+00],\n",
      "       [-6.37432049e-03, -2.00942516e-02,  0.00000000e+00],\n",
      "       [-8.35535483e-04,  1.26973128e-02,  0.00000000e+00],\n",
      "       [ 6.52200869e-05, -2.34443429e-02,  0.00000000e+00],\n",
      "       [ 3.84363616e-03, -5.64961875e-02,  3.83626827e-03]]), array([[-6.37432049e-03, -2.00942516e-02,  0.00000000e+00],\n",
      "       [-8.35535483e-04,  1.26973128e-02,  0.00000000e+00],\n",
      "       [ 6.52200869e-05, -2.34443429e-02,  0.00000000e+00],\n",
      "       [ 3.84363616e-03, -5.64961875e-02,  3.83626827e-03],\n",
      "       [ 3.04954653e-03, -3.61184784e-02,  6.88117436e-03]]), array([[-8.35535483e-04,  1.26973128e-02,  0.00000000e+00],\n",
      "       [ 6.52200869e-05, -2.34443429e-02,  0.00000000e+00],\n",
      "       [ 3.84363616e-03, -5.64961875e-02,  3.83626827e-03],\n",
      "       [ 3.04954653e-03, -3.61184784e-02,  6.88117436e-03],\n",
      "       [ 3.23732993e-04, -3.81164221e-02,  7.20485496e-03]]), array([[ 6.52200869e-05, -2.34443429e-02,  0.00000000e+00],\n",
      "       [ 3.84363616e-03, -5.64961875e-02,  3.83626827e-03],\n",
      "       [ 3.04954653e-03, -3.61184784e-02,  6.88117436e-03],\n",
      "       [ 3.23732993e-04, -3.81164221e-02,  7.20485496e-03],\n",
      "       [ 2.57770320e-03,  1.09808090e-02,  9.77924158e-03]]), array([[ 0.00384364, -0.05649619,  0.00383627],\n",
      "       [ 0.00304955, -0.03611848,  0.00688117],\n",
      "       [ 0.00032373, -0.03811642,  0.00720485],\n",
      "       [ 0.0025777 ,  0.01098081,  0.00977924],\n",
      "       [ 0.00770785,  0.09632749,  0.01745754]]), array([[ 0.00304955, -0.03611848,  0.00688117],\n",
      "       [ 0.00032373, -0.03811642,  0.00720485],\n",
      "       [ 0.0025777 ,  0.01098081,  0.00977924],\n",
      "       [ 0.00770785,  0.09632749,  0.01745754],\n",
      "       [ 0.00971568, -0.05525872,  0.02712633]]), array([[ 0.00032373, -0.03811642,  0.00720485],\n",
      "       [ 0.0025777 ,  0.01098081,  0.00977924],\n",
      "       [ 0.00770785,  0.09632749,  0.01745754],\n",
      "       [ 0.00971568, -0.05525872,  0.02712633],\n",
      "       [-0.0006069 ,  0.00534649,  0.02651924]]), array([[ 0.0025777 ,  0.01098081,  0.00977924],\n",
      "       [ 0.00770785,  0.09632749,  0.01745754],\n",
      "       [ 0.00971568, -0.05525872,  0.02712633],\n",
      "       [-0.0006069 ,  0.00534649,  0.02651924],\n",
      "       [-0.00181082,  0.00134077,  0.        ]]), array([[ 0.00770785,  0.09632749,  0.01745754],\n",
      "       [ 0.00971568, -0.05525872,  0.02712633],\n",
      "       [-0.0006069 ,  0.00534649,  0.02651924],\n",
      "       [-0.00181082,  0.00134077,  0.        ],\n",
      "       [ 0.00200768,  0.05312713,  0.        ]]), array([[ 0.00971568, -0.05525872,  0.02712633],\n",
      "       [-0.0006069 ,  0.00534649,  0.02651924],\n",
      "       [-0.00181082,  0.00134077,  0.        ],\n",
      "       [ 0.00200768,  0.05312713,  0.        ],\n",
      "       [ 0.00018208,  0.05299137,  0.00018207]]), array([[-0.0006069 ,  0.00534649,  0.02651924],\n",
      "       [-0.00181082,  0.00134077,  0.        ],\n",
      "       [ 0.00200768,  0.05312713,  0.        ],\n",
      "       [ 0.00018208,  0.05299137,  0.00018207],\n",
      "       [ 0.01008801, -0.00655122,  0.01021953]]), array([[-0.00181082,  0.00134077,  0.        ],\n",
      "       [ 0.00200768,  0.05312713,  0.        ],\n",
      "       [ 0.00018208,  0.05299137,  0.00018207],\n",
      "       [ 0.01008801, -0.00655122,  0.01021953],\n",
      "       [ 0.00055723,  0.10376503,  0.01077661]]), array([[ 0.00200768,  0.05312713,  0.        ],\n",
      "       [ 0.00018208,  0.05299137,  0.00018207],\n",
      "       [ 0.01008801, -0.00655122,  0.01021953],\n",
      "       [ 0.00055723,  0.10376503,  0.01077661],\n",
      "       [ 0.00241357, -0.04529921,  0.        ]]), array([[ 0.00018208,  0.05299137,  0.00018207],\n",
      "       [ 0.01008801, -0.00655122,  0.01021953],\n",
      "       [ 0.00055723,  0.10376503,  0.01077661],\n",
      "       [ 0.00241357, -0.04529921,  0.        ],\n",
      "       [-0.00457848, -0.01525544,  0.        ]]), array([[ 0.01008801, -0.00655122,  0.01021953],\n",
      "       [ 0.00055723,  0.10376503,  0.01077661],\n",
      "       [ 0.00241357, -0.04529921,  0.        ],\n",
      "       [-0.00457848, -0.01525544,  0.        ],\n",
      "       [ 0.00358716,  0.01565274,  0.00358074]]), array([[ 0.00055723,  0.10376503,  0.01077661],\n",
      "       [ 0.00241357, -0.04529921,  0.        ],\n",
      "       [-0.00457848, -0.01525544,  0.        ],\n",
      "       [ 0.00358716,  0.01565274,  0.00358074],\n",
      "       [ 0.00507374,  0.08926321,  0.        ]]), array([[ 0.00241357, -0.04529921,  0.        ],\n",
      "       [-0.00457848, -0.01525544,  0.        ],\n",
      "       [ 0.00358716,  0.01565274,  0.00358074],\n",
      "       [ 0.00507374,  0.08926321,  0.        ],\n",
      "       [-0.00715592,  0.13012025,  0.        ]]), array([[-0.00457848, -0.01525544,  0.        ],\n",
      "       [ 0.00358716,  0.01565274,  0.00358074],\n",
      "       [ 0.00507374,  0.08926321,  0.        ],\n",
      "       [-0.00715592,  0.13012025,  0.        ],\n",
      "       [-0.00070759, -0.04756416, -0.00070784]]), array([[ 0.00358716,  0.01565274,  0.00358074],\n",
      "       [ 0.00507374,  0.08926321,  0.        ],\n",
      "       [-0.00715592,  0.13012025,  0.        ],\n",
      "       [-0.00070759, -0.04756416, -0.00070784],\n",
      "       [-0.00554202, -0.10460852, -0.00626527]]), array([[ 0.00507374,  0.08926321,  0.        ],\n",
      "       [-0.00715592,  0.13012025,  0.        ],\n",
      "       [-0.00070759, -0.04756416, -0.00070784],\n",
      "       [-0.00554202, -0.10460852, -0.00626527],\n",
      "       [ 0.00082201, -0.00850639, -0.0054436 ]]), array([[-0.00715592,  0.13012025,  0.        ],\n",
      "       [-0.00070759, -0.04756416, -0.00070784],\n",
      "       [-0.00554202, -0.10460852, -0.00626527],\n",
      "       [ 0.00082201, -0.00850639, -0.0054436 ],\n",
      "       [ 0.00888962,  0.03698661,  0.        ]]), array([[-0.00070759, -0.04756416, -0.00070784],\n",
      "       [-0.00554202, -0.10460852, -0.00626527],\n",
      "       [ 0.00082201, -0.00850639, -0.0054436 ],\n",
      "       [ 0.00888962,  0.03698661,  0.        ],\n",
      "       [-0.00370854, -0.15682719,  0.        ]]), array([[-0.00554202, -0.10460852, -0.00626527],\n",
      "       [ 0.00082201, -0.00850639, -0.0054436 ],\n",
      "       [ 0.00888962,  0.03698661,  0.        ],\n",
      "       [-0.00370854, -0.15682719,  0.        ],\n",
      "       [-0.00141572,  0.09046909,  0.        ]]), array([[ 0.00082201, -0.00850639, -0.0054436 ],\n",
      "       [ 0.00888962,  0.03698661,  0.        ],\n",
      "       [-0.00370854, -0.15682719,  0.        ],\n",
      "       [-0.00141572,  0.09046909,  0.        ],\n",
      "       [ 0.00544363, -0.06015966,  0.        ]]), array([[ 0.00888962,  0.03698661,  0.        ],\n",
      "       [-0.00370854, -0.15682719,  0.        ],\n",
      "       [-0.00141572,  0.09046909,  0.        ],\n",
      "       [ 0.00544363, -0.06015966,  0.        ],\n",
      "       [ 0.01365396,  0.04003177,  0.        ]]), array([[-0.00370854, -0.15682719,  0.        ],\n",
      "       [-0.00141572,  0.09046909,  0.        ],\n",
      "       [ 0.00544363, -0.06015966,  0.        ],\n",
      "       [ 0.01365396,  0.04003177,  0.        ],\n",
      "       [-0.00067135,  0.01554399,  0.        ]]), array([[-0.00141572,  0.09046909,  0.        ],\n",
      "       [ 0.00544363, -0.06015966,  0.        ],\n",
      "       [ 0.01365396,  0.04003177,  0.        ],\n",
      "       [-0.00067135,  0.01554399,  0.        ],\n",
      "       [-0.00066918, -0.03230832, -0.0006694 ]]), array([[ 0.00544363, -0.06015966,  0.        ],\n",
      "       [ 0.01365396,  0.04003177,  0.        ],\n",
      "       [-0.00067135,  0.01554399,  0.        ],\n",
      "       [-0.00066918, -0.03230832, -0.0006694 ],\n",
      "       [-0.00079588, -0.0580835 , -0.0014656 ]]), array([[ 0.01365396,  0.04003177,  0.        ],\n",
      "       [-0.00067135,  0.01554399,  0.        ],\n",
      "       [-0.00066918, -0.03230832, -0.0006694 ],\n",
      "       [-0.00079588, -0.0580835 , -0.0014656 ],\n",
      "       [-0.00153669,  0.01404663,  0.        ]]), array([[-0.00067135,  0.01554399,  0.        ],\n",
      "       [-0.00066918, -0.03230832, -0.0006694 ],\n",
      "       [-0.00079588, -0.0580835 , -0.0014656 ],\n",
      "       [-0.00153669,  0.01404663,  0.        ],\n",
      "       [ 0.00329637, -0.06381958,  0.        ]])]\n",
      "Rewards in best episode: [0, 0, 0, 0, 0, 0, 0, 0, 0.024706785026400852, 0, 0, 0, 0, 0.013187268850138106, 0, 0, 0.00864164799208144, 0, 0, 0, 0, 0.0034067390494498854, 0, 0.0014147228872512581, 0, 0.013561588420889377, 0, 0, 0, -0.0030034756884940485, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "env_config = {\n",
    "    \"data_filepath\": \"testbase_data.csv\",\n",
    "    \"window_size\": 5,\n",
    "}\n",
    "env = TradingEnv(env_config)\n",
    "\n",
    "best_trial = analysis.get_best_trial(\"episode_reward_mean\", \"max\", \"last\")\n",
    "\n",
    "best_checkpoint = analysis.get_best_checkpoint(best_trial, metric=\"episode_reward_mean\", mode=\"max\")\n",
    "# Create a new trainer with the configuration of the best trial\n",
    "best_trainer = PPO(env=\"wrapped_trading_env\", config=best_trial.config)\n",
    "\n",
    "# Restore the trainer state from the best checkpoint\n",
    "best_trainer.restore(best_checkpoint)\n",
    "\n",
    "num_episodes = 50\n",
    "rewards = []\n",
    "results = []\n",
    "\n",
    "# Now you can use this trainer to compute actions in your testing loop\n",
    "for i in range(num_episodes):\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    actions = []\n",
    "    states = [obs]\n",
    "    episode_rewards = []\n",
    "    \n",
    "    while not done:\n",
    "        #action = best_trainer.compute_single_action(obs )\n",
    "        # Initialize LSTM state\n",
    "        state = best_trainer.get_policy().get_initial_state()\n",
    "\n",
    "        # Use the state when computing actions\n",
    "        action, state_out, _ = best_trainer.compute_single_action(obs, state=state, full_fetch=True)\n",
    "\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        \n",
    "        actions.append(action)\n",
    "        states.append(obs)\n",
    "        episode_rewards.append(reward)\n",
    "        \n",
    "        episode_reward += reward\n",
    "\n",
    "    rewards.append(episode_reward)\n",
    "    results.append({\n",
    "        'episode': i,\n",
    "        'reward': episode_reward,\n",
    "        'actions': actions,\n",
    "        'states': states,\n",
    "        'episode_rewards': episode_rewards\n",
    "    })\n",
    "\n",
    "# Now results is a list of dictionaries containing the actions, states, \n",
    "# rewards for each step in each episode, and the total reward for each episode\n",
    "# This information can be used for further analysis\n",
    "\n",
    "# If you want to get the complete action, reward and state values for the best performing test run, \n",
    "# You can use the following line of code:\n",
    "best_episode = max(results, key=lambda x: x['reward'])\n",
    "\n",
    "print(f\"Best episode reward: {best_episode['reward']}\")\n",
    "print(f\"Actions in best episode: {best_episode['actions']}\")\n",
    "print(f\"States in best episode: {best_episode['states']}\")\n",
    "print(f\"Rewards in best episode: {best_episode['episode_rewards']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['flatten.0._hidden_layers.0._model.0.weight', 'flatten.0._hidden_layers.0._model.0.bias', 'flatten.0._hidden_layers.1._model.0.weight', 'flatten.0._hidden_layers.1._model.0.bias', 'flatten.0._value_branch_separate.0._model.0.weight', 'flatten.0._value_branch_separate.0._model.0.bias', 'flatten.0._value_branch_separate.1._model.0.weight', 'flatten.0._value_branch_separate.1._model.0.bias', 'flatten.0._value_branch._model.0.weight', 'flatten.0._value_branch._model.0.bias', 'flatten_0._hidden_layers.0._model.0.weight', 'flatten_0._hidden_layers.0._model.0.bias', 'flatten_0._hidden_layers.1._model.0.weight', 'flatten_0._hidden_layers.1._model.0.bias', 'flatten_0._value_branch_separate.0._model.0.weight', 'flatten_0._value_branch_separate.0._model.0.bias', 'flatten_0._value_branch_separate.1._model.0.weight', 'flatten_0._value_branch_separate.1._model.0.bias', 'flatten_0._value_branch._model.0.weight', 'flatten_0._value_branch._model.0.bias', 'post_fc_stack._value_branch._model.0.weight', 'post_fc_stack._value_branch._model.0.bias', 'logits_layer._model.0.weight', 'logits_layer._model.0.bias', 'value_layer._model.0.weight', 'value_layer._model.0.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(best_trainer.get_policy().model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward = sum(rewards)/len(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03155970240034727\n"
     ]
    }
   ],
   "source": [
    "print(mean_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure()\n",
    "# Plot the data\n",
    "plt.plot(rewards)\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "print(ray.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Extract the checkpoint path from the best_checkpoint object\n",
    "#Checkpoint(local_path=/Users/himanshuagrawal/ray_results/PPO_PBT_Trading/PPO_wrapped_trading_env_76be2_00000_0_num_sgd_iter=43_2023-09-19_19-27-25/checkpoint_003580)\n",
    "checkpoint_path_to_save = '/Users/himanshuagrawal/ray_results/PPO_PBT_Trading/PPO_wrapped_trading_env_76be2_00000_0_num_sgd_iter=43_2023-09-19_19-27-25/checkpoint_003580'\n",
    "\n",
    "# Save the checkpoint path and best trial config\n",
    "with open('model_info1.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'checkpoint_path': checkpoint_path_to_save,\n",
    "        'best_trial_config': best_trial.config\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 03:02:02,975\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='wrapped_trading_env', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('wrapped_trading_env').build()` instead. This will raise an error in the future!\n",
      "/Users/himanshuagrawal/rllib_project/rllib_env/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:442: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/Users/himanshuagrawal/rllib_project/rllib_env/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/himanshuagrawal/rllib_project/rllib_env/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/himanshuagrawal/rllib_project/rllib_env/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30894)\u001b[0m 2023-09-20 03:02:06,033\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "2023-09-20 03:02:07,987\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "2023-09-20 03:02:08,107\tINFO trainable.py:918 -- Restored on 127.0.0.1 from checkpoint: /Users/himanshuagrawal/ray_results/PPO_PBT_Trading/PPO_wrapped_trading_env_76be2_00000_0_num_sgd_iter=43_2023-09-19_19-27-25/checkpoint_003580\n",
      "2023-09-20 03:02:08,107\tINFO trainable.py:927 -- Current state after restoring: {'_iteration': 3580, '_timesteps_total': None, '_time_total': 712.39705991745, '_episodes_total': 1163}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from ray.rllib.algorithms.ppo import PPO\n",
    "\n",
    "with open('model_info1.json', 'r') as f:\n",
    "        model_info = json.load(f)\n",
    "\n",
    "env_config = {\n",
    "    \"data_filepath\": \"testbase_data.csv\",\n",
    "    \"window_size\": 5,\n",
    "}\n",
    "env = TradingEnv(env_config)\n",
    "\n",
    "checkpoint_path = model_info['checkpoint_path']\n",
    "best_trial_config = model_info['best_trial_config']\n",
    "        #best_trial_config[\"env_config\"] = {\"disable_env_checking\": True}\n",
    "trainer = PPO(env=\"wrapped_trading_env\", config=best_trial_config)\n",
    "trainer.restore(checkpoint_path)\n",
    "\n",
    "num_episodes = 50\n",
    "rewards = []\n",
    "results = []\n",
    "\n",
    "# Now you can use this trainer to compute actions in your testing loop\n",
    "for i in range(num_episodes):\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    actions = []\n",
    "    states = [obs]\n",
    "    episode_rewards = []\n",
    "    \n",
    "    while not done:\n",
    "        #action = best_trainer.compute_single_action(obs )\n",
    "        # Initialize LSTM state\n",
    "        state = trainer.get_policy().get_initial_state()\n",
    "\n",
    "        # Use the state when computing actions\n",
    "        action, state_out, _ = trainer.compute_single_action(obs, state=state, full_fetch=True)\n",
    "\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        \n",
    "        actions.append(action)\n",
    "        states.append(obs)\n",
    "        episode_rewards.append(reward)\n",
    "        \n",
    "        episode_reward += reward\n",
    "\n",
    "    rewards.append(episode_reward)\n",
    "    results.append({\n",
    "        'episode': i,\n",
    "        'reward': episode_reward,\n",
    "        'actions': actions,\n",
    "        'states': states,\n",
    "        'episode_rewards': episode_rewards\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def default_serialize(o):\n",
    "    if isinstance(o, np.integer):\n",
    "        return int(o)\n",
    "    elif isinstance(o, np.floating):\n",
    "        return float(o)\n",
    "    elif isinstance(o, np.ndarray):\n",
    "        return o.tolist()\n",
    "    else:\n",
    "        raise TypeError(f\"Object of type '{type(o).__name__}' is not JSON serializable\")\n",
    "\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f, default=default_serialize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rllib_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
